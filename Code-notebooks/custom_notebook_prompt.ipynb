{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import os\n",
    "from PIL import Image\n",
    "from moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips\n",
    "import numpy as np\n",
    "import io\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "def generate_animated_frames(data):\n",
    "    logging.info(\"Generating animated frames from data\")\n",
    "    frames = []\n",
    "    \n",
    "    # Generate a basic time series plot if a date column is present\n",
    "    date_column = None\n",
    "    for col in data.columns:\n",
    "        if 'date' in col.lower() or 'time' in col.lower():\n",
    "            date_column = col\n",
    "            break\n",
    "    \n",
    "    if date_column:\n",
    "        numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "        if len(numeric_columns) > 0:\n",
    "            fig, ax = plt.subplots(figsize=(10, 6))\n",
    "            lines = [ax.plot([], [], label=col)[0] for col in numeric_columns]\n",
    "            ax.set_xlim(data[date_column].min(), data[date_column].max())\n",
    "            ax.set_ylim(data[numeric_columns].min().min(), data[numeric_columns].max().max())\n",
    "            ax.set_title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n",
    "            ax.set_xlabel('Time')\n",
    "            ax.set_ylabel('Values')\n",
    "            ax.legend()\n",
    "\n",
    "            def update(frame):\n",
    "                for line, col in zip(lines, numeric_columns):\n",
    "                    line.set_data(data[date_column][:frame], data[col][:frame])\n",
    "                return lines\n",
    "\n",
    "            ani = FuncAnimation(fig, update, frames=len(data), blit=True)\n",
    "            for i in range(len(data)):\n",
    "                update(i)\n",
    "                buf = io.BytesIO()\n",
    "                fig.savefig(buf, format='png')\n",
    "                buf.seek(0)\n",
    "                img = Image.open(buf)\n",
    "                frames.append(np.array(img))\n",
    "            plt.close(fig)\n",
    "    \n",
    "    # Generate a moving bar chart\n",
    "    if 'category' in data.columns and 'value' in data.columns:\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        categories = data['category'].unique()\n",
    "        bars = ax.bar(categories, np.zeros(len(categories)))\n",
    "        ax.set_ylim(0, data['value'].max())\n",
    "        ax.set_title('Moving Bar Chart')\n",
    "        ax.set_xlabel('Category')\n",
    "        ax.set_ylabel('Value')\n",
    "\n",
    "        def update_bar(frame):\n",
    "            for bar, category in zip(bars, categories):\n",
    "                bar.set_height(data[data['category'] == category]['value'].iloc[frame])\n",
    "            return bars\n",
    "\n",
    "        ani = FuncAnimation(fig, update_bar, frames=len(data), blit=True)\n",
    "        for i in range(len(data)):\n",
    "            update_bar(i)\n",
    "            buf = io.BytesIO()\n",
    "            fig.savefig(buf, format='png')\n",
    "            buf.seek(0)\n",
    "            img = Image.open(buf)\n",
    "            frames.append(np.array(img))\n",
    "        plt.close(fig)\n",
    "    \n",
    "    # Generate a correlation matrix plot\n",
    "    if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n",
    "        corr_matrix = data.corr()\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n",
    "        ax.set_title('Correlation Matrix')\n",
    "        buf = io.BytesIO()\n",
    "        fig.savefig(buf, format='png')\n",
    "        buf.seek(0)\n",
    "        img = Image.open(buf)\n",
    "        frames.append(np.array(img))\n",
    "        plt.close(fig)\n",
    "    \n",
    "    # Generate distribution plots for numeric columns\n",
    "    numeric_columns = data.select_dtypes(include(['float64', 'int64']).columns\n",
    "    for col in numeric_columns:\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        sns.histplot(data[col], bins=10, kde=True, ax=ax)\n",
    "        ax.set_title(f\"Distribution of {col}\")\n",
    "        buf = io.BytesIO()\n",
    "        fig.savefig(buf, format='png')\n",
    "        buf.seek(0)\n",
    "        img = Image.open(buf)\n",
    "        frames.append(np.array(img))\n",
    "        plt.close(fig)\n",
    "    \n",
    "    logging.info(f\"Generated {len(frames)} animated frames\")\n",
    "    return frames\n",
    "\n",
    "def create_video_from_frames(frames, audio_file=None, video_file=\"super_final_video.mp4\"):\n",
    "    if not frames:\n",
    "        raise ValueError(\"No frames to create video from.\")\n",
    "    \n",
    "    logging.info(\"Creating video from frames\")\n",
    "    video_clips = [ImageSequenceClip([np.array(frame)], fps=1) for frame in frames]  # Adjust fps to slow down the video\n",
    "    \n",
    "    video = concatenate_videoclips(video_clips, method=\"compose\")\n",
    "    \n",
    "    if audio_file and os.path.isfile(audio_file):\n",
    "        audio = AudioFileClip(audio_file)\n",
    "        video = video.set_audio(audio)\n",
    "    \n",
    "    video.write_videofile(video_file, codec=\"libx264\", fps=24)\n",
    "    logging.info(f\"Video saved as {video_file}\")\n",
    "\n",
    "def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n",
    "    frames = generate_animated_frames(data)\n",
    "    if not frames:\n",
    "        raise ValueError(\"No frames generated from data.\")\n",
    "    \n",
    "    if os.path.exists(title_image):\n",
    "        title_image_clip = Image.open(title_image)\n",
    "        title_image_clip = title_image_clip.convert(\"RGBA\")\n",
    "        title_image_clip = np.array(title_image_clip)\n",
    "        frames.insert(0, title_image_clip)\n",
    "    \n",
    "    create_video_from_frames(frames, audio_file)\n",
    "    print(\"Video successfully generated!\")\n",
    "\n",
    "def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        logging.info(\"Loading and preprocessing data...\")\n",
    "        data = load_and_preprocess_data(file_path)\n",
    "        logging.debug(f\"Loaded Data: {data.head()}\")\n",
    "        \n",
    "        logging.info(\"Performing EDA...\")\n",
    "        eda_summary = perform_eda(data)\n",
    "        logging.debug(f\"EDA Summary: {eda_summary}\")\n",
    "        \n",
    "        logging.info(\"Analyzing the user's prompt...\")\n",
    "        insights = analyze_prompt_for_insights(prompt)\n",
    "        logging.debug(f\"Extracted insights: {insights}\")\n",
    "        \n",
    "        logging.info(\"Creating the infographic video...\")\n",
    "        generate_infographic_video(data, insights, audio_file=audio_file)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "    except FileNotFoundError as fnf_error:\n",
    "        logging.error(f\"File not found: {fnf_error}\")\n",
    "        raise\n",
    "    except pd.errors.ParserError as parser_error:\n",
    "        logging.error(f\"Error parsing the file: {parser_error}\")\n",
    "        raise\n",
    "    except TypeError as type_error:\n",
    "        logging.error(f\"Type error: {type_error}\")\n",
    "        raise\n",
    "    except ValueError as value_error:\n",
    "        logging.error(f\"Value error: {value_error}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An unexpected error occurred: {e}\")\n",
    "        raise\n",
    "\n",
    "# Example usage:\n",
    "file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n",
    "prompt = \"Analyze the country and region data\"\n",
    "audio_file = \"/kaggle/working/file.mp3\"\n",
    "title_image = \"/kaggle/working/title_screen.png\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    raise FileNotFoundError(f\"Data file not found: {file_path}\")\n",
    "if not os.path.exists(audio_file):\n",
    "    raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n",
    "if not os.path.exists(title_image):\n",
    "    raise FileNotFoundError(f\"Title image not found: {title_image}\")\n",
    "\n",
    "data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import os\n",
    "from PIL import Image\n",
    "from moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips, CompositeVideoClip, TextClip\n",
    "import numpy as np\n",
    "import io\n",
    "import pandas as pd\n",
    "import time\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from gtts import gTTS\n",
    "\n",
    "def generate_default_frames(data):\n",
    "    logging.info(\"Generating default frames from data\")\n",
    "    frames = []\n",
    "    \n",
    "    # Generate a basic time series plot if a date column is present\n",
    "    date_column = None\n",
    "    for col in data.columns:\n",
    "        if 'date' in col.lower() or 'time' in col.lower():\n",
    "            date_column = col\n",
    "            break\n",
    "    \n",
    "    if date_column:\n",
    "        numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "        if len(numeric_columns) > 0:\n",
    "            fig, ax = plt.subplots(figsize=(10, 6))\n",
    "            for col in numeric_columns:\n",
    "                ax.plot(data[date_column], data[col], label=col)\n",
    "            ax.set_title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n",
    "            ax.set_xlabel('Time')\n",
    "            ax.set_ylabel('Values')\n",
    "            ax.legend()\n",
    "            buf = io.BytesIO()\n",
    "            fig.savefig(buf, format='png')\n",
    "            buf.seek(0)\n",
    "            img = Image.open(buf)\n",
    "            frames.append(img)\n",
    "            plt.close(fig)\n",
    "    \n",
    "    # Generate a correlation matrix plot\n",
    "    if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n",
    "        corr_matrix = data.corr()\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n",
    "        ax.set_title('Correlation Matrix')\n",
    "        buf = io.BytesIO()\n",
    "        fig.savefig(buf, format='png')\n",
    "        buf.seek(0)\n",
    "        img = Image.open(buf)\n",
    "        frames.append(img)\n",
    "        plt.close(fig)\n",
    "    \n",
    "    # Generate animated bar plots for numeric columns\n",
    "    numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "    for col in numeric_columns:\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        def update(num):\n",
    "            ax.clear()\n",
    "            sns.histplot(data[col][:num], bins=10, kde=True, ax=ax)\n",
    "            ax.set_title(f\"Distribution of {col} (Frame {num})\")\n",
    "        ani = FuncAnimation(fig, update, frames=len(data), repeat=False)\n",
    "        temp_file = \"temp_animation.gif\"\n",
    "        ani.save(temp_file, writer='imagemagick')\n",
    "        img = Image.open(temp_file)\n",
    "        frames.append(img)\n",
    "        os.remove(temp_file)\n",
    "        plt.close(fig)\n",
    "    \n",
    "    # Generate 3D scatter plot if there are at least 3 numeric columns\n",
    "    if len(numeric_columns) >= 3:\n",
    "        fig = plt.figure(figsize=(10, 6))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.scatter(data[numeric_columns[0]], data[numeric_columns[1]], data[numeric_columns[2]])\n",
    "        ax.set_title('3D Scatter Plot')\n",
    "        ax.set_xlabel(numeric_columns[0])\n",
    "        ax.set_ylabel(numeric_columns[1])\n",
    "        ax.set_zlabel(numeric_columns[2])\n",
    "        buf = io.BytesIO()\n",
    "        fig.savefig(buf, format='png')\n",
    "        buf.seek(0)\n",
    "        img = Image.open(buf)\n",
    "        frames.append(img)\n",
    "        plt.close(fig)\n",
    "    \n",
    "    logging.info(f\"Generated {len(frames)} default frames\")\n",
    "    return frames\n",
    "\n",
    "def create_video_from_frames(frames, audio_file=None, video_file=\"final_video.mp4\"):\n",
    "    if not frames:\n",
    "        raise ValueError(\"No frames to create video from.\")\n",
    "    \n",
    "    logging.info(\"Creating video from frames\")\n",
    "    video_clips = []\n",
    "    for frame in frames:\n",
    "        img_clip = ImageSequenceClip([np.array(frame)], fps=1)  # 1 frame per second\n",
    "        img_clip = img_clip.set_duration(5)  # Each frame lasts 5 seconds\n",
    "        video_clips.append(img_clip)\n",
    "    \n",
    "    video = concatenate_videoclips(video_clips, method=\"compose\")\n",
    "    \n",
    "    if audio_file and os.path.isfile(audio_file):\n",
    "        audio = AudioFileClip(audio_file)\n",
    "        video = video.set_audio(audio)\n",
    "    \n",
    "    video.write_videofile(video_file, codec=\"libx264\", fps=24)\n",
    "    logging.info(f\"Video saved as {video_file}\")\n",
    "\n",
    "def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n",
    "    frames = generate_default_frames(data)\n",
    "    if not frames:\n",
    "        raise ValueError(\"No frames generated from data.\")\n",
    "    \n",
    "    if os.path.exists(title_image):\n",
    "        title_image_clip = Image.open(title_image)\n",
    "        title_image_clip = title_image_clip.convert(\"RGBA\")\n",
    "        title_image_clip = np.array(title_image_clip)\n",
    "        frames.insert(0, title_image_clip)\n",
    "    \n",
    "    create_video_from_frames(frames, audio_file)\n",
    "    print(\"Video successfully generated!\")\n",
    "\n",
    "def generate_narration(text, output_file=\"narration.mp3\"):\n",
    "    tts = gTTS(text=text, lang='en')\n",
    "    tts.save(output_file)\n",
    "    return output_file\n",
    "\n",
    "def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        logging.info(\"Loading and preprocessing data...\")\n",
    "        data = load_and_preprocess_data(file_path)\n",
    "        logging.debug(f\"Loaded Data: {data.head()}\")\n",
    "        \n",
    "        logging.info(\"Performing EDA...\")\n",
    "        eda_summary = perform_eda(data)\n",
    "        logging.debug(f\"EDA Summary: {eda_summary}\")\n",
    "        \n",
    "        logging.info(\"Analyzing the user's prompt...\")\n",
    "        insights = analyze_prompt_for_insights(prompt)\n",
    "        logging.debug(f\"Extracted insights: {insights}\")\n",
    "        \n",
    "        logging.info(\"Generating narration...\")\n",
    "        narration_text = f\"Here is the analysis based on the prompt: {prompt}. {insights}\"\n",
    "        narration_file = generate_narration(narration_text)\n",
    "        \n",
    "        logging.info(\"Creating the infographic video...\")\n",
    "        generate_infographic_video(data, insights, audio_file=narration_file)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "    except FileNotFoundError as fnf_error:\n",
    "        logging.error(f\"File not found: {fnf_error}\")\n",
    "        raise\n",
    "    except pd.errors.ParserError as parser_error:\n",
    "        logging.error(f\"Error parsing the file: {parser_error}\")\n",
    "        raise\n",
    "    except TypeError as type_error:\n",
    "        logging.error(f\"Type error: {type_error}\")\n",
    "        raise\n",
    "    except ValueError as value_error:\n",
    "        logging.error(f\"Value error: {value_error}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An unexpected error occurred: {e}\")\n",
    "        raise\n",
    "\n",
    "# Example usage:\n",
    "file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n",
    "prompt = \"Analyze the country and region data\"\n",
    "audio_file = \"/kaggle/working/\"\n",
    "title_image = \"/kaggle/working/\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    raise FileNotFoundError(f\"Data file not found: {file_path}\")\n",
    "if not os.path.exists(audio_file):\n",
    "    raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n",
    "if not os.path.exists(title_image):\n",
    "    raise FileNotFoundError(f\"Title image not found: {title_image}\")\n",
    "\n",
    "data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import os\n",
    "from PIL import Image\n",
    "from moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips, CompositeVideoClip, TextClip\n",
    "import numpy as np\n",
    "import io\n",
    "import pandas as pd\n",
    "import time\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from gtts import gTTS\n",
    "\n",
    "def generate_default_frames(data):\n",
    "    logging.info(\"Generating default frames from data\")\n",
    "    frames = []\n",
    "    \n",
    "    # Generate a basic time series plot if a date column is present\n",
    "    date_column = None\n",
    "    for col in data.columns:\n",
    "        if 'date' in col.lower() or 'time' in col.lower():\n",
    "            date_column = col\n",
    "            break\n",
    "    \n",
    "    if date_column:\n",
    "        numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "        if len(numeric_columns) > 0:\n",
    "            fig, ax = plt.subplots(figsize=(10, 6))\n",
    "            for col in numeric_columns:\n",
    "                ax.plot(data[date_column], data[col], label=col)\n",
    "            ax.set_title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n",
    "            ax.set_xlabel('Time')\n",
    "            ax.set_ylabel('Values')\n",
    "            ax.legend()\n",
    "            buf = io.BytesIO()\n",
    "            fig.savefig(buf, format='png')\n",
    "            buf.seek(0)\n",
    "            img = Image.open(buf)\n",
    "            frames.append(np.array(img))\n",
    "            plt.close(fig)\n",
    "    \n",
    "    # Generate a correlation matrix plot\n",
    "    if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n",
    "        corr_matrix = data.corr()\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n",
    "        ax.set_title('Correlation Matrix')\n",
    "        buf = io.BytesIO()\n",
    "        fig.savefig(buf, format='png')\n",
    "        buf.seek(0)\n",
    "        img = Image.open(buf)\n",
    "        frames.append(np.array(img))\n",
    "        plt.close(fig)\n",
    "    \n",
    "    # Generate animated bar plots for numeric columns\n",
    "    numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "    for col in numeric_columns:\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        def update(num):\n",
    "            ax.clear()\n",
    "            sns.histplot(data[col][:num], bins=10, kde=True, ax=ax)\n",
    "            ax.set_title(f\"Distribution of {col} (Frame {num})\")\n",
    "        ani = FuncAnimation(fig, update, frames=len(data), repeat=False)\n",
    "        temp_file = \"temp_animation.gif\"\n",
    "        ani.save(temp_file, writer='imagemagick')\n",
    "        img = Image.open(temp_file)\n",
    "        frames.append(np.array(img))\n",
    "        os.remove(temp_file)\n",
    "        plt.close(fig)\n",
    "    \n",
    "    # Generate 3D scatter plot if there are at least 3 numeric columns\n",
    "    if len(numeric_columns) >= 3:\n",
    "        fig = plt.figure(figsize=(10, 6))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.scatter(data[numeric_columns[0]], data[numeric_columns[1]], data[numeric_columns[2]])\n",
    "        ax.set_title('3D Scatter Plot')\n",
    "        ax.set_xlabel(numeric_columns[0])\n",
    "        ax.set_ylabel(numeric_columns[1])\n",
    "        ax.set_zlabel(numeric_columns[2])\n",
    "        buf = io.BytesIO()\n",
    "        fig.savefig(buf, format='png')\n",
    "        buf.seek(0)\n",
    "        img = Image.open(buf)\n",
    "        frames.append(np.array(img))\n",
    "        plt.close(fig)\n",
    "    \n",
    "    logging.info(f\"Generated {len(frames)} default frames\")\n",
    "    return frames\n",
    "\n",
    "def create_video_from_frames(frames, audio_file=None, video_file=\"final_video.mp4\"):\n",
    "    if not frames:\n",
    "        raise ValueError(\"No frames to create video from.\")\n",
    "    \n",
    "    logging.info(\"Creating video from frames\")\n",
    "    video_clips = []\n",
    "    for frame in frames:\n",
    "        img_clip = ImageSequenceClip([frame], fps=1)  # 1 frame per second\n",
    "        img_clip = img_clip.set_duration(5)  # Each frame lasts 5 seconds\n",
    "        video_clips.append(img_clip)\n",
    "    \n",
    "    video = concatenate_videoclips(video_clips, method=\"compose\")\n",
    "    \n",
    "    if audio_file and os.path.isfile(audio_file):\n",
    "        audio = AudioFileClip(audio_file)\n",
    "        video = video.set_audio(audio)\n",
    "    \n",
    "    video.write_videofile(video_file, codec=\"libx264\", fps=24)\n",
    "    logging.info(f\"Video saved as {video_file}\")\n",
    "\n",
    "def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n",
    "    frames = generate_default_frames(data)\n",
    "    if not frames:\n",
    "        raise ValueError(\"No frames generated from data.\")\n",
    "    \n",
    "    if os.path.exists(title_image):\n",
    "        title_image_clip = Image.open(title_image)\n",
    "        title_image_clip = title_image_clip.convert(\"RGBA\")\n",
    "        title_image_clip = np.array(title_image_clip)\n",
    "        frames.insert(0, title_image_clip)\n",
    "    \n",
    "    create_video_from_frames(frames, audio_file)\n",
    "    print(\"Video successfully generated!\")\n",
    "\n",
    "def generate_narration(text, output_file=\"narration.mp3\"):\n",
    "    tts = gTTS(text=text, lang='en')\n",
    "    tts.save(output_file)\n",
    "    return output_file\n",
    "\n",
    "def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        logging.info(\"Loading and preprocessing data...\")\n",
    "        data = load_and_preprocess_data(file_path)\n",
    "        logging.debug(f\"Loaded Data: {data.head()}\")\n",
    "        \n",
    "        logging.info(\"Performing EDA...\")\n",
    "        eda_summary = perform_eda(data)\n",
    "        logging.debug(f\"EDA Summary: {eda_summary}\")\n",
    "        \n",
    "        logging.info(\"Analyzing the user's prompt...\")\n",
    "        insights = analyze_prompt_for_insights(prompt)\n",
    "        logging.debug(f\"Extracted insights: {insights}\")\n",
    "        \n",
    "        logging.info(\"Generating narration...\")\n",
    "        narration_text = f\"Here is the analysis based on the prompt: {prompt}. {insights}\"\n",
    "        narration_file = generate_narration(narration_text)\n",
    "        \n",
    "        logging.info(\"Creating the infographic video...\")\n",
    "        generate_infographic_video(data, insights, audio_file=narration_file)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "    except FileNotFoundError as fnf_error:\n",
    "        logging.error(f\"File not found: {fnf_error}\")\n",
    "        raise\n",
    "    except pd.errors.ParserError as parser_error:\n",
    "        logging.error(f\"Error parsing the file: {parser_error}\")\n",
    "        raise\n",
    "    except TypeError as type_error:\n",
    "        logging.error(f\"Type error: {type_error}\")\n",
    "        raise\n",
    "    except ValueError as value_error:\n",
    "        logging.error(f\"Value error: {value_error}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An unexpected error occurred: {e}\")\n",
    "        raise\n",
    "\n",
    "# Example usage:\n",
    "file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n",
    "prompt = \"Analyze the country and region data\"\n",
    "audio_file = \"/kaggle/working/file.mp3\"\n",
    "title_image = \"/kaggle/working/title_screen.png\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    raise FileNotFoundError(f\"Data file not found: {file_path}\")\n",
    "if not os.path.exists(audio_file):\n",
    "    raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n",
    "if not os.path.exists(title_image):\n",
    "    raise FileNotFoundError(f\"Title image not found: {title_image}\")\n",
    "\n",
    "data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import os\n",
    "from PIL import Image\n",
    "from moviepy.editor import ImageSequenceClip, AudioFileClip, concatenate_videoclips, CompositeVideoClip, TextClip\n",
    "import numpy as np\n",
    "import io\n",
    "import pandas as pd\n",
    "import time\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from gtts import gTTS\n",
    "\n",
    "def generate_default_frames(data):\n",
    "    logging.info(\"Generating default frames from data\")\n",
    "    frames = []\n",
    "    \n",
    "    # Generate a basic time series plot if a date column is present\n",
    "    date_column = None\n",
    "    for col in data.columns:\n",
    "        if 'date' in col.lower() or 'time' in col.lower():\n",
    "            date_column = col\n",
    "            break\n",
    "    \n",
    "    if date_column:\n",
    "        numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "        if len(numeric_columns) > 0:\n",
    "            fig, ax = plt.subplots(figsize=(10, 6))\n",
    "            for col in numeric_columns:\n",
    "                ax.plot(data[date_column], data[col], label=col)\n",
    "            ax.set_title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n",
    "            ax.set_xlabel('Time')\n",
    "            ax.set_ylabel('Values')\n",
    "            ax.legend()\n",
    "            buf = io.BytesIO()\n",
    "            fig.savefig(buf, format='png')\n",
    "            buf.seek(0)\n",
    "            img = Image.open(buf)\n",
    "            frames.append(np.array(img))\n",
    "            plt.close(fig)\n",
    "    \n",
    "    # Generate a correlation matrix plot\n",
    "    if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n",
    "        corr_matrix = data.corr()\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n",
    "        ax.set_title('Correlation Matrix')\n",
    "        buf = io.BytesIO()\n",
    "        fig.savefig(buf, format='png')\n",
    "        buf.seek(0)\n",
    "        img = Image.open(buf)\n",
    "        frames.append(np.array(img))\n",
    "        plt.close(fig)\n",
    "    \n",
    "    # Generate animated bar plots for numeric columns\n",
    "    numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "    for col in numeric_columns:\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        def update(num):\n",
    "            ax.clear()\n",
    "            sns.histplot(data[col][:num], bins=10, kde=True, ax=ax)\n",
    "            ax.set_title(f\"Distribution of {col} (Frame {num})\")\n",
    "        ani = FuncAnimation(fig, update, frames=len(data), repeat=False)\n",
    "        temp_file = \"temp_animation.gif\"\n",
    "        ani.save(temp_file, writer='imagemagick')\n",
    "        img = Image.open(temp_file)\n",
    "        frames.append(np.array(img))\n",
    "        os.remove(temp_file)\n",
    "        plt.close(fig)\n",
    "    \n",
    "    # Generate 3D scatter plot if there are at least 3 numeric columns\n",
    "    if len(numeric_columns) >= 3:\n",
    "        fig = plt.figure(figsize=(10, 6))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.scatter(data[numeric_columns[0]], data[numeric_columns[1]], data[numeric_columns[2]])\n",
    "        ax.set_title('3D Scatter Plot')\n",
    "        ax.set_xlabel(numeric_columns[0])\n",
    "        ax.set_ylabel(numeric_columns[1])\n",
    "        ax.set_zlabel(numeric_columns[2])\n",
    "        buf = io.BytesIO()\n",
    "        fig.savefig(buf, format='png')\n",
    "        buf.seek(0)\n",
    "        img = Image.open(buf)\n",
    "        frames.append(np.array(img))\n",
    "        plt.close(fig)\n",
    "    \n",
    "    logging.info(f\"Generated {len(frames)} default frames\")\n",
    "    return frames\n",
    "\n",
    "def create_video_from_frames(frames, audio_file=None, video_file=\"final_video.mp4\"):\n",
    "    if not frames:\n",
    "        raise ValueError(\"No frames to create video from.\")\n",
    "    \n",
    "    logging.info(f\"Creating video from {len(frames)} frames\")\n",
    "    for i, frame in enumerate(frames):\n",
    "        logging.debug(f\"Frame {i} shape: {frame.shape}\")\n",
    "    video_clips = []\n",
    "    for frame in frames:\n",
    "        img_clip = ImageSequenceClip([frame], fps=1)  # 1 frame per second\n",
    "        img_clip = img_clip.set_duration(5)  # Each frame lasts 5 seconds\n",
    "        video_clips.append(img_clip)\n",
    "    \n",
    "    video = concatenate_videoclips(video_clips, method=\"compose\")\n",
    "    \n",
    "    if audio_file and os.path.isfile(audio_file):\n",
    "        audio = AudioFileClip(audio_file)\n",
    "        video = video.set_audio(audio)\n",
    "    \n",
    "    video.write_videofile(video_file, codec=\"libx264\", fps=24)\n",
    "    logging.info(f\"Video saved as {video_file}\")\n",
    "\n",
    "def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n",
    "    frames = generate_default_frames(data)\n",
    "    if not frames:\n",
    "        raise ValueError(\"No frames generated from data.\")\n",
    "    \n",
    "    if os.path.exists(title_image):\n",
    "        title_image_clip = Image.open(title_image)\n",
    "        title_image_clip = title_image_clip.convert(\"RGBA\")\n",
    "        title_image_clip = np.array(title_image_clip)\n",
    "        frames.insert(0, title_image_clip)\n",
    "    \n",
    "    create_video_from_frames(frames, audio_file)\n",
    "    print(\"Video successfully generated!\")\n",
    "\n",
    "def generate_narration(text, output_file=\"narration.mp3\"):\n",
    "    tts = gTTS(text=text, lang='en')\n",
    "    tts.save(output_file)\n",
    "    return output_file\n",
    "\n",
    "def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        logging.info(\"Loading and preprocessing data...\")\n",
    "        data = load_and_preprocess_data(file_path)\n",
    "        logging.debug(f\"Loaded Data: {data.head()}\")\n",
    "        \n",
    "        logging.info(\"Performing EDA...\")\n",
    "        eda_summary = perform_eda(data)\n",
    "        logging.debug(f\"EDA Summary: {eda_summary}\")\n",
    "        \n",
    "        logging.info(\"Analyzing the user's prompt...\")\n",
    "        insights = analyze_prompt_for_insights(prompt)\n",
    "        logging.debug(f\"Extracted insights: {insights}\")\n",
    "        \n",
    "        logging.info(\"Generating narration...\")\n",
    "        narration_text = f\"Here is the analysis based on the prompt: {prompt}. {insights}\"\n",
    "        narration_file = generate_narration(narration_text)\n",
    "        \n",
    "        logging.info(\"Creating the infographic video...\")\n",
    "        generate_infographic_video(data, insights, audio_file=narration_file)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "    except FileNotFoundError as fnf_error:\n",
    "        logging.error(f\"File not found: {fnf_error}\")\n",
    "        raise\n",
    "    except pd.errors.ParserError as parser_error:\n",
    "        logging.error(f\"Error parsing the file: {parser_error}\")\n",
    "        raise\n",
    "    except TypeError as type_error:\n",
    "        logging.error(f\"Type error: {type_error}\")\n",
    "        raise\n",
    "    except ValueError as value_error:\n",
    "        logging.error(f\"Value error: {value_error}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An unexpected error occurred: {e}\")\n",
    "        raise\n",
    "\n",
    "# Example usage:\n",
    "file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n",
    "prompt = \"Analyze the country and region data\"\n",
    "audio_file = \"/kaggle/working/file.mp3\"\n",
    "title_image = \"/kaggle/working/title_screen.png\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    raise FileNotFoundError(f\"Data file not found: {file_path}\")\n",
    "if not os.path.exists(audio_file):\n",
    "    raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n",
    "if not os.path.exists(title_image):\n",
    "    raise FileNotFoundError(f\"Title image not found: {title_image}\")\n",
    "\n",
    "data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install plotly moviepy gtts\n",
    "\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "from moviepy.editor import ImageSequenceClip, concatenate_videoclips, AudioFileClip\n",
    "from gtts import gTTS\n",
    "\n",
    "def generate_frames(data, chart_type, output_dir=\"frames\"):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    frames = []\n",
    "    for date in data['date'].unique():\n",
    "        filtered_data = data[data['date'] == date]\n",
    "        if chart_type == 'bar':\n",
    "            fig = px.bar(filtered_data, x='category', y='value', title=f\"Bar Chart - {date}\")\n",
    "        elif chart_type == 'pie':\n",
    "            fig = px.pie(filtered_data, values='value', names='category', title=f\"Pie Chart - {date}\")\n",
    "        elif chart_type == 'scatter':\n",
    "            fig = px.scatter(filtered_data, x='x', y='y', size='value', color='category', title=f\"Scatter Plot - {date}\")\n",
    "        else:\n",
    "            raise ValueError(\"Invalid chart type\")\n",
    "        \n",
    "        frame_path = os.path.join(output_dir, f\"{chart_type}_{date}.png\")\n",
    "        fig.write_image(frame_path)\n",
    "        frames.append(frame_path)\n",
    "    \n",
    "    return frames\n",
    "\n",
    "def generate_video_from_frames(frames, output_file=\"animation.mp4\", fps=1):\n",
    "    clip = ImageSequenceClip(frames, fps=fps)\n",
    "    clip.write_videofile(output_file, codec=\"libx264\")\n",
    "    return output_file\n",
    "\n",
    "def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n",
    "    logging.info(\"Checking data columns for required visualizations\")\n",
    "    video_files = []\n",
    "    \n",
    "    # Check if required columns are present for each visualization\n",
    "    video_files = generate_videos_if_needed(data)\n",
    "    \n",
    "    if not video_files:\n",
    "        logging.error(\"No video files generated from data. Check if the data has the required columns.\")\n",
    "        raise ValueError(\"No video files generated from data.\")\n",
    "    \n",
    "    logging.info(\"Combining video files into a single video\")\n",
    "    video_clips = [VideoFileClip(video_file) for video_file in video_files]\n",
    "    \n",
    "    if os.path.exists(title_image):\n",
    "        title_clip = VideoFileClip(title_image).set_duration(5)\n",
    "        video_clips.insert(0, title_clip)\n",
    "    \n",
    "    final_video = concatenate_videoclips(video_clips, method=\"compose\")\n",
    "    \n",
    "    if audio_file and os.path.isfile(audio_file):\n",
    "        audio = AudioFileClip(audio_file)\n",
    "        final_video = final_video.set_audio(audio)\n",
    "    \n",
    "    final_video.write_videofile(\"final_video.mp4\", codec=\"libx264\", fps=24)\n",
    "    logging.info(\"Final video saved as final_video.mp4\")\n",
    "\n",
    "def generate_videos_if_needed(data):\n",
    "    video_files = []\n",
    "    if {'category', 'value', 'date'}.issubset(data.columns):\n",
    "        logging.info(\"Data contains required columns for bar and pie charts\")\n",
    "        try:\n",
    "            bar_frames = generate_frames(data, 'bar')\n",
    "            video_files.append(generate_video_from_frames(bar_frames, \"animated_bar_chart.mp4\"))\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to generate animated bar chart: {e}\")\n",
    "        try:\n",
    "            pie_frames = generate_frames(data, 'pie')\n",
    "            video_files.append(generate_video_from_frames(pie_frames, \"animated_pie_chart.mp4\"))\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to generate animated pie chart: {e}\")\n",
    "    if {'x', 'y', 'value', 'date'}.issubset(data.columns):\n",
    "        logging.info(\"Data contains required columns for scatter plot\")\n",
    "        try:\n",
    "            scatter_frames = generate_frames(data, 'scatter')\n",
    "            video_files.append(generate_video_from_frames(scatter_frames, \"animated_scatter_plot.mp4\"))\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to generate animated scatter plot: {e}\")\n",
    "    return video_files\n",
    "\n",
    "def generate_narration(text, output_file=\"narration.mp3\"):\n",
    "    tts = gTTS(text=text, lang='en')\n",
    "    tts.save(output_file)\n",
    "    return output_file\n",
    "\n",
    "def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        logging.info(\"Loading and preprocessing data...\")\n",
    "        data = pd.read_csv(file_path)\n",
    "        logging.debug(f\"Loaded Data: {data.head()}\")\n",
    "        \n",
    "        logging.info(\"Performing EDA...\")\n",
    "        eda_summary = data.describe()\n",
    "        logging.debug(f\"EDA Summary: {eda_summary}\")\n",
    "        \n",
    "        logging.info(\"Analyzing the user's prompt...\")\n",
    "        insights = f\"Insights based on the prompt: {prompt}\"\n",
    "        logging.debug(f\"Extracted insights: {insights}\")\n",
    "        \n",
    "        logging.info(\"Generating narration...\")\n",
    "        narration_text = f\"Here is the analysis based on the prompt: {prompt}. {insights}\"\n",
    "        narration_file = generate_narration(narration_text)\n",
    "        \n",
    "        logging.info(\"Creating the infographic video...\")\n",
    "        generate_infographic_video(data, insights, audio_file=narration_file)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "    except FileNotFoundError as fnf_error:\n",
    "        logging.error(f\"File not found: {fnf_error}\")\n",
    "        raise\n",
    "    except pd.errors.ParserError as parser_error:\n",
    "        logging.error(f\"Error parsing the file: {parser_error}\")\n",
    "        raise\n",
    "    except TypeError as type_error:\n",
    "        logging.error(f\"Type error: {type_error}\")\n",
    "        raise\n",
    "    except ValueError as value_error:\n",
    "        logging.error(f\"Value error: {value_error}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An unexpected error occurred: {e}\")\n",
    "        raise\n",
    "\n",
    "# Example usage:\n",
    "file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n",
    "prompt = \"Analyze the country and region data\"\n",
    "audio_file = \"/kaggle/working/file.mp3\"\n",
    "title_image = \"/kaggle/working/title_screen.png\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    raise FileNotFoundError(f\"Data file not found: {file_path}\")\n",
    "if not os.path.exists(audio_file):\n",
    "    raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n",
    "if not os.path.exists(title_image):\n",
    "    raise FileNotFoundError(f\"Title image not found: {title_image}\")\n",
    "\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "required_columns = [{'category', 'value', 'date'}, {'x', 'y', 'value', 'date'}]\n",
    "if not any(columns.issubset(data.columns) for columns in required_columns):\n",
    "    raise ValueError(\"Data does not contain the required columns for generating visualizations.\")\n",
    "\n",
    "data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def generate_visualizations(data, insights):\n",
    "    try:\n",
    "        logging.info(\"Generating visualizations\")\n",
    "        if data.empty:\n",
    "            raise ValueError(\"Data is empty.\")\n",
    "        if not insights:\n",
    "            raise ValueError(\"No insights available to generate visualizations.\")\n",
    "        \n",
    "        visuals = []\n",
    "        \n",
    "        if 'Date' in data.columns or 'Datetime' in data.columns:\n",
    "            time_column = 'Date' if 'Date' in data.columns else 'Datetime'\n",
    "            numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "            if len(numeric_columns) > 0:\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                for col in numeric_columns:\n",
    "                    plt.plot(data[time_column], data[col], label=col)\n",
    "                plt.title(f\"Time Series Plot for {', '.join(numeric_columns)}\")\n",
    "                plt.xlabel('Time')\n",
    "                plt.ylabel('Values')\n",
    "                plt.xticks(rotation=45)\n",
    "                plt.legend()\n",
    "                visuals.append(plt)\n",
    "        \n",
    "        if data.select_dtypes(include=['float64', 'int64']).shape[1] > 1:\n",
    "            corr_matrix = data.corr()\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "            plt.title('Correlation Matrix')\n",
    "            visuals.append(plt)\n",
    "        \n",
    "        categorical_columns = data.select_dtypes(include=['object', 'category']).columns\n",
    "        if len(categorical_columns) > 0:\n",
    "            for col in categorical_columns:\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                sns.countplot(x=col, data=data)\n",
    "                plt.title(f\"Distribution of {col}\")\n",
    "                visuals.append(plt)\n",
    "        \n",
    "        numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "        if len(numeric_columns) > 1:\n",
    "            sns.pairplot(data[numeric_columns])\n",
    "            plt.suptitle('Pairwise Relationships')\n",
    "            visuals.append(plt)\n",
    "        \n",
    "        if not visuals:\n",
    "            return None\n",
    "        \n",
    "        logging.info(f\"Generated {len(visuals)} visualizations\")\n",
    "        return visuals\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error generating visualizations: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install plotly moviepy gtts transformers spacy\n",
    "\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "from moviepy.editor import ImageSequenceClip, concatenate_videoclips, AudioFileClip, VideoFileClip\n",
    "from gtts import gTTS\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "import spacy\n",
    "import re\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Setting up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Load spaCy model for NER\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def load_and_preprocess_data(file_path):\n",
    "    try:\n",
    "        logging.info(f\"Loading data from {file_path}\")\n",
    "        # Load data\n",
    "        if file_path.endswith('.csv'):\n",
    "            data = pd.read_csv(file_path)\n",
    "        elif file_path.endswith('.xlsx'):\n",
    "            data = pd.read_excel(file_path)\n",
    "        elif file_path.endswith('.txt'):\n",
    "            data = pd.read_csv(file_path, delimiter='\\t')\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file format.\")\n",
    "        \n",
    "        logging.info(\"Data loaded successfully\")\n",
    "        \n",
    "        # Detect and convert data types\n",
    "        for col in data.columns:\n",
    "            try:\n",
    "                data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "            except ValueError:\n",
    "                pass\n",
    "        \n",
    "        # Handle missing values\n",
    "        data.fillna(data.mean(), inplace=True)\n",
    "        \n",
    "        # Handle categorical data\n",
    "        categorical_cols = data.select_dtypes(include=['object']).columns\n",
    "        data = pd.get_dummies(data, columns=categorical_cols, drop_first=True)\n",
    "        \n",
    "        # Normalize numeric data\n",
    "        numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "        scaler = StandardScaler()\n",
    "        data[numeric_cols] = scaler.fit_transform(data[numeric_cols])\n",
    "        \n",
    "        logging.info(\"Data preprocessing completed\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading and preprocessing data: {e}\")\n",
    "        raise\n",
    "\n",
    "def generate_frames(data, chart_type, output_dir=\"frames\"):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    frames = []\n",
    "    for date in data['date'].unique():\n",
    "        filtered_data = data[data['date'] == date]\n",
    "        if chart_type == 'bar':\n",
    "            fig = px.bar(filtered_data, x='category', y='value', title=f\"Bar Chart - {date}\")\n",
    "        elif chart_type == 'pie':\n",
    "            fig = px.pie(filtered_data, values='value', names='category', title=f\"Pie Chart - {date}\")\n",
    "        elif chart_type == 'scatter':\n",
    "            fig = px.scatter(filtered_data, x='x', y='y', size='value', color='category', title=f\"Scatter Plot - {date}\")\n",
    "        else:\n",
    "            raise ValueError(\"Invalid chart type\")\n",
    "        \n",
    "        frame_path = os.path.join(output_dir, f\"{chart_type}_{date}.png\")\n",
    "        fig.write_image(frame_path)\n",
    "        frames.append(frame_path)\n",
    "    \n",
    "    return frames\n",
    "\n",
    "def generate_video_from_frames(frames, output_file=\"animation.mp4\", fps=1):\n",
    "    clip = ImageSequenceClip(frames, fps=fps)\n",
    "    clip.write_videofile(output_file, codec=\"libx264\")\n",
    "    return output_file\n",
    "\n",
    "def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n",
    "    logging.info(\"Checking data columns for required visualizations\")\n",
    "    video_files = []\n",
    "    \n",
    "    # Check if required columns are present for each visualization\n",
    "    video_files = generate_videos_if_needed(data)\n",
    "    \n",
    "    if not video_files:\n",
    "        logging.error(\"No video files generated from data. Check if the data has the required columns.\")\n",
    "        raise ValueError(\"No video files generated from data.\")\n",
    "    \n",
    "    logging.info(\"Combining video files into a single video\")\n",
    "    video_clips = [VideoFileClip(video_file) for video_file in video_files]\n",
    "    \n",
    "    if os.path.exists(title_image):\n",
    "        title_clip = VideoFileClip(title_image).set_duration(5)\n",
    "        video_clips.insert(0, title_clip)\n",
    "    \n",
    "    final_video = concatenate_videoclips(video_clips, method=\"compose\")\n",
    "    \n",
    "    if audio_file and os.path.isfile(audio_file):\n",
    "        audio = AudioFileClip(audio_file)\n",
    "        final_video = final_video.set_audio(audio)\n",
    "    \n",
    "    final_video.write_videofile(\"final_video.mp4\", codec=\"libx264\", fps=24)\n",
    "    logging.info(\"Final video saved as final_video.mp4\")\n",
    "\n",
    "def generate_videos_if_needed(data):\n",
    "    video_files = []\n",
    "    if {'category', 'value', 'date'}.issubset(data.columns):\n",
    "        logging.info(\"Data contains required columns for bar and pie charts\")\n",
    "        try:\n",
    "            bar_frames = generate_frames(data, 'bar')\n",
    "            video_files.append(generate_video_from_frames(bar_frames, \"animated_bar_chart.mp4\"))\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to generate animated bar chart: {e}\")\n",
    "        try:\n",
    "            pie_frames = generate_frames(data, 'pie')\n",
    "            video_files.append(generate_video_from_frames(pie_frames, \"animated_pie_chart.mp4\"))\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to generate animated pie chart: {e}\")\n",
    "    if {'x', 'y', 'value', 'date'}.issubset(data.columns):\n",
    "        logging.info(\"Data contains required columns for scatter plot\")\n",
    "        try:\n",
    "            scatter_frames = generate_frames(data, 'scatter')\n",
    "            video_files.append(generate_video_from_frames(scatter_frames, \"animated_scatter_plot.mp4\"))\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to generate animated scatter plot: {e}\")\n",
    "    return video_files\n",
    "\n",
    "def generate_narration(text, output_file=\"narration.mp3\"):\n",
    "    tts = gTTS(text=text, lang='en')\n",
    "    tts.save(output_file)\n",
    "    return output_file\n",
    "\n",
    "def perform_eda(data):\n",
    "    try:\n",
    "        eda_summary = {\n",
    "            \"shape\": data.shape,\n",
    "            \"columns\": data.columns.tolist(),\n",
    "            \"dtypes\": data.dtypes.tolist(),\n",
    "            \"null_counts\": data.isnull().sum().tolist(),\n",
    "            \"describe\": data.describe().to_dict()\n",
    "        }\n",
    "        return eda_summary\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error performing EDA: {e}\")\n",
    "        raise\n",
    "\n",
    "def analyze_prompt_for_insights(prompt, model_name=\"facebook/bart-large\"):\n",
    "    try:\n",
    "        logging.info(\"Analyzing prompt for insights\")\n",
    "        tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "        model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "        \n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        input_ids = inputs.input_ids\n",
    "        attention_mask = inputs.attention_mask\n",
    "        \n",
    "        outputs = model.generate(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_length=200,\n",
    "            num_return_sequences=1,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            top_k=50,\n",
    "            no_repeat_ngram_size=2,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "        \n",
    "        generated_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "        insights = extract_insights_from_text(generated_text)\n",
    "        \n",
    "        insights_list = [key for key, value in insights.items() if value]\n",
    "        if not insights_list:\n",
    "            raise ValueError(\"No insights could be extracted from the provided prompt.\")\n",
    "        \n",
    "        logging.info(f\"Insights extracted: {insights_list}\")\n",
    "        return insights_list\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in analyzing prompt for insights: {e}\")\n",
    "        return []\n",
    "\n",
    "def extract_insights_from_text(text):\n",
    "    possible_insights = [\"trend\", \"comparison\", \"distribution\", \"correlation\", \"pattern\", \"anomaly\", \"outlier\", \"relationship\", \"performance\", \"growth\"]\n",
    "    insights = {insight: False for insight in possible_insights}\n",
    "    text = text.lower()\n",
    "    \n",
    "    for insight in possible_insights:\n",
    "        if re.search(r'\\b' + re.escape(insight) + r'\\b', text):\n",
    "            insights[insight] = True\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    insights['entities'] = entities\n",
    "    \n",
    "    return insights\n",
    "\n",
    "def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        logging.info(\"Loading and preprocessing data...\")\n",
    "        data = load_and_preprocess_data(file_path)\n",
    "        logging.debug(f\"Loaded Data: {data.head()}\")\n",
    "        \n",
    "        logging.info(\"Performing EDA...\")\n",
    "        eda_summary = perform_eda(data)\n",
    "        logging.debug(f\"EDA Summary: {eda_summary}\")\n",
    "        \n",
    "        logging.info(\"Analyzing the user's prompt...\")\n",
    "        insights = analyze_prompt_for_insights(prompt)\n",
    "        logging.debug(f\"Extracted insights: {insights}\")\n",
    "        \n",
    "        logging.info(\"Generating narration...\")\n",
    "        narration_text = f\"Here is the analysis based on the prompt: {prompt}. {insights}\"\n",
    "        narration_file = generate_narration(narration_text)\n",
    "        \n",
    "        logging.info(\"Creating the infographic video...\")\n",
    "        generate_infographic_video(data, insights, audio_file=narration_file)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "    except FileNotFoundError as fnf_error:\n",
    "        logging.error(f\"File not found: {fnf_error}\")\n",
    "        raise\n",
    "    except pd.errors.ParserError as parser_error:\n",
    "        logging.error(f\"Error parsing the file: {parser_error}\")\n",
    "        raise\n",
    "    except TypeError as type_error:\n",
    "        logging.error(f\"Type error: {type_error}\")\n",
    "        raise\n",
    "    except ValueError as value_error:\n",
    "        logging.error(f\"Value error: {value_error}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An unexpected error occurred: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "file_path = '/kaggle/input/model-dataset-new-1/2015.csv'\n",
    "prompt = \"Analyze the country and region data\"\n",
    "audio_file = \"/kaggle/working/narration.mp3\"\n",
    "title_image = \"/kaggle/working/title_screen.png\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    raise FileNotFoundError(f\"Data file not found: {file_path}\")\n",
    "if not os.path.exists(audio_file):\n",
    "    raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n",
    "if not os.path.exists(title_image):\n",
    "    raise FileNotFoundError(f\"Title image not found: {title_image}\")\n",
    "\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Print the first few rows and columns in the data for debugging purposes\n",
    "print(\"First few rows of the data:\\n\", data.head())\n",
    "print(\"Columns in the data:\", data.columns)\n",
    "\n",
    "required_columns = [{'category', 'value', 'date'}, {'x', 'y', 'value', 'date'}]\n",
    "missing_columns = [columns for columns in required_columns if not columns.issubset(data.columns)]\n",
    "\n",
    "if missing_columns:\n",
    "    raise ValueError(f\"Data does not contain the required columns for generating visualizations. Missing columns: {missing_columns}\")\n",
    "\n",
    "data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "from moviepy.editor import ImageSequenceClip, concatenate_videoclips, AudioFileClip, VideoFileClip\n",
    "from gtts import gTTS\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "import spacy\n",
    "import re\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Setting up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Load spaCy model for NER\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def load_and_preprocess_data(file_path):\n",
    "    try:\n",
    "        logging.info(f\"Loading data from {file_path}\")\n",
    "        # Load data\n",
    "        if file_path.endswith('.csv'):\n",
    "            data = pd.read_csv(file_path)\n",
    "        elif file_path.endswith('.xlsx'):\n",
    "            data = pd.read_excel(file_path)\n",
    "        elif file_path.endswith('.txt'):\n",
    "            data = pd.read_csv(file_path, delimiter='\\t')\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file format.\")\n",
    "        \n",
    "        logging.info(\"Data loaded successfully\")\n",
    "        \n",
    "        # Detect and convert data types\n",
    "        for col in data.columns:\n",
    "            try:\n",
    "                data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "            except ValueError:\n",
    "                pass\n",
    "        \n",
    "        # Handle missing values\n",
    "        data.fillna(data.mean(), inplace=True)\n",
    "        \n",
    "        # Handle categorical data\n",
    "        categorical_cols = data.select_dtypes(include=['object']).columns\n",
    "        data = pd.get_dummies(data, columns=categorical_cols, drop_first=True)\n",
    "        \n",
    "        # Normalize numeric data\n",
    "        numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "        scaler = StandardScaler()\n",
    "        data[numeric_cols] = scaler.fit_transform(data[numeric_cols])\n",
    "        \n",
    "        logging.info(\"Data preprocessing completed\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading and preprocessing data: {e}\")\n",
    "        raise\n",
    "\n",
    "def infer_columns(data):\n",
    "    column_mapping = {}\n",
    "    possible_columns = {\n",
    "        'category': ['category', 'type', 'class', 'label', 'country', 'region'],\n",
    "        'value': ['value', 'amount', 'score', 'total', 'family', 'generosity'],\n",
    "        'date': ['date', 'time', 'year', 'month', 'day'],\n",
    "        'x': ['x', 'longitude', 'lat', 'latitude'],\n",
    "        'y': ['y', 'latitude', 'long', 'longitude']\n",
    "    }\n",
    "    \n",
    "    logging.info(f\"Data columns: {data.columns.tolist()}\")\n",
    "    for key, patterns in possible_columns.items():\n",
    "        for pattern in patterns:\n",
    "            potential_cols = [col for col in data.columns if re.search(pattern, col, re.IGNORECASE)]\n",
    "            if potential_cols:\n",
    "                column_mapping[key] = potential_cols[0]\n",
    "                break\n",
    "    \n",
    "    # If any required column is missing, attempt to infer it\n",
    "    if 'date' not in column_mapping:\n",
    "        data['date'] = pd.date_range(start='1/1/2020', periods=len(data), freq='D')\n",
    "        column_mapping['date'] = 'date'\n",
    "    \n",
    "    if 'value' not in column_mapping:\n",
    "        numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "        if len(numeric_cols) > 0:\n",
    "            column_mapping['value'] = numeric_cols[0]\n",
    "        else:\n",
    "            raise ValueError(\"Cannot infer 'value' column.\")\n",
    "    \n",
    "    if 'category' not in column_mapping:\n",
    "        categorical_cols = data.select_dtypes(include=['object']).columns\n",
    "        if len(categorical_cols) > 0:\n",
    "            column_mapping['category'] = categorical_cols[0]\n",
    "        else:\n",
    "            non_numeric_cols = data.select_dtypes(exclude=['float64', 'int64']).columns\n",
    "            if len(non_numeric_cols) > 0:\n",
    "                column_mapping['category'] = non_numeric_cols[0]\n",
    "            else:\n",
    "                raise ValueError(\"Cannot infer 'category' column.\")\n",
    "    \n",
    "    return column_mapping\n",
    "\n",
    "def generate_frames(data, chart_type, column_mapping, output_dir=\"frames\"):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    frames = []\n",
    "    for date in data[column_mapping['date']].unique():\n",
    "        filtered_data = data[data[column_mapping['date']] == date]\n",
    "        if chart_type == 'bar':\n",
    "            fig = px.bar(filtered_data, x=column_mapping['category'], y=column_mapping['value'], title=f\"Bar Chart - {date}\")\n",
    "        elif chart_type == 'pie':\n",
    "            fig = px.pie(filtered_data, values=column_mapping['value'], names=column_mapping['category'], title=f\"Pie Chart - {date}\")\n",
    "        elif chart_type == 'scatter':\n",
    "            fig = px.scatter(filtered_data, x=column_mapping['x'], y=column_mapping['y'], size=column_mapping['value'], color=column_mapping['category'], title=f\"Scatter Plot - {date}\")\n",
    "        else:\n",
    "            raise ValueError(\"Invalid chart type\")\n",
    "        \n",
    "        frame_path = os.path.join(output_dir, f\"{chart_type}_{date}.png\")\n",
    "        fig.write_image(frame_path)\n",
    "        frames.append(frame_path)\n",
    "    \n",
    "    return frames\n",
    "\n",
    "def generate_video_from_frames(frames, output_file=\"animation.mp4\", fps=1):\n",
    "    clip = ImageSequenceClip(frames, fps=fps)\n",
    "    clip.write_videofile(output_file, codec=\"libx264\")\n",
    "    return output_file\n",
    "\n",
    "def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n",
    "    logging.info(\"Checking data columns for required visualizations\")\n",
    "    video_files = []\n",
    "    \n",
    "    # Check if required columns are present for each visualization\n",
    "    video_files = generate_videos_if_needed(data)\n",
    "    \n",
    "    if not video_files:\n",
    "        logging.error(\"No video files generated from data. Check if the data has the required columns.\")\n",
    "        logging.error(f\"Column mapping: {column_mapping}\")\n",
    "        logging.error(f\"Required columns: {required_columns}\")\n",
    "        raise ValueError(\"No video files generated from data.\")\n",
    "    \n",
    "    logging.info(\"Combining video files into a single video\")\n",
    "    video_clips = [VideoFileClip(video_file) for video_file in video_files]\n",
    "    \n",
    "    if os.path.exists(title_image):\n",
    "        title_clip = VideoFileClip(title_image).set_duration(5)\n",
    "        video_clips.insert(0, title_clip)\n",
    "    \n",
    "    final_video = concatenate_videoclips(video_clips, method=\"compose\")\n",
    "    \n",
    "    if audio_file and os.path.isfile(audio_file):\n",
    "        audio = AudioFileClip(audio_file)\n",
    "        final_video = final_video.set_audio(audio)\n",
    "    \n",
    "    final_video.write_videofile(\"final_video.mp4\", codec=\"libx264\", fps=24)\n",
    "    logging.info(\"Final video saved as final_video.mp4\")\n",
    "\n",
    "def generate_videos_if_needed(data):\n",
    "    video_files = []\n",
    "    column_mapping = infer_columns(data)\n",
    "    required_columns = {'category', 'value', 'date'}\n",
    "    if not required_columns.issubset(column_mapping.keys()):\n",
    "        logging.error(f\"Missing required columns: {required_columns - column_mapping.keys()}\")\n",
    "        raise ValueError(f\"Missing required columns: {required_columns - column_mapping.keys()}\")\n",
    "\n",
    "    if required_columns.issubset(column_mapping.keys()):\n",
    "        logging.info(\"Data contains required columns for bar and pie charts\")\n",
    "        try:\n",
    "            bar_frames = generate_frames(data, 'bar', column_mapping)\n",
    "            video_files.append(generate_video_from_frames(bar_frames, \"animated_bar_chart.mp4\"))\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to generate animated bar chart: {e}\")\n",
    "        try:\n",
    "            pie_frames = generate_frames(data, 'pie', column_mapping)\n",
    "            video_files.append(generate_video_from_frames(pie_frames, \"animated_pie_chart.mp4\"))\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to generate animated pie chart: {e}\")\n",
    "    if {'x', 'y', 'value', 'date'}.issubset(column_mapping.keys()):\n",
    "        logging.info(\"Data contains required columns for scatter plot\")\n",
    "        try:\n",
    "            scatter_frames = generate_frames(data, 'scatter', column_mapping)\n",
    "            video_files.append(generate_video_from_frames(scatter_frames, \"animated_scatter_plot.mp4\"))\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to generate animated scatter plot: {e}\")\n",
    "    return video_files\n",
    "\n",
    "def generate_narration(text, output_file=\"narration.mp3\"):\n",
    "    tts = gTTS(text=text, lang='en')\n",
    "    tts.save(output_file)\n",
    "    return output_file\n",
    "\n",
    "def perform_eda(data):\n",
    "    try:\n",
    "        eda_summary = {\n",
    "            \"shape\": data.shape,\n",
    "            \"columns\": data.columns.tolist(),\n",
    "            \"dtypes\": data.dtypes.tolist(),\n",
    "            \"null_counts\": data.isnull().sum().tolist(),\n",
    "            \"describe\": data.describe().to_dict()\n",
    "        }\n",
    "        return eda_summary\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error performing EDA: {e}\")\n",
    "        raise\n",
    "\n",
    "def analyze_prompt_for_insights(prompt, model_name=\"facebook/bart-large\"):\n",
    "    try:\n",
    "        logging.info(\"Analyzing prompt for insights\")\n",
    "        tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "        model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "        \n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        input_ids = inputs.input_ids\n",
    "        attention_mask = inputs.attention_mask\n",
    "        \n",
    "        outputs = model.generate(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_length=200,\n",
    "            num_return_sequences=1,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            top_k=50,\n",
    "            no_repeat_ngram_size=2,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "        \n",
    "        generated_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "        insights = extract_insights_from_text(generated_text)\n",
    "        \n",
    "        insights_list = [key for key, value in insights.items() if value]\n",
    "        if not insights_list:\n",
    "            raise ValueError(\"No insights could be extracted from the provided prompt.\")\n",
    "        \n",
    "        logging.info(f\"Insights extracted: {insights_list}\")\n",
    "        return insights_list\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in analyzing prompt for insights: {e}\")\n",
    "        return []\n",
    "\n",
    "def extract_insights_from_text(text):\n",
    "    possible_insights = [\"trend\", \"comparison\", \"distribution\", \"correlation\", \"pattern\", \"anomaly\", \"outlier\", \"relationship\", \"performance\", \"growth\"]\n",
    "    insights = {insight: False for insight in possible_insights}\n",
    "    text = text.lower()\n",
    "    \n",
    "    for insight in possible_insights:\n",
    "        if re.search(r'\\b' + re.escape(insight) + r'\\b', text):\n",
    "            insights[insight] = True\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    insights['entities'] = entities\n",
    "    \n",
    "    return insights\n",
    "\n",
    "def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        logging.info(\"Loading and preprocessing data...\")\n",
    "        data = load_and_preprocess_data(file_path)\n",
    "        logging.debug(f\"Loaded Data: {data.head()}\")\n",
    "        \n",
    "        logging.info(\"Performing EDA...\")\n",
    "        eda_summary = perform_eda(data)\n",
    "        logging.debug(f\"EDA Summary: {eda_summary}\")\n",
    "        \n",
    "        logging.info(\"Analyzing the user's prompt...\")\n",
    "        insights = analyze_prompt_for_insights(prompt)\n",
    "        logging.debug(f\"Extracted insights: {insights}\")\n",
    "        \n",
    "        logging.info(\"Generating narration...\")\n",
    "        narration_text = f\"Here is the analysis based on the prompt: {prompt}. {insights}\"\n",
    "        narration_file = generate_narration(narration_text)\n",
    "        \n",
    "        logging.info(\"Creating the infographic video...\")\n",
    "        generate_infographic_video(data, insights, audio_file=narration_file)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "    except FileNotFoundError as fnf_error:\n",
    "        logging.error(f\"File not found: {fnf_error}\")\n",
    "        raise\n",
    "    except pd.errors.ParserError as parser_error:\n",
    "        logging.error(f\"Error parsing the file: {parser_error}\")\n",
    "        raise\n",
    "    except TypeError as type_error:\n",
    "        logging.error(f\"Type error: {type_error}\")\n",
    "        raise\n",
    "    except ValueError as value_error:\n",
    "        logging.error(f\"Value error: {value_error}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An unexpected error occurred: {e}\")\n",
    "        raise\n",
    "\n",
    "# Example usage:\n",
    "file_path = '/kaggle/input/model-dataset-new-1/2017.csv'\n",
    "prompt = \"compare the family and generosity in an interactive video format\"\n",
    "audio_file = \"/kaggle/working/narration.mp3\"\n",
    "title_image = \"/kaggle/working/title_screen.png\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    raise FileNotFoundError(f\"Data file not found: {file_path}\")\n",
    "if not os.path.exists(audio_file):\n",
    "    raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n",
    "if not os.path.exists(title_image):\n",
    "    raise FileNotFoundError(f\"Title image not found: {title_image}\")\n",
    "\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Print the first few rows and columns in the data for debugging purposes\n",
    "print(\"First few rows of the data:\\n\", data.head())\n",
    "print(\"Columns in the data:\", data.columns)\n",
    "\n",
    "data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "from moviepy.editor import ImageSequenceClip, concatenate_videoclips, AudioFileClip, VideoFileClip\n",
    "from gtts import gTTS\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "import spacy\n",
    "import re\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Ensure all required packages are installed\n",
    "%pip install plotly pandas moviepy gtts transformers spacy scikit-learn\n",
    "%pip install torch  # Required for transformers\n",
    "%pip install openpyxl  # Required for reading .xlsx files with pandas\n",
    "%pip install kaleido  # Required for saving plotly figures as images\n",
    "\n",
    "# Setting up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Load spaCy model for NER\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def load_and_preprocess_data(file_path):\n",
    "    try:\n",
    "        logging.info(f\"Loading data from {file_path}\")\n",
    "        print(f\"Loading data from {file_path}\")\n",
    "        # Load data\n",
    "        if file_path.endswith('.csv'):\n",
    "            data = pd.read_csv(file_path)\n",
    "        elif file_path.endswith('.xlsx'):\n",
    "            data = pd.read_excel(file_path)\n",
    "        elif file_path.endswith('.txt'):\n",
    "            data = pd.read_csv(file_path, delimiter='\\t')\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file format.\")\n",
    "        \n",
    "        logging.info(\"Data loaded successfully\")\n",
    "        print(\"Data loaded successfully\")\n",
    "        \n",
    "        # Detect and convert data types\n",
    "        for col in data.columns:\n",
    "            try:\n",
    "                data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "            except ValueError:\n",
    "                pass\n",
    "        \n",
    "        # Handle missing values\n",
    "        data.fillna(data.mean(), inplace=True)\n",
    "        \n",
    "        # Handle categorical data\n",
    "        categorical_cols = data.select_dtypes(include=['object']).columns\n",
    "        data = pd.get_dummies(data, columns=categorical_cols, drop_first=True)\n",
    "        \n",
    "        # Normalize numeric data\n",
    "        numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "        scaler = StandardScaler()\n",
    "        data[numeric_cols] = scaler.fit_transform(data[numeric_cols])\n",
    "        \n",
    "        logging.info(\"Data preprocessing completed\")\n",
    "        print(\"Data preprocessing completed\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading and preprocessing data: {e}\")\n",
    "        print(f\"Error loading and preprocessing data: {e}\")\n",
    "        raise\n",
    "\n",
    "def infer_columns(data):\n",
    "    try:\n",
    "        column_mapping = {}\n",
    "        possible_columns = {\n",
    "            'category': ['category', 'type', 'class', 'label', 'country', 'region'],\n",
    "            'value': ['value', 'amount', 'score', 'total', 'family', 'generosity'],\n",
    "            'date': ['date', 'time', 'year', 'month', 'day'],\n",
    "            'x': ['x', 'longitude', 'lat', 'latitude'],\n",
    "            'y': ['y', 'latitude', 'long', 'longitude']\n",
    "        }\n",
    "        \n",
    "        logging.info(f\"Data columns: {data.columns.tolist()}\")\n",
    "        print(f\"Data columns: {data.columns.tolist()}\")\n",
    "        for key, patterns in possible_columns.items():\n",
    "            for pattern in patterns:\n",
    "                potential_cols = [col for col in data.columns if re.search(pattern, col, re.IGNORECASE)]\n",
    "                if potential_cols:\n",
    "                    column_mapping[key] = potential_cols[0]\n",
    "                    break\n",
    "        \n",
    "        # If any required column is missing, attempt to infer it\n",
    "        if 'date' not in column_mapping:\n",
    "            data['date'] = pd.date_range(start='1/1/2020', periods=len(data), freq='D')\n",
    "            column_mapping['date'] = 'date'\n",
    "        \n",
    "        if 'value' not in column_mapping:\n",
    "            numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "            if len(numeric_cols) > 0:\n",
    "                column_mapping['value'] = numeric_cols[0]\n",
    "            else:\n",
    "                raise ValueError(\"Cannot infer 'value' column.\")\n",
    "        \n",
    "        if 'category' not in column_mapping:\n",
    "            categorical_cols = data.select_dtypes(include=['object']).columns\n",
    "            if len(categorical_cols) > 0:\n",
    "                column_mapping['category'] = categorical_cols[0]\n",
    "            else:\n",
    "                non_numeric_cols = data.select_dtypes(exclude=['float64', 'int64']).columns\n",
    "                if len(non_numeric_cols) > 0:\n",
    "                    column_mapping['category'] = non_numeric_cols[0]\n",
    "                else:\n",
    "                    raise ValueError(\"Cannot infer 'category' column.\")\n",
    "        \n",
    "        return column_mapping\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error inferring columns: {e}\")\n",
    "        print(f\"Error inferring columns: {e}\")\n",
    "        raise\n",
    "\n",
    "def generate_frames(data, chart_type, column_mapping, output_dir=\"frames\"):\n",
    "    try:\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        \n",
    "        frames = []\n",
    "        for date in data[column_mapping['date']].unique():\n",
    "            filtered_data = data[data[column_mapping['date']] == date]\n",
    "            if chart_type == 'bar':\n",
    "                fig = px.bar(filtered_data, x=column_mapping['category'], y=column_mapping['value'], title=f\"Bar Chart - {date}\")\n",
    "            elif chart_type == 'pie':\n",
    "                fig = px.pie(filtered_data, values=column_mapping['value'], names=column_mapping['category'], title=f\"Pie Chart - {date}\")\n",
    "            elif chart_type == 'scatter':\n",
    "                fig = px.scatter(filtered_data, x=column_mapping['x'], y=column_mapping['y'], size=column_mapping['value'], color=column_mapping['category'], title=f\"Scatter Plot - {date}\")\n",
    "            else:\n",
    "                raise ValueError(\"Invalid chart type\")\n",
    "            \n",
    "            frame_path = os.path.join(output_dir, f\"{chart_type}_{date}.png\")\n",
    "            fig.write_image(frame_path)\n",
    "            frames.append(frame_path)\n",
    "        \n",
    "        return frames\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error generating frames: {e}\")\n",
    "        print(f\"Error generating frames: {e}\")\n",
    "        raise\n",
    "\n",
    "def generate_video_from_frames(frames, output_file=\"animation.mp4\", fps=1):\n",
    "    try:\n",
    "        clip = ImageSequenceClip(frames, fps=fps)\n",
    "        clip.write_videofile(output_file, codec=\"libx264\")\n",
    "        return output_file\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error generating video from frames: {e}\")\n",
    "        print(f\"Error generating video from frames: {e}\")\n",
    "        raise\n",
    "\n",
    "def generate_infographic_video(data, insights, audio_file=None, title_image=\"title_screen.png\"):\n",
    "    try:\n",
    "        logging.info(\"Checking data columns for required visualizations\")\n",
    "        print(\"Checking data columns for required visualizations\")\n",
    "        column_mapping = infer_columns(data)\n",
    "        logging.debug(f\"Column mapping: {column_mapping}\")\n",
    "        print(f\"Column mapping: {column_mapping}\")\n",
    "        video_files = generate_videos_if_needed(data)\n",
    "        \n",
    "        if not video_files:\n",
    "            logging.error(\"No video files generated from data. Check if the data has the required columns.\")\n",
    "            print(\"No video files generated from data. Check if the data has the required columns.\")\n",
    "            raise ValueError(\"No video files generated from data.\")\n",
    "        \n",
    "        logging.info(\"Combining video files into a single video\")\n",
    "        print(\"Combining video files into a single video\")\n",
    "        video_clips = [VideoFileClip(video_file) for video_file in video_files]\n",
    "        \n",
    "        if os.path.exists(title_image):\n",
    "            title_clip = VideoFileClip(title_image).set_duration(5)\n",
    "            video_clips.insert(0, title_clip)\n",
    "        \n",
    "        final_video = concatenate_videoclips(video_clips, method=\"compose\")\n",
    "        \n",
    "        if audio_file and os.path.isfile(audio_file):\n",
    "            audio = AudioFileClip(audio_file)\n",
    "            final_video = final_video.set_audio(audio)\n",
    "        \n",
    "        final_video.write_videofile(\"final_video.mp4\", codec=\"libx264\", fps=24)\n",
    "        logging.info(\"Final video saved as final_video.mp4\")\n",
    "        print(\"Final video saved as final_video.mp4\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error generating infographic video: {e}\")\n",
    "        print(f\"Error generating infographic video: {e}\")\n",
    "        raise\n",
    "\n",
    "def generate_videos_if_needed(data):\n",
    "    try:\n",
    "        video_files = []\n",
    "        column_mapping = infer_columns(data)\n",
    "        required_columns = {'category', 'value', 'date'}\n",
    "        if not required_columns.issubset(column_mapping.keys()):\n",
    "            logging.error(f\"Missing required columns: {required_columns - column_mapping.keys()}\")\n",
    "            print(f\"Missing required columns: {required_columns - column_mapping.keys()}\")\n",
    "            raise ValueError(f\"Missing required columns: {required_columns - column_mapping.keys()}\")\n",
    "\n",
    "        if required_columns.issubset(column_mapping.keys()):\n",
    "            logging.info(\"Data contains required columns for bar and pie charts\")\n",
    "            print(\"Data contains required columns for bar and pie charts\")\n",
    "            try:\n",
    "                bar_frames = generate_frames(data, 'bar', column_mapping)\n",
    "                video_files.append(generate_video_from_frames(bar_frames, \"animated_bar_chart.mp4\"))\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Failed to generate animated bar chart: {e}\")\n",
    "                print(f\"Failed to generate animated bar chart: {e}\")\n",
    "            try:\n",
    "                pie_frames = generate_frames(data, 'pie', column_mapping)\n",
    "                video_files.append(generate_video_from_frames(pie_frames, \"animated_pie_chart.mp4\"))\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Failed to generate animated pie chart: {e}\")\n",
    "                print(f\"Failed to generate animated pie chart: {e}\")\n",
    "        if {'x', 'y', 'value', 'date'}.issubset(column_mapping.keys()):\n",
    "            logging.info(\"Data contains required columns for scatter plot\")\n",
    "            print(\"Data contains required columns for scatter plot\")\n",
    "            try:\n",
    "                scatter_frames = generate_frames(data, 'scatter', column_mapping)\n",
    "                video_files.append(generate_video_from_frames(scatter_frames, \"animated_scatter_plot.mp4\"))\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Failed to generate animated scatter plot: {e}\")\n",
    "                print(f\"Failed to generate animated scatter plot: {e}\")\n",
    "        return video_files\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error generating videos if needed: {e}\")\n",
    "        print(f\"Error generating videos if needed: {e}\")\n",
    "        raise\n",
    "\n",
    "def generate_narration(text, output_file=\"narration.mp3\"):\n",
    "    try:\n",
    "        tts = gTTS(text=text, lang='en')\n",
    "        tts.save(output_file)\n",
    "        return output_file\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error generating narration: {e}\")\n",
    "        print(f\"Error generating narration: {e}\")\n",
    "        raise\n",
    "\n",
    "def perform_eda(data):\n",
    "    try:\n",
    "        eda_summary = {\n",
    "            \"shape\": data.shape,\n",
    "            \"columns\": data.columns.tolist(),\n",
    "            \"dtypes\": data.dtypes.tolist(),\n",
    "            \"null_counts\": data.isnull().sum().tolist(),\n",
    "            \"describe\": data.describe().to_dict()\n",
    "        }\n",
    "        return eda_summary\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error performing EDA: {e}\")\n",
    "        print(f\"Error performing EDA: {e}\")\n",
    "        raise\n",
    "\n",
    "def analyze_prompt_for_insights(prompt, model_name=\"facebook/bart-large\"):\n",
    "    try:\n",
    "        logging.info(\"Analyzing prompt for insights\")\n",
    "        print(\"Analyzing prompt for insights\")\n",
    "        tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "        model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "        \n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        input_ids = inputs.input_ids\n",
    "        attention_mask = inputs.attention_mask\n",
    "        \n",
    "        outputs = model.generate(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_length=200,\n",
    "            num_return_sequences=1,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            top_k=50,\n",
    "            no_repeat_ngram_size=2,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "        \n",
    "        generated_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "        insights = extract_insights_from_text(generated_text)\n",
    "        \n",
    "        insights_list = [key for key, value in insights.items() if value]\n",
    "        if not insights_list:\n",
    "            raise ValueError(\"No insights could be extracted from the provided prompt.\")\n",
    "        \n",
    "        logging.info(f\"Insights extracted: {insights_list}\")\n",
    "        print(f\"Insights extracted: {insights_list}\")\n",
    "        return insights_list\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in analyzing prompt for insights: {e}\")\n",
    "        print(f\"Error in analyzing prompt for insights: {e}\")\n",
    "        return []\n",
    "\n",
    "def extract_insights_from_text(text):\n",
    "    try:\n",
    "        possible_insights = [\"trend\", \"comparison\", \"distribution\", \"correlation\", \"pattern\", \"anomaly\", \"outlier\", \"relationship\", \"performance\", \"growth\"]\n",
    "        insights = {insight: False for insight in possible_insights}\n",
    "        text = text.lower()\n",
    "        \n",
    "        for insight in possible_insights:\n",
    "            if re.search(r'\\b' + re.escape(insight) + r'\\b', text):\n",
    "                insights[insight] = True\n",
    "        \n",
    "        doc = nlp(text)\n",
    "        entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "        insights['entities'] = entities\n",
    "        \n",
    "        return insights\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error extracting insights from text: {e}\")\n",
    "        print(f\"Error extracting insights from text: {e}\")\n",
    "        raise\n",
    "\n",
    "def data_storytelling_pipeline(file_path, prompt, audio_file=None):\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        logging.info(\"Loading and preprocessing data...\")\n",
    "        print(\"Loading and preprocessing data...\")\n",
    "        data = load_and_preprocess_data(file_path)\n",
    "        logging.debug(f\"Loaded Data: {data.head()}\")\n",
    "        print(f\"Loaded Data: {data.head()}\")\n",
    "        \n",
    "        logging.info(\"Performing EDA...\")\n",
    "        print(\"Performing EDA...\")\n",
    "        eda_summary = perform_eda(data)\n",
    "        logging.debug(f\"EDA Summary: {eda_summary}\")\n",
    "        print(f\"EDA Summary: {eda_summary}\")\n",
    "        \n",
    "        logging.info(\"Analyzing the user's prompt...\")\n",
    "        print(\"Analyzing the user's prompt...\")\n",
    "        insights = analyze_prompt_for_insights(prompt)\n",
    "        logging.debug(f\"Extracted insights: {insights}\")\n",
    "        print(f\"Extracted insights: {insights}\")\n",
    "        \n",
    "        logging.info(\"Generating narration...\")\n",
    "        print(\"Generating narration...\")\n",
    "        narration_text = f\"Here is the analysis based on the prompt: {prompt}. {insights}\"\n",
    "        narration_file = generate_narration(narration_text)\n",
    "        \n",
    "        logging.info(\"Creating the infographic video...\")\n",
    "        print(\"Creating the infographic video...\")\n",
    "        generate_infographic_video(data, insights, audio_file=narration_file)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        logging.info(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n",
    "        print(f\"Pipeline completed successfully in {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "    except FileNotFoundError as fnf_error:\n",
    "        logging.error(f\"File not found: {fnf_error}\")\n",
    "        print(f\"File not found: {fnf_error}\")\n",
    "        raise\n",
    "    except pd.errors.ParserError as parser_error:\n",
    "        logging.error(f\"Error parsing the file: {parser_error}\")\n",
    "        print(f\"Error parsing the file: {parser_error}\")\n",
    "        raise\n",
    "    except TypeError as type_error:\n",
    "        logging.error(f\"Type error: {type_error}\")\n",
    "        print(f\"Type error: {type_error}\")\n",
    "        raise\n",
    "    except ValueError as value_error:\n",
    "        logging.error(f\"Value error: {value_error}\")\n",
    "        print(f\"Value error: {value_error}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An unexpected error occurred: {e}\")\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        raise\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    raise FileNotFoundError(f\"Data file not found: {file_path}\")\n",
    "if audio_file and not os.path.exists(audio_file):\n",
    "    raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n",
    "if title_image and not os.path.exists(title_image):\n",
    "    raise FileNotFoundError(f\"Title image not found: {title_image}\")\n",
    "if not os.path.exists(file_path):\n",
    "    raise FileNotFoundError(f\"Data file not found: {file_path}\")\n",
    "if not os.path.exists(audio_file):\n",
    "    raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n",
    "if not os.path.exists(title_image):\n",
    "    raise FileNotFoundError(f\"Title image not found: {title_image}\")\n",
    "\n",
    "try:\n",
    "    data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)\n",
    "except ValueError as e:\n",
    "    if \"Missing required columns\" in str(e):\n",
    "        logging.info(\"Adding missing columns to the data\")\n",
    "        print(\"Adding missing columns to the data\")\n",
    "        data = load_and_preprocess_data(file_path)\n",
    "        column_mapping = infer_columns(data)\n",
    "        \n",
    "        if 'date' not in column_mapping:\n",
    "            data['date'] = pd.date_range(start='1/1/2020', periods=len(data), freq='D')\n",
    "        \n",
    "        if 'value' not in column_mapping:\n",
    "            data['value'] = data.select_dtypes(include=['float64', 'int64']).iloc[:, 0]\n",
    "        \n",
    "        if 'category' not in column_mapping:\n",
    "            data['category'] = 'default_category'\n",
    "        \n",
    "        data_storytelling_pipeline(file_path, prompt, audio_file=audio_file)\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will work tommorow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
