{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel \n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to load and preprocess the text input\n",
    "def preprocess_text(text):\n",
    "    # Here we can use a tokenizer or any NLP model to process the text\n",
    "    # For simplicity, we will just return the text\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to generate video from text\n",
    "def generate_video_from_text(text):\n",
    "    # Load the CLIP model and processor\n",
    "    model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch16\")\n",
    "    processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch16\")\n",
    "\n",
    "    # Preprocess the text\n",
    "    processed_text = preprocess_text(text)\n",
    "\n",
    "    # Generate video frames using VideoGPT or any other model\n",
    "    video_model = VideoGPT.from_pretrained(\"your_video_gpt_model\")\n",
    "    \n",
    "    # Generate video frames based on the processed text\n",
    "    video_frames = video_model.generate(processed_text)\n",
    "\n",
    "    return video_frames\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to save video frames as a video file\n",
    "def save_video(frames, filename='output_video.mp4'):\n",
    "    # Convert frames to a video format\n",
    "    # This is a placeholder for actual video saving logic\n",
    "    # You can use libraries like OpenCV or imageio to save the frames\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     text_input = \"A beautiful sunset over the mountains\"\n",
    "#     video_frames = generate_video_from_text(text_input)\n",
    "#     save_video(video_frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "# # Step 1: Data Understanding\n",
    "\n",
    "# def parse_input_text(text):\n",
    "#     # Extract data and statistics from the input text\n",
    "#     return text  # For simplicity, returning the text directly\n",
    "\n",
    "# # Step 2: Text Processing\n",
    "\n",
    "# def preprocess_text(text):\n",
    "#     return text.strip()\n",
    "\n",
    "# # Step 3: Video Generation\n",
    "\n",
    "# def generate_video_from_text(text):\n",
    "#     # Preprocess the input text\n",
    "#     processed_text = preprocess_text(text)\n",
    "\n",
    "#     # Load the CLIP model and processor\n",
    "#     model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch16\")\n",
    "#     processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch16\")\n",
    "\n",
    "#     # Since VideoGPT cannot be imported, we will use an alternative approach\n",
    "#     import numpy as np\n",
    "#     import cv2\n",
    "\n",
    "#     # Generate a simple video with random colors as a placeholder\n",
    "#     height, width, num_frames = 240, 320, 30\n",
    "#     video_frames = []\n",
    "\n",
    "#     for _ in range(num_frames):\n",
    "#         # Create a random color frame\n",
    "#         frame = np.random.randint(0, 256, (height, width, 3), dtype=np.uint8)\n",
    "#         video_frames.append(frame)\n",
    "\n",
    "#     # Convert list of frames to a video file\n",
    "#     fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "#     out = cv2.VideoWriter('output_video.mp4', fourcc, 20.0, (width, height))\n",
    "\n",
    "#     for frame in video_frames:\n",
    "#         out.write(frame)\n",
    "\n",
    "#     out.release()\n",
    "\n",
    "# # Main function\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Example input text\n",
    "#     input_text = \"20% of users own an iPhone, 50% own a Samsung, and the rest own a variety of brands\"\n",
    "    \n",
    "#     # Parse the input text\n",
    "#     try:\n",
    "#         data = parse_input_text(input_text)\n",
    "#         print(\"Parsed Data:\", data)\n",
    "\n",
    "#         # Generate video frames from text\n",
    "#         video_frames = generate_video_from_text(input_text)\n",
    "#         if not video_frames:\n",
    "#             print(\"No suitable video frames generated. Please check the input data or model response.\")\n",
    "#         else:\n",
    "#             print(\"Generated Video Frames:\", video_frames)\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # It seems you are looking for a model that can generate videos from text. One of the popular models for text-to-video generation is the \"Make-A-Video\" model by Meta. \n",
    "# # However, if you are facing issues with existing models, you might want to try using the \"Stable Diffusion\" model for generating video frames from text prompts.\n",
    "# # Below is an example of how you can implement a simple text-to-video generation using the Stable Diffusion model.\n",
    "\n",
    "# from diffusers import StableDiffusionPipeline\n",
    "# import torch\n",
    "# import numpy as np\n",
    "\n",
    "# def generate_video_from_text(prompt):\n",
    "#     # Load the Stable Diffusion model for video generation\n",
    "#     video_model = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", torch_dtype=torch.float16)\n",
    "#     video_model = video_model.to(\"cuda\")  # Move model to GPU if available\n",
    "\n",
    "#     # Generate video frames using the Stable Diffusion model\n",
    "#     video_frames = []\n",
    "#     for _ in range(30):  # Generate 30 frames\n",
    "#         frame = video_model(prompt).images[0]  # Generate a single frame\n",
    "#         video_frames.append(frame)\n",
    "\n",
    "#     # Return the generated frames instead of saving them to a video file\n",
    "#     return video_frames\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whole API implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Submit video generation task-----------------\n",
      "{\"task_id\":\"\",\"base_resp\":{\"status_code\":1008,\"status_msg\":\"insufficient balance\"}}\n",
      "Video generation task submitted successfully, task ID: \n",
      "-----------------Video generation task submitted -----------------\n",
      "---------------Failed---------------\n"
     ]
    }
   ],
   "source": [
    "# This Python script is a program that interacts with an API to generate a video based on a given prompt using a specific model. Here's a breakdown of what the script does:\n",
    "# # import os\n",
    "# import time\n",
    "# import requests\n",
    "# import json\n",
    "\n",
    "# api_key = \"eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJHcm91cE5hbWUiOiJTdWppdCIsIlVzZXJOYW1lIjoiU3VqaXQiLCJBY2NvdW50IjoiIiwiU3ViamVjdElEIjoiMTg1OTg1NDg3NDY3NDQ2NzA2OSIsIlBob25lIjoiIiwiR3JvdXBJRCI6IjE4NTk4NTQ4NzQ2NjYwNzg0NjEiLCJQYWdlTmFtZSI6IiIsIk1haWwiOiJuaXJtYWxzdWppdDk4MUBnbWFpbC5jb20iLCJDcmVhdGVUaW1lIjoiMjAyNC0xMS0yMyAyMTo1MzoxNiIsIlRva2VuVHlwZSI6MSwiaXNzIjoibWluaW1heCJ9.SD9MBb3JLVkKhTpbUA3Sfm9dn4fMp_L8eoHxlLKUGPAVcdjsXIWF59J2NVTb2UJ6zQNLfDSFmRpzL-GQJeolf_y9sWOttBSROIUTJETtHFcd6YKKo_CFdWelQFlsSoC_-xnQoGte9xIJQ86YUBkYSjSGlrMSxEh1UowrW-rgtAuZ8NPJxRXR50vNWjcUGUyvIfX44Yb7MHp7wtqksWoWqoRonH3UeCC5E-w-hkFrNs5sf2AdTs9FA9x_EzTp8nXyAaUc4i4Deqgm60DlDmCrJ8KqwuaIK8HOr_1FA6KWnrxHy0D4ODWWfbOIcydSkT3elGa7ZHB0nTxaQdi1L5-Fug\"\n",
    "\n",
    "# prompt = \"cat dancing\"\n",
    "# model = \"video-01\" \n",
    "# output_file_name = \"output.mp4\"  # Please enter the save path for the generated video here\n",
    "\n",
    "# def invoke_video_generation() -> str:\n",
    "#     print(\"-----------------Submit video generation task-----------------\")\n",
    "#     url = \"https://api.minimaxi.chat/v1/video_generation\"\n",
    "#     payload = json.dumps({\n",
    "#         \"prompt\": prompt,\n",
    "#         \"model\": model\n",
    "#     })\n",
    "#     headers = {\n",
    "#         'authorization': 'Bearer ' + api_key,\n",
    "#         'content-type': 'application/json',\n",
    "#     }\n",
    "\n",
    "#     response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "#     print(response.text)\n",
    "    \n",
    "#     # Check for errors in the response\n",
    "#     if response.status_code != 200 or 'task_id' not in response.json():\n",
    "#         print(\"Error: \", response.json().get('base_resp', {}).get('status_msg', 'Unknown error occurred'))\n",
    "#         if response.json().get('base_resp', {}).get('status_code') == 1008:\n",
    "#             print(\"Video generation failed due to insufficient balance.\")\n",
    "#         return \"\"\n",
    "    \n",
    "#     task_id = response.json()['task_id']\n",
    "#     print(\"Video generation task submitted successfully, task ID: \" + task_id)\n",
    "#     return task_id\n",
    "\n",
    "# def query_video_generation(task_id: str):\n",
    "#     url = \"https://api.minimaxi.chat/v1/query/video_generation?task_id=\" + task_id\n",
    "#     headers = {\n",
    "#         'authorization': 'Bearer ' + api_key\n",
    "#     }\n",
    "#     response = requests.request(\"GET\", url, headers=headers)\n",
    "#     status = response.json()['status']\n",
    "    \n",
    "#     if status == 'Queueing':\n",
    "#         print(\"...In the queue...\")\n",
    "#         return \"\", 'Queueing'\n",
    "#     elif status == 'Processing':\n",
    "#         print(\"...Generating...\")\n",
    "#         return \"\", 'Processing'\n",
    "#     elif status == 'Success':\n",
    "#         return response.json()['file_id'], \"Finished\"\n",
    "#     elif status == 'Fail':\n",
    "#         print(\"Video generation failed. Reason: \", response.json().get('base_resp', {}).get('status_msg', 'Unknown error'))\n",
    "#         return \"\", \"Fail\"\n",
    "#     else:\n",
    "#         return \"\", \"Unknown\"\n",
    "\n",
    "# def fetch_video_result(file_id: str):\n",
    "#     print(\"---------------Video generated successfully, downloading now---------------\")\n",
    "#     url = \"https://api.minimaxi.chat/v1/files/retrieve?file_id=\" + file_id\n",
    "#     headers = {\n",
    "#         'authorization': 'Bearer ' + api_key,\n",
    "#     }\n",
    "\n",
    "#     response = requests.request(\"GET\", url, headers=headers)\n",
    "#     print(response.text)\n",
    "\n",
    "#     download_url = response.json()['file']['download_url']\n",
    "#     print(\"Video download link: \" + download_url)\n",
    "#     with open(output_file_name, 'wb') as f:\n",
    "#         f.write(requests.get(download_url).content)\n",
    "#     print(\"The video has been downloaded in: \" + os.getcwd() + '/' + output_file_name)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     task_id = invoke_video_generation()\n",
    "#     print(\"-----------------Video generation task submitted -----------------\")\n",
    "#     while True:\n",
    "#         time.sleep(3)  # Rate limiting to 20 requests per minute (3 seconds per request)\n",
    "\n",
    "#         file_id, status = query_video_generation(task_id)\n",
    "#         if file_id != \"\":\n",
    "#             fetch_video_result(file_id)\n",
    "#             print(\"---------------Successful---------------\")\n",
    "#             break\n",
    "#         elif status == \"Fail\" or status == \"Unknown\":\n",
    "#             print(\"---------------Failed---------------\")\n",
    "#             break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  # pip install runwayml\n",
    "# from runwayml import RunwayML\n",
    "\n",
    "# # The env var RUNWAYML_API_SECRET is expected to contain your API key.\n",
    "# client = RunwayML()\n",
    "\n",
    "# task = client.image_to_video.create(\n",
    "#   model='gen3a_turbo',\n",
    "#   prompt_image='https://example.com/assets/bunny.jpg',\n",
    "#   prompt_text='The bunny is eating a carrot',\n",
    "# )\n",
    "# print(task.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code 2 Correct implematation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code 3 Giving some type error but in use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import json\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import moviepy.editor as mpy\n",
    "# import time\n",
    "# import os\n",
    "\n",
    "# # Hardcoded Pexels API key\n",
    "# PEXELS_API_KEY = \"yepFtS82dEUPX41sHUOMVzris34EohIYvW8Czo5Z5s6KQ2WHPPe4eIQA\"  # Replace with your actual Pexels API key\n",
    "\n",
    "# # Function to search for videos using Pexels API\n",
    "# def search_videos(query_string, orientation_landscape=True):\n",
    "#     url = \"https://api.pexels.com/videos/search\"\n",
    "#     headers = {\n",
    "#         \"Authorization\": PEXELS_API_KEY,\n",
    "#         \"User-Agent\": \"Mozilla/5.0\"\n",
    "#     }\n",
    "#     params = {\n",
    "#         \"query\": query_string,\n",
    "#         \"orientation\": \"landscape\" if orientation_landscape else \"portrait\",\n",
    "#         \"per_page\": 15\n",
    "#     }\n",
    "\n",
    "#     response = requests.get(url, headers=headers, params=params)\n",
    "#     return response.json()\n",
    "\n",
    "# # Function to create visualizations based on the type\n",
    "# def create_visualization(data, visualization_type):\n",
    "#     if visualization_type == \"line_chart\":\n",
    "#         plt.plot(data['x'], data['y'].astype(float))  # Ensure y values are float\n",
    "#         plt.title('Growth Over Time')\n",
    "#         plt.xlabel('Time')\n",
    "#         plt.ylabel('Value')\n",
    "#         plt.grid()\n",
    "#         plt.savefig('line_chart.png')\n",
    "#     elif visualization_type == \"bar_chart\":\n",
    "#         plt.bar(data['categories'], data['values'].astype(float))  # Ensure values are float\n",
    "#         plt.title('Distribution of Values')\n",
    "#         plt.xlabel('Categories')\n",
    "#         plt.ylabel('Values')\n",
    "#         plt.savefig('bar_chart.png')\n",
    "#     elif visualization_type == \"pie_chart\":\n",
    "#         plt.pie(data['values'].astype(float), labels=data['categories'], autopct='%1.1f%%')  # Ensure values are float\n",
    "#         plt.title('Comparison of Categories')\n",
    "#         plt.savefig('pie_chart.png')\n",
    "#     plt.close()\n",
    "\n",
    "# # Function to generate video from visualizations\n",
    "# def generate_video_from_visualization():\n",
    "#     # Check if the required image files exist before creating the video\n",
    "#     image_files = ['line_chart.png', 'bar_chart.png', 'pie_chart.png']\n",
    "#     if all(os.path.exists(img) for img in image_files):\n",
    "#         # Ensure all images are the same size\n",
    "#         first_image = mpy.ImageClip(image_files[0])\n",
    "#         width, height = first_image.size\n",
    "#         for img in image_files:\n",
    "#             clip = mpy.ImageClip(img)\n",
    "#             if clip.size != (width, height):\n",
    "#                 print(f\"Image {img} does not match the required size of {width}x{height}. Resizing...\")\n",
    "#                 clip = clip.resize(newsize=(width, height))\n",
    "#                 clip.save_frame(img)  # Save the resized image back to file\n",
    "\n",
    "#         output_video_path = 'data_visualization.mp4'\n",
    "#         clip = mpy.ImageSequenceClip(image_files, fps=1)\n",
    "#         clip.write_videofile(output_video_path)\n",
    "#         print(f\"Video saved at: {output_video_path}\")\n",
    "#     else:\n",
    "#         print(\"One or more visualization files are missing. Please ensure all images are created successfully.\")\n",
    "\n",
    "# # Function to analyze data and suggest visualization methods\n",
    "# def analyze_data(context_text):\n",
    "#     if \"growth\" in context_text or \"increase\" in context_text:\n",
    "#         return \"line_chart\"\n",
    "#     elif \"distribution\" in context_text:\n",
    "#         return \"bar_chart\"\n",
    "#     elif \"comparison\" in context_text:\n",
    "#         return \"pie_chart\"\n",
    "#     else:\n",
    "#         return \"text\"\n",
    "\n",
    "# # Function to generate video using data input\n",
    "# def generate_video_from_text(context_text):\n",
    "#     visualization_type = analyze_data(context_text)\n",
    "#     print(f\"Analyzing context: {context_text}\")\n",
    "    \n",
    "#     # Search for relevant videos using Pexels API\n",
    "#     videos = search_videos(context_text)\n",
    "#     if videos and 'videos' in videos:\n",
    "#         print(f\"Found {len(videos['videos'])} videos for the context.\")\n",
    "    \n",
    "#     # Example data for visualization\n",
    "#     data = {\n",
    "#         'x': np.arange(10),\n",
    "#         'y': np.random.randint(1, 10, size=10).astype(float),  # Ensure y values are float\n",
    "#         'categories': ['A', 'B', 'C', 'D'],\n",
    "#         'values': [15.0, 30.0, 45.0, 10.0]  # Ensure values are float\n",
    "#     }\n",
    "    \n",
    "#     create_visualization(data, visualization_type)\n",
    "#     generate_video_from_visualization()\n",
    "\n",
    "# # Example usage\n",
    "# if __name__ == '__main__':\n",
    "#     user_input = \"The growth of sales over the last decade shows a significant increase.\"\n",
    "#     generate_video_from_text(user_input)\n",
    "#     print(\"Video generated successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import moviepy.editor as mpy\n",
    "# from video.background_video_generator import search_videos, getBestVideo\n",
    "\n",
    "# def create_visualization(data, visualization_type):\n",
    "#     if visualization_type == \"line_chart\":\n",
    "#         import matplotlib.pyplot as plt\n",
    "#         plt.plot(data['x'], data['y'])\n",
    "#         plt.title('Line Chart')\n",
    "#         plt.xlabel('X-axis')\n",
    "#         plt.ylabel('Y-axis')\n",
    "#         plt.savefig('line_chart.png')\n",
    "#         plt.close()\n",
    "#     elif visualization_type == \"bar_chart\":\n",
    "#         import matplotlib.pyplot as plt\n",
    "#         plt.bar(data['categories'], data['values'])\n",
    "#         plt.title('Bar Chart')\n",
    "#         plt.xlabel('Categories')\n",
    "#         plt.ylabel('Values')\n",
    "#         plt.savefig('bar_chart.png')\n",
    "#         plt.close()\n",
    "#     elif visualization_type == \"pie_chart\":\n",
    "#         import matplotlib.pyplot as plt\n",
    "#         plt.pie(data['values'], labels=data['categories'], autopct='%1.1f%%')\n",
    "#         plt.title('Pie Chart')\n",
    "#         plt.savefig('pie_chart.png')\n",
    "#         plt.close()\n",
    "#     else:\n",
    "#         print(\"No valid visualization type provided.\")\n",
    "\n",
    "# def generate_video_from_visualization():\n",
    "#     image_files = ['line_chart.png', 'bar_chart.png', 'pie_chart.png']\n",
    "#     if all(os.path.exists(img) for img in image_files):\n",
    "#         output_video_path = 'data_visualization.mp4'\n",
    "#         clip = mpy.ImageSequenceClip(image_files, fps=1)\n",
    "#         clip.write_videofile(output_video_path)\n",
    "#         print(f\"Video saved at: {output_video_path}\")\n",
    "#     else:\n",
    "#         print(\"One or more visualization files are missing. Please ensure all images are created successfully.\")\n",
    "\n",
    "# def generate_video_from_text(context_text):\n",
    "#     visualization_type = analyze_data(context_text)\n",
    "#     print(f\"Analyzing context: {context_text}\")\n",
    "    \n",
    "#     # Search for relevant videos using Pexels API\n",
    "#     videos = search_videos(context_text)\n",
    "#     if videos and 'videos' in videos:\n",
    "#         print(f\"Found {len(videos['videos'])} videos for the context.\")\n",
    "#         video_url = getBestVideo(context_text)\n",
    "#         print(f\"Selected video URL: {video_url}\")\n",
    "    \n",
    "#     # Example data for visualization\n",
    "#     data = {\n",
    "#         'x': np.arange(10),\n",
    "#         'y': np.random.randint(1, 10, size=10),\n",
    "#         'categories': ['A', 'B', 'C', 'D'],\n",
    "#         'values': [15, 30, 45, 10]\n",
    "#     }\n",
    "    \n",
    "#     create_visualization(data, visualization_type)\n",
    "#     generate_video_from_visualization()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whole Processed end to end pipeline code working "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import moviepy.editor as mpy\n",
    "import requests\n",
    "\n",
    "# Hardcoded API key\n",
    "PEXELS_API_KEY = 'yepFtS82dEUPX41sHUOMVzris34EohIYvW8Czo5Z5s6KQ2WHPPe4eIQA'\n",
    "\n",
    "def analyze_data(context_text):\n",
    "    # Simple analysis to determine visualization type based on keywords\n",
    "    if \"percent\" in context_text or \"%\" in context_text:\n",
    "        return \"pie_chart\"\n",
    "    elif \"trend\" in context_text or \"increase\" in context_text or \"decrease\" in context_text:\n",
    "        return \"line_chart\"\n",
    "    else:\n",
    "        return \"bar_chart\"\n",
    "\n",
    "def search_videos(query_string, orientation_landscape=True):\n",
    "    url = \"https://api.pexels.com/videos/search\"\n",
    "    headers = {\n",
    "        \"Authorization\": PEXELS_API_KEY,\n",
    "        \"User-Agent\": \"Mozilla/5.0\"\n",
    "    }\n",
    "    params = {\n",
    "        \"query\": query_string,\n",
    "        \"orientation\": \"landscape\" if orientation_landscape else \"portrait\",\n",
    "        \"per_page\": 15\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    json_data = response.json()\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error fetching videos: {json_data.get('message', 'Unknown error')}\")\n",
    "    else:\n",
    "        print(f\"Fetched videos for query '{query_string}': {json_data.get('videos', [])}\")  # Print fetched video data\n",
    "    return json_data\n",
    "\n",
    "def getBestVideo(query_string, orientation_landscape=True, used_vids=[]):\n",
    "    vids = search_videos(query_string, orientation_landscape)\n",
    "    videos = vids.get('videos', [])\n",
    "\n",
    "    if not videos:\n",
    "        print(\"No videos found for the given query.\")\n",
    "        return None\n",
    "\n",
    "    if orientation_landscape:\n",
    "        filtered_videos = [video for video in videos if video['width'] >= 1920 and video['height'] >= 1080]\n",
    "    else:\n",
    "        filtered_videos = [video for video in videos if video['width'] >= 1080 and video['height'] >= 1920]\n",
    "\n",
    "    sorted_videos = sorted(filtered_videos, key=lambda x: abs(15 - int(x['duration'])))\n",
    "\n",
    "    for video in sorted_videos:\n",
    "        for video_file in video['video_files']:\n",
    "            if orientation_landscape and video_file['width'] == 1920 and video_file['height'] == 1080:\n",
    "                if video_file['link'].split('.hd')[0] not in used_vids:\n",
    "                    print(f\"Found video URL: {video_file['link']}\")  # Print found video URL\n",
    "                    return video_file['link']\n",
    "            elif not orientation_landscape and video_file['width'] == 1080 and video_file['height'] == 1920:\n",
    "                if video_file['link'].split('.hd')[0] not in used_vids:\n",
    "                    print(f\"Found video URL: {video_file['link']}\")  # Print found video URL\n",
    "                    return video_file['link']\n",
    "    print(\"No suitable video found.\")\n",
    "    return None\n",
    "\n",
    "def create_visualization(data, visualization_type):\n",
    "    import matplotlib.pyplot as plt\n",
    "    if visualization_type == \"line_chart\":\n",
    "        plt.plot(data['x'], data['y'])\n",
    "        plt.title('Line Chart')\n",
    "        plt.xlabel('X-axis')\n",
    "        plt.ylabel('Y-axis')\n",
    "        plt.savefig('line_chart.png')\n",
    "        plt.close()\n",
    "    elif visualization_type == \"bar_chart\":\n",
    "        plt.bar(data['categories'], data['values'])\n",
    "        plt.title('Bar Chart')\n",
    "        plt.xlabel('Categories')\n",
    "        plt.ylabel('Values')\n",
    "        plt.savefig('bar_chart.png')\n",
    "        plt.close()\n",
    "    elif visualization_type == \"pie_chart\":\n",
    "        plt.pie(data['values'], labels=data['categories'], autopct='%1.1f%%')\n",
    "        plt.title('Pie Chart')\n",
    "        plt.savefig('pie_chart.png')\n",
    "        plt.close()\n",
    "    else:\n",
    "        print(\"No valid visualization type provided.\")\n",
    "\n",
    "def generate_video_from_visualization():\n",
    "    image_files = ['line_chart.png', 'bar_chart.png', 'pie_chart.png']\n",
    "    if all(os.path.exists(img) for img in image_files):\n",
    "        output_video_path = 'data_visualization.mp4'\n",
    "        clip = mpy.ImageSequenceClip(image_files, fps=1)\n",
    "        clip.write_videofile(output_video_path)\n",
    "        print(f\"Video saved at: {output_video_path}\")\n",
    "    else:\n",
    "        print(\"One or more visualization files are missing. Please ensure all images are created successfully.\")\n",
    "\n",
    "def generate_video_from_text(context_text):\n",
    "    visualization_type = analyze_data(context_text)\n",
    "    print(f\"Analyzing context: {context_text}\")\n",
    "    \n",
    "    # Search for relevant videos using Pexels API\n",
    "    video_url = getBestVideo(context_text)\n",
    "    if video_url:\n",
    "        print(f\"Selected video URL: {video_url}\")\n",
    "    else:\n",
    "        print(\"No video URL selected.\")\n",
    "    \n",
    "    # Example data for visualization\n",
    "    data = {\n",
    "        'x': np.arange(10),\n",
    "        'y': np.random.randint(1, 10, size=10),\n",
    "        'categories': ['A', 'B', 'C', 'D'],\n",
    "        'values': [15, 30, 45, 10]\n",
    "    }\n",
    "    \n",
    "    create_visualization(data, visualization_type)\n",
    "    generate_video_from_visualization()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import moviepy.editor as mpy\n",
    "import os  # Import os to check for file existence\n",
    "\n",
    "def get_video_from_pexels(query, api_key):\n",
    "    url = \"https://api.pexels.com/videos/search\"\n",
    "    headers = {\n",
    "        \"Authorization\": api_key\n",
    "    }\n",
    "    params = {\n",
    "        \"query\": query,\n",
    "        \"per_page\": 1\n",
    "    }\n",
    "    \n",
    "    # Rate limiting: wait for 1 second between requests\n",
    "    time.sleep(3)\n",
    "    \n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if data['videos']:\n",
    "            return data['videos'][0]['video_files'][0]['link']\n",
    "        else:\n",
    "            print(\"No videos found for the given query.\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Error fetching videos: {response.status_code} - {response.text}\")\n",
    "        return None\n",
    "\n",
    "def analyze_data(context_text):\n",
    "    # Enhanced analysis to determine visualization type based on context\n",
    "    if \"percent\" in context_text or \"%\" in context_text:\n",
    "        return \"pie_chart\"\n",
    "    return \"bar_chart\"  # Default to bar chart if no percentage found\n",
    "\n",
    "def create_visualization(data, visualization_type):\n",
    "    if visualization_type == \"pie_chart\":\n",
    "        plt.pie(data['values'], labels=data['categories'], autopct='%1.1f%%')\n",
    "        plt.title('User Distribution by Brand')\n",
    "        plt.savefig('pie_chart.png')  # Save the pie chart\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.bar(data['categories'], data['values'])\n",
    "        plt.title('Bar Chart')\n",
    "        plt.xlabel('Categories')\n",
    "        plt.ylabel('Values')\n",
    "        plt.savefig('bar_chart.png')  # Save the bar chart\n",
    "        plt.close()\n",
    "\n",
    "def process_text_and_generate_video(query, api_key):\n",
    "    # Step 1: Analyze the text to determine visualization type\n",
    "    visualization_type = analyze_data(query)\n",
    "    print(f\"Analyzing context: {query}\")\n",
    "    \n",
    "    # Step 2: Fetch relevant video from Pexels\n",
    "    video_url = get_video_from_pexels(query, api_key)\n",
    "    if video_url:\n",
    "        print(f\"Selected video URL: {video_url}\")\n",
    "    else:\n",
    "        print(\"No video URL available to create the final video.\")\n",
    "    \n",
    "    # Step 3: Generate a placeholder image based on the query\n",
    "    generated_image_path = 'F:\\\\100x_enginners_hackathon_genai\\\\visualization.png'  # Use a placeholder image instead\n",
    "    if not os.path.exists(generated_image_path):\n",
    "        print(f\"Placeholder image not found at: {generated_image_path}. Please ensure it exists.\")\n",
    "        return  # Exit if the placeholder image does not exist\n",
    "    print(f\"Using placeholder image at: {generated_image_path}\")\n",
    "    \n",
    "    # Step 4: Prepare data for visualization based on the input query\n",
    "    data = {\n",
    "        'categories': ['iPhone', 'Samsung', 'Other'],\n",
    "        'values': [20, 50, 30]  # Assuming the rest is 30%\n",
    "    }\n",
    "    \n",
    "    # Step 5: Create the visualization\n",
    "    create_visualization(data, visualization_type)\n",
    "    \n",
    "    # Step 6: Create infographic video\n",
    "    clips = []\n",
    "    if visualization_type == \"pie_chart\":\n",
    "        clips.append(mpy.ImageClip('pie_chart.png').set_duration(5))\n",
    "    else:\n",
    "        clips.append(mpy.ImageClip('bar_chart.png').set_duration(5))\n",
    "    \n",
    "    # Step 7: Add the generated image to the video clips\n",
    "    clips.append(mpy.ImageClip(generated_image_path).set_duration(5))\n",
    "    \n",
    "    # Step 8: Add a short video clip from Pexels if available\n",
    "    if video_url:\n",
    "        clips.append(mpy.VideoFileClip(video_url).subclip(0, 15))  # Use first 15 seconds of the video\n",
    "    \n",
    "    # Step 9: Concatenate clips (do not save the final video)\n",
    "    final_video = mpy.concatenate_videoclips(clips)\n",
    "    print(\"Infographic video created but not saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing context: profit  of 80 dollars in cloths \n",
      "Selected video URL: https://videos.pexels.com/video-files/3196002/3196002-hd_1920_1080_25fps.mp4\n",
      "Using placeholder image at: F:\\100x_enginners_hackathon_genai\\visualization.png\n",
      "Infographic video created but not saved.\n"
     ]
    }
   ],
   "source": [
    "api_key='yepFtS82dEUPX41sHUOMVzris34EohIYvW8Czo5Z5s6KQ2WHPPe4eIQA'\n",
    "# groq_api_key='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'\n",
    "process_text_and_generate_video('profit  of 80 dollars in cloths ', api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# end here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import pipeline\n",
    "\n",
    "# def generate_video_from_text(prompt, api_key):\n",
    "#     # Load the Hugging Face pipeline for text-to-video generation\n",
    "#     pipe = pipeline(\"text-to-video\", model=\"CompVis/stable-diffusion-v-1-4\", use_auth_token=api_key)\n",
    "    \n",
    "#     # Generate a video from the text prompt\n",
    "#     video = pipe(prompt)\n",
    "    \n",
    "#     # Save the generated video\n",
    "#     video_path = 'generated_video.mp4'\n",
    "#     video.save(video_path)\n",
    "    \n",
    "#     print(f\"Generated video saved at: {video_path}\")\n",
    "    \n",
    "#     return video_path\n",
    "\n",
    "# # Example usage\n",
    "# generated_video_path = generate_video_from_text(\"A beautiful sunset over the mountains\", api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This code need to check , having API faliure 400 error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed Data: 20% of users own an iPhone, 50% own a Samsung, and the rest own a variety of brands\n",
      "An error occurred: Pexels API request failed with status code 400\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import time\n",
    "# from groq import Groq\n",
    "# from transformers import CLIPProcessor, CLIPModel\n",
    "# import requests  # Ensure requests is imported\n",
    "\n",
    "# # Hardcoded API keys\n",
    "# GROQ_API_KEY = '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'  # Replace with your actual Groq API key\n",
    "# PEXELS_API_KEY = 'yepFtS82dEUPX41sHUOMVzris34EohIYvW8Czo5Z5s6KQ2WHPPe4eIQA'\n",
    "\n",
    "# client = Groq(\n",
    "#     api_key=GROQ_API_KEY,\n",
    "# )\n",
    "\n",
    "# # Step 1: Data Understanding\n",
    "\n",
    "# def parse_input_text(text):\n",
    "#     return text  # For simplicity, returning the text directly\n",
    "\n",
    "# # Step 2: Text Processing\n",
    "\n",
    "# def preprocess_text(text):\n",
    "#     return text.strip()\n",
    "\n",
    "# # Step 3: Video Generation\n",
    "\n",
    "# def generate_video_from_text(text):\n",
    "#     # Process the input text to extract relevant data points\n",
    "#     processed_text = preprocess_text(text)\n",
    "\n",
    "#     # Generate a prompt using Groq API based on the processed text\n",
    "#     chat_completion = client.chat.completions.create(\n",
    "#         messages=[\n",
    "#             {\n",
    "#                 \"role\": \"system\",\n",
    "#                 \"content\": \"you are a helpful assistant.\"\n",
    "#             },\n",
    "#             {\n",
    "#                 \"role\": \"user\",\n",
    "#                 \"content\": f\"Extract relevant data points from the following text: {processed_text}\",\n",
    "#             }\n",
    "#         ],\n",
    "#         model=\"llama3-8b-8192\",\n",
    "#     )\n",
    "\n",
    "#     prompt = chat_completion.choices[0].message.content\n",
    "\n",
    "#     # Use Pexels API to generate infographic videos\n",
    "#     headers = {'Authorization': PEXELS_API_KEY}\n",
    "#     params = {'query': f'infographics {prompt}', 'per_page': 5}\n",
    "    \n",
    "#     # Rate limiting to avoid exhausting the API\n",
    "#     time.sleep(3)  # Wait for 3 seconds between requests\n",
    "#     response = requests.get('https://api.pexels.com/videos/search', headers=headers, params=params)\n",
    "    \n",
    "#     if response.status_code != 200:\n",
    "#         raise Exception(f\"Pexels API request failed with status code {response.status_code}\")\n",
    "\n",
    "#     videos = response.json().get('videos', [])\n",
    "#     video_urls = [video['video_files'][0]['link'] for video in videos if video['video_files']]\n",
    "    \n",
    "#     # Additional rate limiting before returning the URLs\n",
    "#     time.sleep(3)  # Wait for 2 seconds before returning the video URLs\n",
    "#     return video_urls[:3]  # Return only the first 3 video URLs\n",
    "\n",
    "# # Main function\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     input_text = \"20% of users own an iPhone, 50% own a Samsung, and the rest own a variety of brands\"\n",
    "    \n",
    "#     try:\n",
    "#         data = parse_input_text(input_text)\n",
    "#         print(\"Parsed Data:\", data)\n",
    "\n",
    "#         video_frames = generate_video_from_text(input_text)\n",
    "#         print(\"Generated Video URLs:\", video_frames)\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred: {e}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import hf_hub_download\n",
    "# from transformers import pipeline\n",
    "\n",
    "# def generate_video_with_ltx_model(text):\n",
    "#     # Load the Lightricks/LTX-Video model\n",
    "#     video_generator = pipeline(\"text-to-video\", model=\"Lightricks/LTX-Video\")\n",
    "    \n",
    "#     # Generate video from the input text\n",
    "#     video_output = video_generator(text)\n",
    "    \n",
    "#     return video_output\n",
    "\n",
    "# # Example usage\n",
    "# input_text = \"20% of users own an iPhone, 50% own a Samsung, and the rest own a variety of brands\"\n",
    "# video_output = generate_video_with_ltx_model(input_text)\n",
    "# print(\"Generated Video Output:\", video_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from diffusers import DiffusionPipeline\n",
    "# from langchain import LLMChain\n",
    "\n",
    "# def generate_video_with_combined_models(text):\n",
    "#     try:\n",
    "#         # Load the models using DiffusionPipeline\n",
    "#         ltx_video_generator = DiffusionPipeline.from_pretrained(\"Lightricks/LTX-Video\")\n",
    "#         mochi_video_generator = DiffusionPipeline.from_pretrained(\"genmo/mochi-1-preview\")\n",
    "\n",
    "#         # Generate video outputs from both models\n",
    "#         ltx_output = ltx_video_generator(text).images[0]\n",
    "#         mochi_output = mochi_video_generator(text).images[0]\n",
    "\n",
    "#         return {\"mochi_output\": mochi_output, \"ltx_output\": ltx_output}  # Return outputs as a dictionary\n",
    "#     except Exception as e:\n",
    "#         print(\"An error occurred while generating video: \", str(e))\n",
    "#         return None\n",
    "\n",
    "# # Example usage\n",
    "# input_text = \"20% of users own an iPhone, 50% own a Samsung, and the rest own a variety of brands\"\n",
    "# video_output = generate_video_with_combined_models(input_text)\n",
    "# if video_output:\n",
    "#     print(\"Generated Video Outputs:\", video_output)\n",
    "# else:\n",
    "#     print(\"Video generation failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import moviepy.editor as mp\n",
    "\n",
    "# def fetch_videos_from_pexels(prompt, api_key):\n",
    "#     url = \"https://api.pexels.com/videos/search\"\n",
    "#     headers = {\n",
    "#         \"Authorization\": api_key\n",
    "#     }\n",
    "#     params = {\n",
    "#         \"query\": prompt,\n",
    "#         \"per_page\": 5  # Fetch a limited number of videos\n",
    "#     }\n",
    "#     response = requests.get(url, headers=headers, params=params)\n",
    "#     if response.status_code == 200:\n",
    "#         return [video['video_files'][0]['link'] for video in response.json()['videos'] if video['video_files']]\n",
    "#     else:\n",
    "#         print(\"Error fetching videos:\", response.status_code)\n",
    "#         return []\n",
    "\n",
    "# def generate_video_from_clips(video_urls, output_filename):\n",
    "#     clips = []\n",
    "#     for url in video_urls:\n",
    "#         try:\n",
    "#             clip = mp.VideoFileClip(url)\n",
    "#             clips.append(clip)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error loading video from {url}: {e}\")\n",
    "\n",
    "#     if clips:  # Check if there are any valid clips\n",
    "#         final_video = mp.concatenate_videoclips(clips)\n",
    "#         if final_video.duration is not None:  # Ensure duration is set\n",
    "#             final_video.write_videofile(output_filename)\n",
    "#         else:\n",
    "#             print(\"Final video has no duration, cannot write to file.\")\n",
    "#     else:\n",
    "#         print(\"No valid video clips to concatenate.\")\n",
    "\n",
    "# # Example usage\n",
    "# api_key = \"yepFtS82dEUPX41sHUOMVzris34EohIYvW8Czo5Z5s6KQ2WHPPe4eIQA\"\n",
    "# input_prompt = \"nature scenery\"\n",
    "# video_urls = fetch_videos_from_pexels(input_prompt, api_key)\n",
    "# if video_urls:\n",
    "#     generate_video_from_clips(video_urls, \"output_video.mp4\")\n",
    "# else:\n",
    "#     print(\"No videos found for the given prompt.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import hf_hub_download\n",
    "# from transformers import pipeline\n",
    "\n",
    "# def generate_video_with_ltx_model(text):\n",
    "#     # Load the Lightricks/LTX-Video model\n",
    "#     video_generator = pipeline(\"text-to-video\", model=\"Lightricks/LTX-Video\")\n",
    "    \n",
    "#     # Generate video from the input text\n",
    "#     video_output = video_generator(text)\n",
    "    \n",
    "#     return video_output\n",
    "\n",
    "# # Example usage\n",
    "# input_text = \"20% of users own an iPhone, 50% own a Samsung, and the rest own a variety of brands\"\n",
    "# video_output = generate_video_with_ltx_model(input_text)\n",
    "# print(\"Generated Video Output:\", video_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sample code impkemtaion using different tecnhique "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import spacy\n",
    "# from transformers import pipeline\n",
    "\n",
    "# # Load the spaCy model for NLP tasks\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# def analyze_text(input_text):\n",
    "#     # Analyze the input text using spaCy\n",
    "#     doc = nlp(input_text)\n",
    "    \n",
    "#     # Extract keywords and entities\n",
    "#     keywords = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
    "#     entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    \n",
    "#     return keywords, entities\n",
    "\n",
    "# def generate_video_from_text(input_text, api_key):\n",
    "#     # Step 1: Analyze the input text\n",
    "#     keywords, entities = analyze_text(input_text)\n",
    "#     print(\"Keywords:\", keywords)\n",
    "#     print(\"Entities:\", entities)\n",
    "    \n",
    "#     # Step 2: Fetch video clips based on keywords\n",
    "#     video_urls = []\n",
    "#     for keyword in keywords:\n",
    "#         video_urls.extend(fetch_videos_from_pexels(keyword, api_key))\n",
    "    \n",
    "#     # Step 3: Generate video from fetched clips\n",
    "#     if video_urls:\n",
    "#         generate_video_from_clips(video_urls, \"output_video.mp4\")\n",
    "#     else:\n",
    "#         print(\"No videos found for the given keywords.\")\n",
    "\n",
    "# # Example usage\n",
    "# input_text = \"A beautiful sunset over the mountains\"\n",
    "# generate_video_from_text(input_text, api_key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# from moviepy.editor import ImageClip, concatenate_videoclips, TextClip, CompositeVideoClip\n",
    "# import re\n",
    "# from matplotlib.animation import FuncAnimation\n",
    "\n",
    "# # Step 1: Text Input Handling\n",
    "# def get_text_input():\n",
    "#     # Simulating user input for demonstration purposes\n",
    "#     return \"\"\"\n",
    "#     Sales Data:\n",
    "#     Product A: 150\n",
    "#     Product B: 200\n",
    "#     Product C: 100\n",
    "#     \"\"\"\n",
    "\n",
    "# # Step 2: Text Analysis and Data Extraction\n",
    "# def extract_data_from_text(text):\n",
    "#     data = {}\n",
    "#     lines = text.strip().split('\\n')\n",
    "#     for line in lines:\n",
    "#         match = re.match(r'(\\w+):\\s*(\\d+)', line)\n",
    "#         if match:\n",
    "#             label, value = match.groups()\n",
    "#             data[label] = int(value)\n",
    "#     return data\n",
    "\n",
    "# # Step 3: Data Visualization\n",
    "# def create_visualization(data):\n",
    "#     # Create a DataFrame using pandas\n",
    "#     df = pd.DataFrame(list(data.items()), columns=['Product', 'Sales'])\n",
    "\n",
    "#     # Create a figure and axis for the plot\n",
    "#     fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "#     # Create a bar chart for sales data\n",
    "#     bars = ax.bar(df['Product'], df['Sales'], color='skyblue')\n",
    "\n",
    "#     # Add data labels on top of each bar\n",
    "#     for bar in bars:\n",
    "#         yval = bar.get_height()\n",
    "#         ax.text(bar.get_x() + bar.get_width()/2, yval, yval, va='bottom', ha='center', fontsize=12)\n",
    "\n",
    "#     # Set labels and title\n",
    "#     ax.set_xlabel('Products', fontsize=14)\n",
    "#     ax.set_ylabel('Sales', fontsize=14)\n",
    "#     ax.set_title('Sales Data Visualization', fontsize=16)\n",
    "\n",
    "#     # Save the visualization as an image\n",
    "#     plt.savefig('bar_chart.png', bbox_inches='tight')  # Save with tight layout\n",
    "#     plt.close()\n",
    "    \n",
    "#     # Create an animated version of the bar chart\n",
    "#     create_animation(df)\n",
    "\n",
    "# def create_animation(df):\n",
    "#     # Create a figure for the animation\n",
    "#     fig, ax = plt.subplots(figsize=(10, 6))\n",
    "#     ax.set_xlim(0, len(df))\n",
    "    \n",
    "#     # Ensure that the maximum sales value is valid before setting ylim\n",
    "#     max_sales = df['Sales'].max() if not df['Sales'].empty else 0\n",
    "#     ax.set_ylim(0, max_sales * 1.1)\n",
    "    \n",
    "#     ax.set_xlabel('Products', fontsize=14)\n",
    "#     ax.set_ylabel('Sales', fontsize=14)\n",
    "#     ax.set_title('Animated Sales Data Visualization', fontsize=16)\n",
    "\n",
    "#     # Create a bar container\n",
    "#     bars = ax.bar(df['Product'], [0]*len(df), color='skyblue')\n",
    "\n",
    "#     # Animation function\n",
    "#     def animate(i):\n",
    "#         for bar, new_height in zip(bars, df['Sales']):\n",
    "#             bar.set_height(new_height * (i / 10))  # Animate to full height over 10 frames\n",
    "#         return bars\n",
    "\n",
    "#     # Create the animation\n",
    "#     ani = FuncAnimation(fig, animate, frames=10, interval=200, blit=True)\n",
    "#     ani.save('animated_bar_chart.gif', writer='pillow', fps=10)  # Save the animation as a GIF instead of MP4\n",
    "\n",
    "# # Step 4: Video Composition\n",
    "# def create_video(image_files, video_urls):\n",
    "#     clips = [ImageClip(img).set_duration(3) for img in image_files]  # Each image displayed for 3 seconds\n",
    "#     video_clips = []\n",
    "    \n",
    "#     for url in video_urls:\n",
    "#         try:\n",
    "#             video_clip = ImageClip(url).set_duration(3)  # Set duration for each video clip\n",
    "#             video_clips.append(video_clip)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error loading video from {url}: {e}\")\n",
    "\n",
    "#     clips.extend(video_clips)  # Combine image clips with video clips\n",
    "\n",
    "#     if clips:  # Check if there are any clips to concatenate\n",
    "#         final_video = concatenate_videoclips(clips)\n",
    "#         if hasattr(final_video, 'duration') and final_video.duration is not None and final_video.duration > 0:  # Ensure duration is set and positive\n",
    "#             final_video.write_videofile(\"infographic_video.mp4\", codec=\"libx264\")\n",
    "#         else:\n",
    "#             print(\"Final video duration is not set or is zero. Cannot write video file.\")\n",
    "#     else:\n",
    "#         print(\"No clips to create a video.\")\n",
    "\n",
    "# def add_text_overlay(image_file, text):\n",
    "#     image_clip = ImageClip(image_file).set_duration(3)\n",
    "#     text_clip = TextClip(text, fontsize=50, color='white', bg_color='black', size=image_clip.size)\n",
    "#     text_clip = text_clip.set_position('bottom').set_duration(image_clip.duration)\n",
    "#     return CompositeVideoClip([image_clip, text_clip])\n",
    "\n",
    "# # Main Function\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Step 1: Get text input\n",
    "#     text_input = get_text_input()\n",
    "    \n",
    "#     # Step 2: Extract data from text\n",
    "#     extracted_data = extract_data_from_text(text_input)\n",
    "#     print(\"Extracted Data:\", extracted_data)\n",
    "    \n",
    "#     # Step 3: Create visualizations\n",
    "#     create_visualization(extracted_data)\n",
    "    \n",
    "#     # Step 4: Prepare video with text overlay\n",
    "#     image_files = ['bar_chart.png']\n",
    "#     video_urls = []\n",
    "    \n",
    "#     for label in extracted_data.keys():\n",
    "#         overlay_text = f\"{label}: {extracted_data[label]}\"\n",
    "#         video_urls.append(add_text_overlay('bar_chart.png', overlay_text))\n",
    "    \n",
    "#     # Create the final video\n",
    "#     create_video(image_files, video_urls)\n",
    "    \n",
    "#     print(\"Infographic video generated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# from moviepy.editor import ImageClip, concatenate_videoclips, TextClip, CompositeVideoClip\n",
    "# import re\n",
    "\n",
    "# # Step 1: Text Input Handling\n",
    "# def get_text_input():\n",
    "#     # Simulating user input for demonstration purposes\n",
    "#     return \"\"\"\n",
    "#     Sales Data:\n",
    "#     Product A: 150\n",
    "#     Product B: 200\n",
    "#     Product C: 100\n",
    "#     \"\"\"\n",
    "\n",
    "# # Step 2: Text Analysis and Data Extraction\n",
    "# def extract_data_from_text(text):\n",
    "#     data = {}\n",
    "#     lines = text.strip().split('\\n')\n",
    "#     for line in lines:\n",
    "#         match = re.match(r'(\\w+):\\s*(\\d+)', line)\n",
    "#         if match:\n",
    "#             label, value = match.groups()\n",
    "#             data[label] = int(value)\n",
    "#     return data\n",
    "\n",
    "# # Step 3: Data Visualization\n",
    "# def create_bar_chart(data, title):\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.bar(data.keys(), data.values(), color='skyblue')\n",
    "#     plt.title(title)\n",
    "#     plt.xlabel('Products')\n",
    "#     plt.ylabel('Sales')\n",
    "#     plt.xticks(rotation=45)\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig('bar_chart.png')  # Save the chart as an image\n",
    "#     plt.close()\n",
    "\n",
    "# # Step 4: Video Composition\n",
    "# def create_video(image_files):\n",
    "#     clips = [ImageClip(img).set_duration(3) for img in image_files]  # Each image displayed for 3 seconds\n",
    "#     final_video = concatenate_videoclips(clips)\n",
    "#     final_video.write_videofile(\"infographic_video.mp4\", codec=\"libx264\")\n",
    "\n",
    "# def add_text_overlay(image_file, text):\n",
    "#     image_clip = ImageClip(image_file).set_duration(3)\n",
    "#     text_clip = TextClip(text, fontsize=50, color='white', bg_color='black', size=image_clip.size)\n",
    "#     text_clip = text_clip.set_position('bottom').set_duration(image_clip.duration)\n",
    "#     return CompositeVideoClip([image_clip, text_clip])\n",
    "\n",
    "# # Main Function\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Step 1: Get text input\n",
    "#     text_input = get_text_input()\n",
    "    \n",
    "#     # Step 2: Extract data from text\n",
    "#     extracted_data = extract_data_from_text(text_input)\n",
    "#     print(\"Extracted Data:\", extracted_data)\n",
    "    \n",
    "#     # Step 3: Create visualizations\n",
    "#     create_bar_chart(extracted_data, \"Sales Data Overview\")\n",
    "    \n",
    "#     # Step 4: Prepare video with text overlay\n",
    "#     image_files = ['bar_chart.png']\n",
    "#     video_clips = []\n",
    "    \n",
    "#     # Create a video clip for the bar chart with overlay text\n",
    "#     overlay_text = \"Sales Data Overview\"\n",
    "#     video_clips.append(add_text_overlay('bar_chart.png', overlay_text))\n",
    "    \n",
    "#     # Create the final video\n",
    "#     create_video([clip for clip in video_clips])\n",
    "\n",
    "#     print(\"Infographic video generated successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working code we can go with \n",
    "# Code 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed Data: {'beverage': 'stats report on 30 percentage'}\n",
      "Generated Video URLs: ['https://videos.pexels.com/video-files/5839005/5839005-hd_1080_1920_24fps.mp4', 'https://videos.pexels.com/video-files/7947455/7947455-sd_960_540_30fps.mp4', 'https://videos.pexels.com/video-files/7947425/7947425-sd_426_240_30fps.mp4']\n"
     ]
    }
   ],
   "source": [
    "import requests  # Ensure requests is imported\n",
    "from textblob import TextBlob\n",
    "import spacy\n",
    "import moviepy\n",
    "import  nltk\n",
    "\n",
    "\n",
    "# Hardcoded API keys\n",
    "PEXELS_API_KEY = 'yepFtS82dEUPX41sHUOMVzris34EohIYvW8Czo5Z5s6KQ2WHPPe4eIQA'\n",
    "\n",
    "# Step 1: Data Understanding\n",
    "\n",
    "def parse_input_text(text):\n",
    "    # Extract relevant data points from the input text\n",
    "    data_points = {}\n",
    "    parts = text.split(',')\n",
    "    for part in parts:\n",
    "        part = part.strip()\n",
    "        if '%' in part:\n",
    "            key, value = part.split('%')\n",
    "            data_points[key.strip()] = float(value.strip().replace('%', '')) / 100\n",
    "        else:\n",
    "            # Handle cases where the part does not contain a percentage\n",
    "            try:\n",
    "                # Check if the part contains a valid key-value pair\n",
    "                key_value = part.split(' ', 1)\n",
    "                if len(key_value) == 2:\n",
    "                    key, value = key_value\n",
    "                    data_points[key.strip()] = value.strip()\n",
    "                else:\n",
    "                    # Attempt to convert to float if it looks like a number\n",
    "                    try:\n",
    "                        data_points[part] = float(part)\n",
    "                    except ValueError:\n",
    "                        print(f\"Could not parse part: '{part}'\")\n",
    "            except ValueError:\n",
    "                print(f\"Could not parse part: '{part}'\")\n",
    "                continue\n",
    "\n",
    "    # Additional processing to convert data points into relevant information\n",
    "    relevant_info = {}\n",
    "    for key, value in data_points.items():\n",
    "        if isinstance(value, float):\n",
    "            relevant_info[key] = f\"{value * 100}%\"\n",
    "        else:\n",
    "            relevant_info[key] = value\n",
    "\n",
    "    return relevant_info  # Return a dictionary of relevant information\n",
    "\n",
    "# Step 2: Text Processing\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase for consistency\n",
    "    cleaned_text = text.strip().lower()\n",
    "    \n",
    "    # Remove duplicates and null values\n",
    "    cleaned_text = ' '.join(sorted(set(cleaned_text.split()), key=lambda x: cleaned_text.index(x)))\n",
    "    \n",
    "    return cleaned_text  # Return the cleaned text\n",
    "\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    # Analyze the sentiment of the input text\n",
    "    analysis = TextBlob(text)\n",
    "    return analysis.sentiment.polarity  # Return the sentiment polarity\n",
    "\n",
    "def semantic_segment_transformation(text):\n",
    "    # Convert the given prompt into a contextual prompt\n",
    "    contextual_prompt = f\"Contextual prompt based on: {text}\"\n",
    "\n",
    "    return contextual_prompt  # Return the contextual prompt\n",
    "\n",
    "# # Process the semantic segment transformation text to generate relevant video\n",
    "# contextual_prompt = semantic_segment_transformation(\"give the employer score among the different companies\")\n",
    "# video_frames = generate_video_from_text(contextual_prompt)\n",
    "# print(\"Generated Video URLs:\", video_frames)\n",
    "\n",
    "def generate_video_from_text(text):\n",
    "    # Process the semantic segment transformation text to generate relevant video\n",
    "    contextual_prompt = semantic_segment_transformation(text)\n",
    "\n",
    "\n",
    "    # Preprocess the input text\n",
    "    processed_prompt = preprocess_text(contextual_prompt)\n",
    "\n",
    "    # Generate a prompt for visualization based on the input data\n",
    "    visualization_prompt = f\"Create an animated infographic video showing the distribution of: {processed_prompt}\"\n",
    "\n",
    "    # Use Pexels API to generate infographic videos\n",
    "    headers = {'Authorization': PEXELS_API_KEY}\n",
    "    params = {'query': f'infographics {visualization_prompt}', 'per_page': 5}\n",
    "    \n",
    "    # Rate limiting to avoid exhausting the API\n",
    "    time.sleep(3)  # Wait for 3 seconds between requests\n",
    "    response = requests.get('https://api.pexels.com/videos/search', headers=headers, params=params)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Pexels API request failed with status code {response.status_code}\")\n",
    "\n",
    "    videos = response.json().get('videos', [])\n",
    "    video_urls = [video['video_files'][0]['link'] for video in videos if video['video_files']]\n",
    "    \n",
    "    # Additional rate limiting before returning the URLs\n",
    "    time.sleep(3)  # Wait for 2 seconds before returning the video URLs\n",
    "    return video_urls[:3]  # Return only the first 3 video URLs\n",
    "    # processed_prompt = preprocess_text(text)\n",
    "\n",
    "    # # Generate a prompt for visualization based on the input data\n",
    "    # visualization_prompt = f\"Create an animated infographic video showing the distribution of: {processed_prompt}\"\n",
    "\n",
    "    # # Use Pexels API to generate infographic videos\n",
    "    # headers = {'Authorization': PEXELS_API_KEY}\n",
    "    # params = {'query': f'infographics {visualization_prompt}', 'per_page': 5}\n",
    "    \n",
    "    # # Rate limiting to avoid exhausting the API\n",
    "    # time.sleep(3)  # Wait for 3 seconds between requests\n",
    "    # response = requests.get('https://api.pexels.com/videos/search', headers=headers, params=params)\n",
    "    \n",
    "    # if response.status_code != 200:\n",
    "    #     raise Exception(f\"Pexels API request failed with status code {response.status_code}\")\n",
    "\n",
    "    # videos = response.json().get('videos', [])\n",
    "    # video_urls = [video['video_files'][0]['link'] for video in videos if video['video_files']]\n",
    "    \n",
    "    # # Additional rate limiting before returning the URLs\n",
    "    # time.sleep(3)  # Wait for 2 seconds before returning the video URLs\n",
    "    # return video_urls[:3]  # Return only the first 3 video URLs\n",
    "\n",
    "# Main function\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_text = \"beverage stats report on 30 percentage \"\n",
    "    \n",
    "    try:\n",
    "        data = parse_input_text(input_text)\n",
    "        print(\"Parsed Data:\", data)\n",
    "\n",
    "        video_frames = generate_video_from_text(input_text)\n",
    "        print(\"Generated Video URLs:\", video_frames)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic Approach  - work going on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import moviepy.editor as mpy\n",
    "# import os\n",
    "# import re\n",
    "\n",
    "# # Hardcoded Pexels API key\n",
    "# PEXELS_API_KEY = \"yepFtS82dEUPX41sHUOMVzris34EohIYvW8Czo5Z5s6KQ2WHPPe4eIQA\"  # Replace with your actual Pexels API key\n",
    "\n",
    "# class VideoGenerationAgent:\n",
    "#     def __init__(self, api_key):\n",
    "#         self.api_key = api_key\n",
    "\n",
    "#     def search_videos(self, query_string):\n",
    "#         url = \"https://api.pexels.com/videos/search\"\n",
    "#         headers = {\n",
    "#             \"Authorization\": self.api_key,\n",
    "#             \"User-Agent\": \"Mozilla/5.0\"\n",
    "#         }\n",
    "#         params = {\n",
    "#             \"query\": query_string,\n",
    "#             \"orientation\": \"landscape\",\n",
    "#             \"per_page\": 15\n",
    "#         }\n",
    "#         response = requests.get(url, headers=headers, params=params)\n",
    "#         return response.json()\n",
    "\n",
    "#     def analyze_data(self, context_text):\n",
    "#         if \"growth\" in context_text or \"increase\" in context_text:\n",
    "#             return \"line_chart\"\n",
    "#         elif \"distribution\" in context_text:\n",
    "#             return \"bar_chart\"\n",
    "#         elif \"comparison\" in context_text:\n",
    "#             return \"pie_chart\"\n",
    "#         else:\n",
    "#             return None\n",
    "\n",
    "#     def create_visualization(self, data, visualization_type):\n",
    "#         if visualization_type == \"line_chart\":\n",
    "#             plt.plot(data['x'], data['y'].astype(float))\n",
    "#             plt.title('Growth Over Time')\n",
    "#             plt.xlabel('Time')\n",
    "#             plt.ylabel('Value')\n",
    "#             plt.grid()\n",
    "#             plt.savefig('line_chart.png')\n",
    "#         elif visualization_type == \"bar_chart\":\n",
    "#             plt.bar(data['categories'], data['values'].astype(float))\n",
    "#             plt.title('Distribution of Values')\n",
    "#             plt.xlabel('Categories')\n",
    "#             plt.ylabel('Values')\n",
    "#             plt.savefig('bar_chart.png')\n",
    "#         elif visualization_type == \"pie_chart\":\n",
    "#             plt.pie(data['values'].astype(float), labels=data['categories'], autopct='%1.1f%%')\n",
    "#             plt.title('Comparison of Categories')\n",
    "#             plt.savefig('pie_chart.png')\n",
    "#         plt.close()\n",
    "\n",
    "#     def generate_video_from_visualization(self):\n",
    "#         image_files = ['line_chart.png', 'bar_chart.png', 'pie_chart.png']\n",
    "#         if all(os.path.exists(img) for img in image_files):\n",
    "#             clip = mpy.ImageSequenceClip(image_files, fps=1)\n",
    "#             output_video_path = 'data_visualization.mp4'\n",
    "#             clip.write_videofile(output_video_path)\n",
    "#             print(f\"Video saved at: {output_video_path}\")\n",
    "#         else:\n",
    "#             print(\"One or more visualization files are missing.\")\n",
    "\n",
    "#     def generate_video_from_text(self, context_text):\n",
    "#         visualization_type = self.analyze_data(context_text)\n",
    "#         print(f\"Analyzing context: {context_text}\")\n",
    "        \n",
    "#         videos = self.search_videos(context_text)\n",
    "#         if videos and 'videos' in videos:\n",
    "#             print(f\"Found {len(videos['videos'])} videos for the context.\")\n",
    "        \n",
    "#         # Example data for visualization\n",
    "#         data = {\n",
    "#             'x': np.arange(10),\n",
    "#             'y': np.random.randint(1, 10, size=10).astype(float),\n",
    "#             'categories': ['A', 'B', 'C', 'D'],\n",
    "#             'values': [15.0, 30.0, 45.0, 10.0]\n",
    "#         }\n",
    "        \n",
    "#         if visualization_type:\n",
    "#             self.create_visualization(data, visualization_type)\n",
    "#             self.generate_video_from_visualization()\n",
    "#         else:\n",
    "#             print(\"No suitable visualization type found.\")\n",
    "\n",
    "# # Example usage\n",
    "# if __name__ == '__main__':\n",
    "#     user_input = \"The growth of sales over the last decade shows a significant increase.\"\n",
    "#     agent = VideoGenerationAgent(PEXELS_API_KEY)\n",
    "#     agent.generate_video_from_text(user_input)\n",
    "#     print(\"Video generated successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
