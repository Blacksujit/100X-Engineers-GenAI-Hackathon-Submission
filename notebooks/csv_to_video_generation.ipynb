{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script imports the necessary libraries for a comprehensive data processing, visualization, and video generation pipeline.\n",
    "Libraries:\n",
    "- pandas: Data manipulation and analysis.\n",
    "- numpy: Numerical operations.\n",
    "- seaborn: Statistical data visualization.\n",
    "- sklearn.model_selection: Splitting data into training and testing sets.\n",
    "- sklearn.preprocessing: Standardizing features.\n",
    "- sklearn.linear_model: Implementing linear regression models.\n",
    "- sklearn.metrics: Evaluating model performance.\n",
    "- pandas.read_csv, pandas.read_excel: Reading data from CSV and Excel files.\n",
    "- scipy.stats: Statistical functions.\n",
    "- moviepy.editor: Video editing and creation.\n",
    "- gtts: Text-to-speech conversion.\n",
    "- matplotlib.pyplot: Plotting graphs and charts.\n",
    "\"\"\"\n",
    "# Loading all The necessary Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from pandas import read_csv, read_excel\n",
    "from scipy import stats\n",
    "from moviepy.editor import VideoClip, concatenate_videoclips\n",
    "from gtts import gTTS\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from scipy.signal import savgol_filter\n",
    "from time import perf_counter\n",
    "import math\n",
    "# from config_loader import load_config_ani, load_config_setup\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "import gtts\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, AutoModelForTokenClassification\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip, ImageSequenceClip\n",
    "import re\n",
    "import shutil\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import imageio\n",
    "import uuid\n",
    "from transformers import pipeline, T5ForConditionalGeneration, T5TokenizerFast\n",
    "import re\n",
    "import os\n",
    "import uuid\n",
    "import gtts\n",
    "from textblob import TextBlob\n",
    "from langdetect import detect\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from pandas import read_csv, read_excel\n",
    "from scipy import stats\n",
    "from moviepy.editor import VideoClip, concatenate_videoclips, VideoFileClip, AudioFileClip, ImageSequenceClip\n",
    "from gtts import gTTS\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import os\n",
    "import pickle\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, AutoModelForTokenClassification\n",
    "import re\n",
    "import shutil\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import imageio\n",
    "import uuid\n",
    "from diffusers import DiffusionPipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from pandas import read_csv, read_excel\n",
    "from scipy import stats\n",
    "from moviepy.editor import VideoClip, concatenate_videoclips, VideoFileClip, AudioFileClip, ImageSequenceClip, TextClip, CompositeVideoClip\n",
    "from gtts import gTTS\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import os\n",
    "import pickle\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import re\n",
    "import shutil\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import imageio\n",
    "import uuid\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from pandas import read_csv, read_excel\n",
    "from scipy import stats\n",
    "from moviepy.editor import VideoClip, concatenate_videoclips, VideoFileClip, AudioFileClip, ImageSequenceClip, TextClip, CompositeVideoClip, ImageClip\n",
    "from gtts import gTTS\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import os\n",
    "import pickle\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import re\n",
    "import shutil\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import imageio\n",
    "import uuid\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from pandas import read_csv, read_excel\n",
    "from scipy import stats\n",
    "from gtts import gTTS\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import os\n",
    "import pickle\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import re\n",
    "import shutil\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import imageio\n",
    "import uuid\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from manim import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the HF_HOME environment variable to change the cache path\n",
    "os.environ['HF_HOME'] = \"D:\\\\cahc_models_folder\"  # Change this to your desired cache path\n",
    "\n",
    "# Load the model and tokenizer from .pkl files\n",
    "models_dir = os.path.abspath(os.path.join(os.getcwd(), 'models'))\n",
    "\n",
    "with open(os.path.join(models_dir, 'model.pkl'), 'rb') as model_file:\n",
    "    summary_model = pickle.load(model_file)\n",
    "\n",
    "with open(os.path.join(models_dir, 'tokenizer.pkl'), 'rb') as tokenizer_file:\n",
    "    summary_tokenizer = pickle.load(tokenizer_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    if file_path.endswith('.csv'):\n",
    "        df = pd.read_csv(file_path)\n",
    "    elif file_path.endswith('.xlsx'):\n",
    "        df = pd.read_excel(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INITIAL CODE IMPLEMNTATION NOT IN USE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Install the vaderSentiment package\n",
    "# # %pip install vaderSentiment\n",
    "\n",
    "# from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# # Load the model and tokenizer\n",
    "# # summary_model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
    "# # summary_tokenizer = T5TokenizerFast.from_pretrained('t5-base')\n",
    "\n",
    "# # Initialize sentiment analyzer\n",
    "# vader_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# # NLP Pipeline Function\n",
    "# def nlp_pipeline(text):\n",
    "#     # Prepare input\n",
    "#     input_text = f\"summarize: {text}\"\n",
    "#     inputs = summary_tokenizer.encode(input_text, return_tensors='pt', max_length=512, truncation=True)\n",
    "\n",
    "#     # Generate summary\n",
    "#     outputs = summary_model.generate(inputs, max_length=100)\n",
    "#     summary_text = summary_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "#     # Extract percentages and categories using regex patterns\n",
    "#     percentages = [int(x.strip('%')) for x in re.findall(r'\\d+%', text)]\n",
    "#     words = text.split()\n",
    "#     categories = []\n",
    "\n",
    "#     # Find words after \"use\" or \"uses\"\n",
    "#     for i, word in enumerate(words):\n",
    "#         if word.lower() in ['use', 'uses'] and i + 1 < len(words):\n",
    "#             categories.append(words[i + 1])\n",
    "\n",
    "#     if not percentages or not categories:\n",
    "#         percentages = [100]\n",
    "#         categories = ['Summary']\n",
    "\n",
    "#     # Sentiment analysis\n",
    "#     sentiment = vader_analyzer.polarity_scores(summary_text)\n",
    "#     sentiment_label = 'positive' if sentiment['compound'] >= 0.05 else 'negative' if sentiment['compound'] <= -0.05 else 'neutral'\n",
    "\n",
    "#     # Text correction and language detection\n",
    "#     blob = TextBlob(summary_text)\n",
    "#     corrected_text = str(blob.correct())\n",
    "#     language = detect(corrected_text)  # Use langdetect to detect language\n",
    "\n",
    "#     # Generate audio\n",
    "#     tts = gtts.gTTS(corrected_text, lang='en')\n",
    "#     audio_filename = f'summary_audio_{uuid.uuid4().hex}.mp3'\n",
    "#     audio_path = os.path.join('D:\\\\1OOx-enginners-hackathon-submission-2\\\\uploads\\\\audio_files', audio_filename)\n",
    "#     tts.save(audio_path)\n",
    "\n",
    "#     return {\n",
    "#         'categories': categories,\n",
    "#         'values': percentages,\n",
    "#         'text': corrected_text,\n",
    "#         'audio_path': audio_path,\n",
    "#         'sentiment': sentiment_label,\n",
    "#         'language': language\n",
    "#     }\n",
    "\n",
    "# # Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     text = \"20% of users own an iPhone, 50% own a Samsung, and the rest own a variety of brands\"\n",
    "#     summary = nlp_pipeline(text)\n",
    "#     print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def nlp_pipeline(text):\n",
    "#     # Prepare input\n",
    "#     input_text = f\"summarize: {text}\"\n",
    "#     inputs = summary_tokenizer.encode(input_text, return_tensors='pt', max_length=512, truncation=True)\n",
    "\n",
    "#     # Generate summary\n",
    "#     outputs = summary_model.generate(inputs, max_length=100)\n",
    "#     summary_text = summary_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "#     # Extract percentages and categories using regex patterns\n",
    "#     percentages = [int(x.strip('%')) for x in re.findall(r'\\d+%', text)]\n",
    "#     words = text.split()\n",
    "#     categories = []\n",
    "\n",
    "#     # Find words after \"use\" or \"uses\"\n",
    "#     for i, word in enumerate(words):\n",
    "#         if word.lower() in ['use', 'uses'] and i + 1 < len(words):\n",
    "#             categories.append(words[i + 1])\n",
    "\n",
    "#     if not percentages or not categories:\n",
    "#         percentages = [100]\n",
    "#         categories = ['Summary']\n",
    "\n",
    "#     # Generate audio\n",
    "#     tts = gTTS(summary_text, lang='en')\n",
    "#     audio_filename = f'summary_audio_{uuid.uuid4().hex}.mp3'\n",
    "#     audio_path = os.path.join('D:\\\\1OOx-enginners-hackathon-submission-2\\\\uploads\\\\audio_files', audio_filename)\n",
    "#     tts.save(audio_path)\n",
    "\n",
    "#     # return {\n",
    "#     #     'categories': categories,\n",
    "#     #     'values': percentages,\n",
    "#     #     'text': summary_text,\n",
    "#     #     'audio_path': audio_path\n",
    "#     # }\n",
    "#     # Sentiment analysis\n",
    "#     sentiment = TextBlob(summary_text).sentiment\n",
    "#     sentiment_label = 'positive' if sentiment.polarity >= 0.05 else 'negative' if sentiment.polarity <= -0.05 else 'neutral'\n",
    "\n",
    "#     # Text correction and language detection\n",
    "#     blob = TextBlob(summary_text)\n",
    "#     corrected_text = str(blob.correct())\n",
    "#     language = detect(corrected_text)\n",
    "\n",
    "#     # Generate audio\n",
    "#     tts = gTTS(corrected_text, lang='en')\n",
    "#     audio_filename = f'summary_audio_{uuid.uuid4().hex}.mp3'\n",
    "#     audio_path = os.path.join('D:\\\\1OOx-enginners-hackathon-submission-2\\\\uploads\\\\audio_files', audio_filename)\n",
    "#     tts.save(audio_path)\n",
    "\n",
    "#     return {\n",
    "#         'categories': categories,\n",
    "#         'values': percentages,\n",
    "#         'text': corrected_text,\n",
    "#         'audio_path': audio_path,\n",
    "#         'sentiment': sentiment_label,\n",
    "#         'language': language\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# def create_detailed_infographic(summary):\n",
    "#     \"\"\"\n",
    "#     Creates a static detailed infographic for data storytelling\n",
    "#     \"\"\"\n",
    "#     categories = summary['categories']\n",
    "#     values = summary['values']\n",
    "#     sentiment = summary.get('sentiment', 'neutral')\n",
    "#     language = summary.get('language', 'en')\n",
    "\n",
    "#     # Create figure with subplots\n",
    "#     fig = plt.figure(figsize=(18, 48))  # Increase the figure size to accommodate more subplots\n",
    "\n",
    "#     # Main bar plot\n",
    "#     ax1 = plt.subplot2grid((13, 2), (0, 0), colspan=2)  # Increase the grid size to (13, 2)\n",
    "#     bars = ax1.bar(categories, values, color='skyblue', edgecolor='black')\n",
    "#     ax1.set_title('Market Share Distribution', fontsize=20, pad=20)\n",
    "#     ax1.set_ylabel('Percentage (%)', fontsize=14)\n",
    "#     ax1.set_xlabel('Categories', fontsize=14)\n",
    "\n",
    "#     # Add value labels\n",
    "#     for bar in bars:\n",
    "#         height = bar.get_height()\n",
    "#         ax1.text(bar.get_x() + bar.get_width() / 2., height,\n",
    "#                  f'{int(height)}%',\n",
    "#                  ha='center', va='bottom', fontsize=12, color='black')\n",
    "\n",
    "#     # Pie chart\n",
    "#     ax2 = plt.subplot2grid((13, 2), (1, 0))\n",
    "#     wedges, texts, autotexts = ax2.pie(values, labels=categories, autopct='%1.1f%%', startangle=140, colors=plt.cm.Paired.colors)\n",
    "#     for text in texts + autotexts:\n",
    "#         text.set_fontsize(12)\n",
    "#     ax2.set_title('Market Share Proportion', fontsize=16)\n",
    "\n",
    "#     # Additional insights text\n",
    "#     ax3 = plt.subplot2grid((13, 2), (1, 1))\n",
    "#     ax3.axis('off')\n",
    "#     total = sum(values)\n",
    "#     insights_text = f\"\"\"Key Insights:\n",
    "\n",
    "#     • Total market coverage: {total}%\n",
    "#     • Leading brand: {categories[values.index(max(values))]}\n",
    "#     • Market share gap: {max(values) - min(values)}%\n",
    "#     • Sentiment: {sentiment.capitalize()}\n",
    "#     • Language: {language.upper()}\n",
    "#     \"\"\"\n",
    "#     ax3.text(0, 0.5, insights_text, fontsize=14, va='center', ha='left')\n",
    "\n",
    "#     # Line plot\n",
    "#     ax4 = plt.subplot2grid((13, 2), (2, 0), colspan=2)\n",
    "#     ax4.plot(categories, values, marker='o', linestyle='-', color='b')\n",
    "#     ax4.set_title('Market Share Trend', fontsize=16)\n",
    "#     ax4.set_ylabel('Percentage (%)', fontsize=14)\n",
    "#     ax4.set_xlabel('Categories', fontsize=14)\n",
    "#     for i, value in enumerate(values):\n",
    "#         ax4.text(i, value, f'{value}%', ha='center', va='bottom', fontsize=12, color='black')\n",
    "\n",
    "#     # Scatter plot\n",
    "#     ax5 = plt.subplot2grid((13, 2), (3, 0))\n",
    "#     ax5.scatter(categories, values, color='r')\n",
    "#     ax5.set_title('Market Share Scatter Plot', fontsize=16)\n",
    "#     ax5.set_ylabel('Percentage (%)', fontsize=14)\n",
    "#     ax5.set_xlabel('Categories', fontsize=14)\n",
    "#     for i, value in enumerate(values):\n",
    "#         ax5.text(i, value, f'{value}%', ha='center', va='bottom', fontsize=12, color='black')\n",
    "\n",
    "#     # Box plot\n",
    "#     ax6 = plt.subplot2grid((13, 2), (3, 1))\n",
    "#     ax6.boxplot(values, vert=False, patch_artist=True)\n",
    "#     ax6.set_title('Market Share Box Plot', fontsize=16)\n",
    "#     ax6.set_xlabel('Percentage (%)', fontsize=14)\n",
    "#     ax6.set_yticklabels(['Market Share'])\n",
    "\n",
    "#     # Histogram\n",
    "#     ax7 = plt.subplot2grid((13, 2), (4, 0))\n",
    "#     ax7.hist(values, bins=10, color='purple', edgecolor='black')\n",
    "#     ax7.set_title('Market Share Histogram', fontsize=16)\n",
    "#     ax7.set_xlabel('Percentage (%)', fontsize=14)\n",
    "#     ax7.set_ylabel('Frequency', fontsize=14)\n",
    "\n",
    "#     # Heatmap\n",
    "#     ax8 = plt.subplot2grid((13, 2), (4, 1))\n",
    "#     heatmap_data = np.array(values).reshape(-1, 1)\n",
    "#     sns.heatmap(heatmap_data, annot=True, fmt=\"d\", cmap='coolwarm', ax=ax8)\n",
    "#     ax8.set_title('Market Share Heatmap', fontsize=16)\n",
    "\n",
    "#     # Violin plot\n",
    "#     ax9 = plt.subplot2grid((13, 2), (5, 0))\n",
    "#     sns.violinplot(data=values, ax=ax9)\n",
    "#     ax9.set_title('Market Share Violin Plot', fontsize=16)\n",
    "#     ax9.set_xlabel('Market Share', fontsize=14)\n",
    "\n",
    "#     # Pair plot\n",
    "#     sns.pairplot(pd.DataFrame({'Categories': categories, 'Values': values}))\n",
    "#     plt.suptitle('Market Share Pair Plot', fontsize=16)\n",
    "\n",
    "#     # KDE plot\n",
    "#     ax11 = plt.subplot2grid((13, 2), (6, 0))\n",
    "#     sns.kdeplot(values, ax=ax11, shade=True, color='green')\n",
    "#     ax11.set_title('Market Share KDE Plot', fontsize=16)\n",
    "#     ax11.set_xlabel('Percentage (%)', fontsize=14)\n",
    "\n",
    "#     # Joint plot\n",
    "#     ax12 = plt.subplot2grid((13, 2), (6, 1))\n",
    "#     sns.jointplot(x=pd.Categorical(categories).codes, y=values, kind='scatter', ax=ax12)\n",
    "#     ax12.set_title('Market Share Joint Plot', fontsize=16)\n",
    "\n",
    "#     # Swarm plot\n",
    "#     ax13 = plt.subplot2grid((13, 2), (7, 0))\n",
    "#     sns.swarmplot(x=categories, y=values, ax=ax13)\n",
    "#     ax13.set_title('Market Share Swarm Plot', fontsize=16)\n",
    "#     ax13.set_xlabel('Categories', fontsize=14)\n",
    "#     ax13.set_ylabel('Percentage (%)', fontsize=14)\n",
    "\n",
    "#     # Strip plot\n",
    "#     ax14 = plt.subplot2grid((13, 2), (7, 1))\n",
    "#     sns.stripplot(x=categories, y=values, ax=ax14)\n",
    "#     ax14.set_title('Market Share Strip Plot', fontsize=16)\n",
    "#     ax14.set_xlabel('Categories', fontsize=14)\n",
    "#     ax14.set_ylabel('Percentage (%)', fontsize=14)\n",
    "\n",
    "#     # Rug plot\n",
    "#     ax15 = plt.subplot2grid((13, 2), (8, 0))\n",
    "#     sns.rugplot(values, ax=ax15)\n",
    "#     ax15.set_title('Market Share Rug Plot', fontsize=16)\n",
    "#     ax15.set_xlabel('Percentage (%)', fontsize=14)\n",
    "\n",
    "#     # Count plot\n",
    "#     ax16 = plt.subplot2grid((13, 2), (8, 1))\n",
    "#     sns.countplot(x=categories, ax=ax16)\n",
    "#     ax16.set_title('Market Share Count Plot', fontsize=16)\n",
    "#     ax16.set_xlabel('Categories', fontsize=14)\n",
    "#     ax16.set_ylabel('Count', fontsize=14)\n",
    "\n",
    "#     # Boxen plot\n",
    "#     ax17 = plt.subplot2grid((13, 2), (9, 0))\n",
    "#     sns.boxenplot(x=categories, y=values, ax=ax17)\n",
    "#     ax17.set_title('Market Share Boxen Plot', fontsize=16)\n",
    "#     ax17.set_xlabel('Categories', fontsize=14)\n",
    "#     ax17.set_ylabel('Percentage (%)', fontsize=14)\n",
    "\n",
    "#     # Point plot\n",
    "#     ax18 = plt.subplot2grid((13, 2), (9, 1))\n",
    "#     sns.pointplot(x=categories, y=values, ax=ax18)\n",
    "#     ax18.set_title('Market Share Point Plot', fontsize=16)\n",
    "#     ax18.set_xlabel('Categories', fontsize=14)\n",
    "#     ax18.set_ylabel('Percentage (%)', fontsize=14)\n",
    "\n",
    "#     # Residual plot\n",
    "#     ax19 = plt.subplot2grid((13, 2), (10, 0))\n",
    "#     sns.residplot(x=pd.Categorical(categories).codes, y=values, ax=ax19)\n",
    "#     ax19.set_title('Market Share Residual Plot', fontsize=16)\n",
    "#     ax19.set_xlabel('Categories', fontsize=14)\n",
    "#     ax19.set_ylabel('Residuals', fontsize=14)\n",
    "\n",
    "#     # Lm plot\n",
    "#     lm_plot = sns.lmplot(x='Categories', y='Values', data=pd.DataFrame({'Categories': pd.Categorical(categories).codes, 'Values': values}))\n",
    "#     lm_plot.fig.suptitle('Market Share Lm Plot', fontsize=16)\n",
    "\n",
    "#     # PairGrid\n",
    "#     ax21 = plt.subplot2grid((13, 2), (11, 0))\n",
    "#     pairgrid = sns.PairGrid(pd.DataFrame({'Categories': categories, 'Values': values}))\n",
    "#     pairgrid.map(plt.scatter)\n",
    "#     ax21.set_title('Market Share PairGrid', fontsize=16)\n",
    "\n",
    "#     # FacetGrid\n",
    "#     ax22 = plt.subplot2grid((13, 2), (11, 1))\n",
    "#     facetgrid = sns.FacetGrid(pd.DataFrame({'Categories': categories, 'Values': values}), col='Categories')\n",
    "#     facetgrid.map(plt.hist, 'Values')\n",
    "#     ax22.set_title('Market Share FacetGrid', fontsize=16)\n",
    "\n",
    "#     # Heatmap with annotations\n",
    "#     ax23 = plt.subplot2grid((13, 2), (12, 0))\n",
    "#     sns.heatmap(pd.DataFrame({'Categories': categories, 'Values': values}).corr(), annot=True, cmap='coolwarm', ax=ax23)\n",
    "#     ax23.set_title('Market Share Heatmap with Annotations', fontsize=16)\n",
    "\n",
    "#     # Clustermap\n",
    "#     ax24 = plt.subplot2grid((13, 2), (12, 1))\n",
    "#     data_for_clustermap = pd.DataFrame({'Categories': categories, 'Values': values}).corr()\n",
    "#     if data_for_clustermap.shape[0] > 1:  # Ensure there is enough data for clustermap\n",
    "#         sns.clustermap(data_for_clustermap, annot=True, cmap='coolwarm')\n",
    "#         ax24.set_title('Market Share Clustermap', fontsize=16)\n",
    "#     else:\n",
    "#         ax24.text(0.5, 0.5, 'Not enough data for Clustermap', ha='center', va='center', fontsize=16)\n",
    "#         ax24.set_title('Market Share Clustermap', fontsize=16)\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     # Save high-quality image\n",
    "#     output_path = 'detailed_infographic.png'\n",
    "#     plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "#     plt.close()\n",
    "\n",
    "#     print(f\"Detailed infographic saved as: {output_path}\")\n",
    "#     return output_path\n",
    "\n",
    "# # Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     summary = {\n",
    "#         'categories': ['iPhone', 'Samsung', 'Others'],\n",
    "#         'values': [20, 50, 30],\n",
    "#         'text': '20% of users own an iPhone, 50% own a Samsung, and the rest own a variety of brands',\n",
    "#         'audio_path': 'D:\\\\1OOx-enginners-hackathon-submission-2\\\\uploads\\\\audio_files\\\\summary_audio.mp3',\n",
    "#         'sentiment': 'neutral',\n",
    "#         'language': 'en'\n",
    "#     }\n",
    "#     create_detailed_infographic(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_animated_gif(summary):\n",
    "#     categories = summary['categories']\n",
    "#     values = summary['values']\n",
    "\n",
    "#     # Create a unique frames directory\n",
    "#     frames_dir = f'animation_frames_{uuid.uuid4().hex}'\n",
    "#     if os.path.exists(frames_dir):\n",
    "#         shutil.rmtree(frames_dir)  # Remove directory if it exists\n",
    "#     os.makedirs(frames_dir)\n",
    "\n",
    "#     def create_frame(frame_number, value_multiplier, categories=categories, values=values):\n",
    "#         fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "#         # Calculate current height of bars\n",
    "#         current_values = [v * value_multiplier for v in values]\n",
    "\n",
    "#         # Create bars with current height\n",
    "#         bars = ax.bar(categories, current_values, color='skyblue')\n",
    "\n",
    "#         # Styling\n",
    "#         ax.set_title('Market Share Analysis', fontsize=20, pad=20)\n",
    "#         ax.set_xlabel('Brands', fontsize=14)\n",
    "#         ax.set_ylabel('Percentage (%)', fontsize=14)\n",
    "#         ax.set_ylim(0, max(values) * 1.2)\n",
    "\n",
    "#         # Add value labels\n",
    "#         for bar, value in zip(bars, current_values):\n",
    "#             if value > 0:\n",
    "#                 height = bar.get_height()\n",
    "#                 ax.text(bar.get_x() + bar.get_width() / 2., height,\n",
    "#                        f'{int(value)}%',\n",
    "#                        ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "#         ax.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "#         plt.tight_layout()\n",
    "\n",
    "#         # Save frame\n",
    "#         frame_path = os.path.join(frames_dir, f'frame_{frame_number:03d}.png')\n",
    "#         plt.savefig(frame_path, dpi=300, bbox_inches='tight')\n",
    "#         plt.close()\n",
    "#         return frame_path\n",
    "\n",
    "#     # Generate frames\n",
    "#     frames = []\n",
    "#     num_frames = 20  # Number of frames for animation\n",
    "\n",
    "#     print(\"Generating frames...\")\n",
    "#     for i in range(num_frames + 1):\n",
    "#         multiplier = i / num_frames\n",
    "#         frame_path = create_frame(i, multiplier)\n",
    "#         frames.append(frame_path)\n",
    "\n",
    "#     # Create GIF\n",
    "#     print(\"Creating GIF...\")\n",
    "#     images = [Image.open(f) for f in frames]\n",
    "\n",
    "#     gif_path = 'animated_infographic.gif'\n",
    "#     images[0].save(\n",
    "#         gif_path,\n",
    "#         save_all=True,\n",
    "#         append_images=images[1:],\n",
    "#         duration=100,  # 100ms between frames\n",
    "#         loop=0\n",
    "#     )\n",
    "\n",
    "#     # Clean up frames directory\n",
    "#     try:\n",
    "#         shutil.rmtree(frames_dir)\n",
    "#         print(\"Cleanup completed successfully\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Cleanup error: {e}\")\n",
    "\n",
    "#     print(f\"Animation saved as GIF: {gif_path}\")\n",
    "#     return gif_path\n",
    "\n",
    "# def convert_gif_to_storytelling_video(gif_path, summary):\n",
    "#     categories = summary['categories']\n",
    "#     values = summary['values']\n",
    "\n",
    "#     def create_text_frame(text, size=(1920, 1080), bg_color='white'):\n",
    "#         img = Image.new('RGB', size, color=bg_color)\n",
    "#         draw = ImageDraw.Draw(img)\n",
    "\n",
    "#         try:\n",
    "#             font = ImageFont.truetype(\"arial.ttf\", 60)\n",
    "#         except:\n",
    "#             font = ImageFont.load_default()\n",
    "\n",
    "#         # Get text bbox\n",
    "#         bbox = draw.textbbox((0, 0), text, font=font)\n",
    "#         text_width = bbox[2] - bbox[0]\n",
    "#         text_height = bbox[3] - bbox[1]\n",
    "\n",
    "#         # Center text\n",
    "#         x = (size[0] - text_width) // 2\n",
    "#         y = (size[1] - text_height) // 2\n",
    "\n",
    "#         draw.text((x, y), text, fill='black' if bg_color == 'white' else 'white', font=font)\n",
    "#         # Convert to RGB numpy array\n",
    "#         return np.array(img.convert('RGB'))\n",
    "\n",
    "#     # Prepare frames\n",
    "#     frames = []\n",
    "#     fps = 30\n",
    "\n",
    "#     # 1. Title sequence (2 seconds)\n",
    "#     title_frame = create_text_frame(\"Market Share Analysis\", bg_color='black')\n",
    "#     for _ in range(2 * fps):\n",
    "#         frames.append(title_frame)\n",
    "\n",
    "#     # 2. GIF sequence (4 seconds)\n",
    "#     gif = Image.open(gif_path)\n",
    "#     gif_frames = []\n",
    "#     try:\n",
    "#         while True:\n",
    "#             frame = gif.copy()\n",
    "#             # Resize frame and ensure RGB\n",
    "#             frame = frame.convert('RGB').resize((1920, 1080), Image.LANCZOS)\n",
    "#             # Convert to numpy array\n",
    "#             frame_array = np.array(frame)\n",
    "#             gif_frames.append(frame_array)\n",
    "#             gif.seek(len(gif_frames))\n",
    "#     except EOFError:\n",
    "#         pass\n",
    "\n",
    "#     # Extend gif frames to 4 seconds\n",
    "#     frames_needed = 4 * fps\n",
    "#     while len(gif_frames) < frames_needed:\n",
    "#         gif_frames.extend(gif_frames)\n",
    "#     frames.extend(gif_frames[:frames_needed])\n",
    "\n",
    "#     # 3. Explanation sequence (4 seconds)\n",
    "#     explanations = [\n",
    "#         \"Analyzing market share data...\",\n",
    "#         f\"Main competitor: {categories[values.index(max(values))]} leads with {max(values)}%\",\n",
    "#         f\"Market gap analysis shows {max(values) - min(values)}% difference\",\n",
    "#         f\"Total market coverage: {sum(values)}%\",\n",
    "#         \"Generating insights and recommendations...\"\n",
    "#     ]\n",
    "\n",
    "#     frames_per_explanation = int((4 * fps) / len(explanations))\n",
    "#     for exp in explanations:\n",
    "#         exp_frame = create_text_frame(exp)\n",
    "#         for _ in range(frames_per_explanation):\n",
    "#             frames.append(exp_frame)\n",
    "\n",
    "#     # Verify all frames have the same shape and channels\n",
    "#     frame_shape = frames[0].shape\n",
    "#     frames = [frame.reshape(frame_shape) if frame.shape != frame_shape else frame\n",
    "#               for frame in frames]\n",
    "\n",
    "#     # Save as MP4\n",
    "#     output_path = 'data_storytelling_video.mp4'\n",
    "\n",
    "#     print(\"Writing video...\")\n",
    "#     writer = imageio.get_writer(output_path, fps=fps)\n",
    "#     for frame in frames:\n",
    "#         writer.append_data(frame)\n",
    "#     writer.close()\n",
    "\n",
    "#     print(f\"Data storytelling video saved as: {output_path}\")\n",
    "\n",
    "#     # Add Narration Audio to Video\n",
    "#     final_video = \"final_data_storytelling_video.mp4\"\n",
    "#     add_auto_generated_audio_to_video(output_path, summary['audio_path'], output_video_path=final_video)\n",
    "\n",
    "#     return final_video\n",
    "\n",
    "# def add_auto_generated_audio_to_video(video_path, audio_file_path, output_video_path):\n",
    "#     video_clip = VideoFileClip(video_path)\n",
    "#     audio_clip = AudioFileClip(audio_file_path)\n",
    "\n",
    "#     # Set the audio of the video clip to the generated narration\n",
    "#     video_clip = video_clip.set_audio(audio_clip)\n",
    "\n",
    "#     # Write the final video with the audio\n",
    "#     video_clip.write_videofile(output_video_path, codec=\"libx264\", audio_codec=\"aac\")\n",
    "#     def create_data_storytelling_video(csv_file_path, summary):\n",
    "#         # Load data from CSV\n",
    "#         data = pd.read_csv(csv_file_path)\n",
    "        \n",
    "#         # Generate summary if not provided\n",
    "#         if not summary:\n",
    "#             summary = generate_summary(data)\n",
    "        \n",
    "#         # Create animated GIF\n",
    "#         gif_path = create_animated_gif(summary)\n",
    "        \n",
    "#         # Convert GIF to MP4\n",
    "#         mp4_gif_path = gif_path.replace('.gif', '.mp4')\n",
    "#         clip = VideoFileClip(gif_path)\n",
    "#         clip.write_videofile(mp4_gif_path, codec='libx264')\n",
    "        \n",
    "#         # Create storytelling video\n",
    "#         storytelling_video_path = convert_gif_to_storytelling_video(mp4_gif_path, summary)\n",
    "        \n",
    "#         return storytelling_video_path\n",
    "\n",
    "#     def generate_summary(data):\n",
    "#         # Example summary generation logic\n",
    "#         categories = data['Brand'].unique().tolist()\n",
    "#         values = data['Market Share'].tolist()\n",
    "#         text = \"Market share analysis of various brands.\"\n",
    "#         audio_path = 'path_to_generated_audio.mp3'  # Placeholder for generated audio path\n",
    "        \n",
    "#         summary = {\n",
    "#             'categories': categories,\n",
    "#             'values': values,\n",
    "#             'text': text,\n",
    "#             'audio_path': audio_path,\n",
    "#             'sentiment': 'neutral',\n",
    "#             'language': 'en'\n",
    "#         }\n",
    "        \n",
    "#         return summary\n",
    "\n",
    "#     # Example usage\n",
    "#     storytelling_video_path = create_data_storytelling_video(csv_file_path, summary)\n",
    "#     print(f\"Data storytelling video created at: {storytelling_video_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_detailed_infographic(summary):\n",
    "#     categories = summary['categories']\n",
    "#     values = summary['values']\n",
    "\n",
    "#     # Create figure with subplots\n",
    "#     fig = plt.figure(figsize=(15, 10))\n",
    "\n",
    "#     # Main bar plot\n",
    "#     ax1 = plt.subplot2grid((2, 2), (0, 0), colspan=2)\n",
    "#     bars = ax1.bar(categories, values, color='skyblue')\n",
    "#     ax1.set_title('Market Share Distribution', fontsize=16)\n",
    "#     ax1.set_ylabel('Percentage (%)')\n",
    "\n",
    "#     # Add value labels\n",
    "#     for bar in bars:\n",
    "#         height = bar.get_height()\n",
    "#         ax1.text(bar.get_x() + bar.get_width() / 2., height,\n",
    "#                 f'{int(height)}%',\n",
    "#                 ha='center', va='bottom')\n",
    "\n",
    "#     # Pie chart\n",
    "#     ax2 = plt.subplot2grid((2, 2), (1, 0))\n",
    "#     ax2.pie(values, labels=categories, autopct='%1.1f%%')\n",
    "#     ax2.set_title('Market Share Proportion')\n",
    "\n",
    "#     # Additional insights text\n",
    "#     ax3 = plt.subplot2grid((2, 2), (1, 1))\n",
    "#     ax3.axis('off')\n",
    "#     total = sum(values)\n",
    "#     insights_text = f\"\"\"Key Insights:\n",
    "\n",
    "#     • Total market coverage: {total}%\n",
    "#     • Leading brand: {categories[values.index(max(values))]}\n",
    "#     • Market share gap: {max(values) - min(values)}%\n",
    "#     \"\"\"\n",
    "#     ax3.text(0, 0.5, insights_text, fontsize=12, va='center')\n",
    "\n",
    "#     plt.tight_layout()\n",
    "\n",
    "#     # Save high-quality image\n",
    "#     output_path = 'detailed_infographic.png'\n",
    "#     plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "#     plt.close()\n",
    "\n",
    "#     print(f\"Detailed infographic saved as: {output_path}\")\n",
    "#     return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_video_from_image(image_path, prompt):\n",
    "#     # Load the Stable Diffusion pipeline\n",
    "#     pipe = DiffusionPipeline.from_pretrained(\"stabilityai/stable-video-diffusion-img2vid-xt\")\n",
    "\n",
    "#     # Generate video from image\n",
    "#     video = pipe(prompt, init_image=image_path).videos[0]\n",
    "\n",
    "#     # Save the video\n",
    "#     video_filename = f'video_{uuid.uuid4().hex}.mp4'\n",
    "#     video_path = os.path.join('uploads', video_filename)\n",
    "#     video.save(video_path)\n",
    "\n",
    "#     return video_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_video_from_image(image_path, prompt):\n",
    "#     # Load the Stable Diffusion pipeline\n",
    "#     pipe = DiffusionPipeline.from_pretrained(\"stabilityai/stable-video-diffusion-img2vid-xt\")\n",
    "\n",
    "#     # Generate video from image\n",
    "#     video = pipe(prompt, init_image=image_path).videos[0]\n",
    "\n",
    "#     # Save the video\n",
    "#     video_filename = f'video_{uuid.uuid4().hex}.mp4'\n",
    "#     video_path = os.path.join('uploads', video_filename)\n",
    "#     video.save(video_path)\n",
    "\n",
    "#     return video_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_infographic_video(user_prompt):\n",
    "#     summary = nlp_pipeline(user_prompt)\n",
    "#     infographic_path = create_detailed_infographic(summary)\n",
    "#     video_path = generate_video_from_image(infographic_path, user_prompt)\n",
    "#     final_video_path = add_auto_generated_audio_to_video(video_path, summary['audio_path'])\n",
    "#     print(f\"Infographic video created successfully: {final_video_path}\")\n",
    "\n",
    "# def process_data_and_create_video(file_path):\n",
    "#     # Read the data\n",
    "#     df = read_data(file_path)\n",
    "\n",
    "#     # Convert the DataFrame to a string prompt\n",
    "#     prompt = df.to_string(index=False)\n",
    "\n",
    "#     # Create the infographic video\n",
    "#     create_infographic_video(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     file_path = 'D:\\\\1OOx-enginners-hackathon-submission-2\\\\data\\\\2015.csv'\n",
    "#     process_data_and_create_video(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_infographic_video(user_prompt):\n",
    "#     final_video_path = generate_infographics_from_prompt(user_prompt)\n",
    "#     print(f\"Infographic video created successfully: {final_video_path}\")\n",
    "\n",
    "# def process_data_and_create_video(file_path):\n",
    "#     # Determine file type and read the data\n",
    "#     if file_path.endswith('.csv'):\n",
    "#         df = pd.read_csv(file_path)\n",
    "#     elif file_path.endswith('.xlsx'):\n",
    "#         df = pd.read_excel(file_path)\n",
    "#     else:\n",
    "#         raise ValueError(\"Unsupported file format\")\n",
    "\n",
    "#     # Convert the DataFrame to a string prompt\n",
    "#     prompt = df.to_string(index=False)\n",
    "\n",
    "#     # Create the infographic video\n",
    "#     create_infographic_video(prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     file_path = 'D:\\\\1OOx-enginners-hackathon-submission-2\\\\data\\\\2015.csv'\n",
    "#     process_data_and_create_video(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INITIAL CODE IMPLEMNTATION NOT IN USE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## carry Forward of the code from here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    if file_path.endswith('.csv'):\n",
    "        df = pd.read_csv(file_path)\n",
    "    elif file_path.endswith('.xlsx'):\n",
    "        df = pd.read_excel(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'categories': ['Summary'], 'values': [100], 'text': '20% of users own an shone, 50% own a Samsung, and the rest own a variety of bands . the rest own a variety of bands, including a to, a pp, a pp, a pp, a pp, a pp, a pp, a pp, a pp, a pp, a pp', 'audio_path': 'uploads/audio_files\\\\summary_audio_54c661ddd8b145f5b4d58e4370554eb4.mp3', 'sentiment': 'neutral', 'language': 'en'}\n"
     ]
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "from langdetect import detect\n",
    "\n",
    "# Initialize sentiment analyzer\n",
    "vader_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# NLP Pipeline Function\n",
    "def nlp_pipeline(text):\n",
    "    # Prepare input\n",
    "    input_text = f\"summarize: {text}\"\n",
    "    inputs = summary_tokenizer.encode(input_text, return_tensors='pt', max_length=512, truncation=True)\n",
    "\n",
    "    # Generate summary\n",
    "    outputs = summary_model.generate(inputs, max_length=100)\n",
    "    summary_text = summary_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Extract percentages and categories using regex patterns\n",
    "    percentages = [int(x.strip('%')) for x in re.findall(r'\\d+%', text)]\n",
    "    words = text.split()\n",
    "    categories = []\n",
    "\n",
    "    # Find words after \"use\" or \"uses\"\n",
    "    for i, word in enumerate(words):\n",
    "        if word.lower() in ['use', 'uses'] and i + 1 < len(words):\n",
    "            categories.append(words[i + 1])\n",
    "\n",
    "    if not percentages or not categories:\n",
    "        percentages = [100]\n",
    "        categories = ['Summary']\n",
    "\n",
    "    # Sentiment analysis\n",
    "    sentiment = vader_analyzer.polarity_scores(summary_text)\n",
    "    sentiment_label = 'positive' if sentiment['compound'] >= 0.05 else 'negative' if sentiment['compound'] <= -0.05 else 'neutral'\n",
    "\n",
    "    # Text correction and language detection\n",
    "    blob = TextBlob(summary_text)\n",
    "    corrected_text = str(blob.correct())\n",
    "    language = detect(corrected_text)  # Use langdetect to detect language\n",
    "\n",
    "    # Generate audio\n",
    "    tts = gTTS(corrected_text, lang='en')\n",
    "    audio_filename = f'summary_audio_{uuid.uuid4().hex}.mp3'\n",
    "    audio_path = os.path.join('uploads/audio_files', audio_filename)\n",
    "    tts.save(audio_path)\n",
    "\n",
    "    return {\n",
    "        'categories': categories,\n",
    "        'values': percentages,\n",
    "        'text': corrected_text,\n",
    "        'audio_path': audio_path,\n",
    "        'sentiment': sentiment_label,\n",
    "        'language': language\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    text = \"20% of users own an iPhone, 50% own a Samsung, and the rest own a variety of brands\"\n",
    "    summary = nlp_pipeline(text)\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_visualization_method(df):\n",
    "    # Analyze the data and select appropriate visualization methods\n",
    "    visualizations = []\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'object':\n",
    "            visualizations.append(('bar', column))\n",
    "        elif df[column].dtype in ['int64', 'float64']:\n",
    "            if df[column].nunique() < 10:\n",
    "                visualizations.append(('pie', column))\n",
    "            else:\n",
    "                visualizations.append(('line', column))\n",
    "    return visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_visualizations(df, visualizations, output_dir=\"outputs\"):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    image_paths = []\n",
    "    for viz_type, column in visualizations:\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))  # Ensure all images have the same size\n",
    "        if viz_type == 'bar':\n",
    "            df[column].value_counts().plot(kind='bar', ax=ax, color='skyblue')\n",
    "            ax.set_title(f'{column} Distribution')\n",
    "        elif viz_type == 'pie':\n",
    "            df[column].value_counts().plot(kind='pie', ax=ax, autopct='%1.1f%%')\n",
    "            ax.set_title(f'{column} Distribution')\n",
    "        elif viz_type == 'line':\n",
    "            df[column].plot(kind='line', ax=ax, color='skyblue')\n",
    "            ax.set_title(f'{column} Trend')\n",
    "        \n",
    "        image_filename = f\"{uuid.uuid4().hex}.png\"\n",
    "        image_path = os.path.join(output_dir, image_filename)\n",
    "        plt.savefig(image_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        image_paths.append(image_path)\n",
    "    \n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "\n",
    "def generate_video_from_images(image_paths, output_video_path, fps=10):\n",
    "    # Ensure all images are the same size and in RGB format\n",
    "    first_image = Image.open(image_paths[0]).convert('RGB')\n",
    "    width, height = first_image.size\n",
    "    print(f\"First image size: {width}x{height}\")\n",
    "    resized_image_paths = []\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        resized_image = image.resize((width, height))\n",
    "        resized_image_path = f\"resized_{os.path.basename(image_path)}\"\n",
    "        resized_image.save(resized_image_path)\n",
    "        resized_image_paths.append(resized_image_path)\n",
    "        print(f\"Processed image: {resized_image_path}, size: {resized_image.size}\")\n",
    "\n",
    "    # Create a video from a sequence of images\n",
    "    clips = []\n",
    "    for img_path in tqdm(resized_image_paths, desc=\"Processing images\"):\n",
    "        img_clip = ImageClip(img_path).set_duration(5).fadein(1).fadeout(1)\n",
    "        clips.append(img_clip)\n",
    "\n",
    "    final_clip = concatenate_videoclips(clips, method=\"compose\")\n",
    "    final_clip = final_clip.set_duration(max(30, final_clip.duration))  # Ensure at least 30 seconds\n",
    "    final_clip.fps = fps  # Set the fps attribute\n",
    "\n",
    "    # Ensure the output path is absolute\n",
    "    output_video_path = os.path.abspath(output_video_path)\n",
    "    print(f\"Output video path: {output_video_path}\")\n",
    "\n",
    "    try:\n",
    "        final_clip.write_videofile(output_video_path, codec=\"mpeg4\")\n",
    "    except OSError as e:\n",
    "        print(f\"Error writing video file: {e}\")\n",
    "        raise\n",
    "\n",
    "    return output_video_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_auto_generated_audio_to_video(video_path, audio_file_path, output_video_path):\n",
    "    if video_path is None:\n",
    "        logging.error(\"Video path is None, cannot add audio.\")\n",
    "        return None\n",
    "    video_clip = VideoFileClip(video_path)\n",
    "    audio_clip = AudioFileClip(audio_file_path)\n",
    "\n",
    "    # Set the audio of the video clip to the generated narration\n",
    "    video_clip = video_clip.set_audio(audio_clip)\n",
    "\n",
    "    # Write the final video with the audio\n",
    "    video_clip.write_videofile(output_video_path, codec=\"libx264\", audio_codec=\"aac\")\n",
    "    return output_video_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_infographic_video(file_path):\n",
    "    df = read_data(file_path)\n",
    "    summary = nlp_pipeline(df.to_string(index=False))\n",
    "    visualizations = select_visualization_method(df)\n",
    "    image_paths = create_visualizations(df, visualizations)\n",
    "    video_path = generate_video_from_images(image_paths, f'video_{uuid.uuid4().hex}.mp4')\n",
    "    if video_path is None:\n",
    "        logging.error(\"Failed to generate video from images.\")\n",
    "        return\n",
    "    final_video_path = add_auto_generated_audio_to_video(video_path, summary['audio_path'], f'final_video_{uuid.uuid4().hex}.mp4')\n",
    "    if final_video_path is None:\n",
    "        logging.error(\"Failed to add audio to video.\")\n",
    "        return\n",
    "    print(f\"Infographic video created successfully: {final_video_path}\")\n",
    "\n",
    "def process_data_and_create_video(file_path):\n",
    "    # Create the infographic video\n",
    "    create_infographic_video(file_path)\n",
    "\n",
    "# # Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     file_path = 'D:\\\\1OOx-enginners-hackathon-submission-2\\\\data\\\\2015.csv'\n",
    "#     process_data_and_create_video(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     file_path ='D:\\\\1OOx-enginners-hackathon-submission-2\\\\data\\\\2015.csv'\n",
    "#     process_data_and_create_video(file_path)\n",
    "\n",
    "# This will run  in the other notebook while actual code implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD CODE NOT IN USE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def select_visualization_method(df):\n",
    "#     # Analyze the data and select appropriate visualization methods\n",
    "#     visualizations = []\n",
    "#     for column in df.columns:\n",
    "#         if df[column].dtype == 'object':\n",
    "#             visualizations.append(('bar', column))\n",
    "#         elif df[column].dtype in ['int64', 'float64']:\n",
    "#             if df[column].nunique() < 10:\n",
    "#                 visualizations.append(('pie', column))\n",
    "#             else:\n",
    "#                 visualizations.append(('line', column))\n",
    "#     return visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_visualizations(df, visualizations, output_dir=\"outputs\"):\n",
    "#     if not os.path.exists(output_dir):\n",
    "#         os.makedirs(output_dir)\n",
    "    \n",
    "#     image_paths = []\n",
    "#     for viz_type, column in visualizations:\n",
    "#         fig, ax = plt.subplots(figsize=(10, 6))  # Ensure all images have the same size\n",
    "#         if viz_type == 'bar':\n",
    "#             df[column].value_counts().plot(kind='bar', ax=ax, color='skyblue')\n",
    "#             ax.set_title(f'{column} Distribution')\n",
    "#         elif viz_type == 'pie':\n",
    "#             df[column].value_counts().plot(kind='pie', ax=ax, autopct='%1.1f%%')\n",
    "#             ax.set_title(f'{column} Distribution')\n",
    "#         elif viz_type == 'line':\n",
    "#             df[column].plot(kind='line', ax=ax, color='skyblue')\n",
    "#             ax.set_title(f'{column} Trend')\n",
    "        \n",
    "#         image_filename = f\"{uuid.uuid4().hex}.png\"\n",
    "#         image_path = os.path.join(output_dir, image_filename)\n",
    "#         plt.savefig(image_path, dpi=300, bbox_inches='tight')\n",
    "#         plt.close()\n",
    "        \n",
    "#         image_paths.append(image_path)\n",
    "    \n",
    "#     return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DataVisualizationScene(Scene):\n",
    "#     def __init__(self, image_paths, **kwargs):\n",
    "#         self.image_paths = image_paths\n",
    "#         super().__init__(**kwargs)\n",
    "\n",
    "#     def construct(self):\n",
    "#         for image_path in self.image_paths:\n",
    "#             image = ImageMobject(image_path)\n",
    "#             self.play(FadeIn(image))\n",
    "#             self.wait(2)\n",
    "#             self.play(FadeOut(image))\n",
    "\n",
    "# def generate_video_from_images(image_paths, output_video_path):\n",
    "#     scene = DataVisualizationScene(image_paths)\n",
    "#     scene.render()\n",
    "#     shutil.move(\"media/videos/DataVisualizationScene/1080p60/DataVisualizationScene.mp4\", output_video_path)\n",
    "#     return output_video_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_auto_generated_audio_to_video(video_path, audio_file_path, output_video_path):\n",
    "#     if video_path is None:\n",
    "#         logging.error(\"Video path is None, cannot add audio.\")\n",
    "#         return None\n",
    "#     video_clip = VideoFileClip(video_path)\n",
    "#     audio_clip = AudioFileClip(audio_file_path)\n",
    "\n",
    "#     # Set the audio of the video clip to the generated narration\n",
    "#     video_clip = video_clip.set_audio(audio_clip)\n",
    "\n",
    "#     # Write the final video with the audio\n",
    "#     video_clip.write_videofile(output_video_path, codec=\"libx264\", audio_codec=\"aac\")\n",
    "#     return output_video_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_infographic_video(file_path):\n",
    "#     df = read_data(file_path)\n",
    "#     summary = nlp_pipeline(df.to_string(index=False))\n",
    "#     visualizations = select_visualization_method(df)\n",
    "#     image_paths = create_visualizations(df, visualizations)\n",
    "#     video_path = generate_video_from_images(image_paths, f'video_{uuid.uuid4().hex}.mp4')\n",
    "#     if video_path is None:\n",
    "#         logging.error(\"Failed to generate video from images.\")\n",
    "#         return\n",
    "#     final_video_path = add_auto_generated_audio_to_video(video_path, summary['audio_path'], f'final_video_{uuid.uuid4().hex}.mp4')\n",
    "#     if final_video_path is None:\n",
    "#         logging.error(\"Failed to add audio to video.\")\n",
    "#         return\n",
    "#     print(f\"Infographic video created successfully: {final_video_path}\")\n",
    "\n",
    "# def process_data_and_create_video(file_path):\n",
    "#     # Create the infographic video\n",
    "#     create_infographic_video(file_path)\n",
    "\n",
    "# # Example usage\n",
    "# # if __name__ == \"__main__\":\n",
    "# #     file_path = 'D:\\\\1OOx-enginners-hackathon-submission-2\\\\data\\\\2015.csv'\n",
    "# #     process_data_and_create_video(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     file_path = 'D:\\\\1OOx-enginners-hackathon-submission-2\\\\data\\\\2015.csv'\n",
    "#     process_data_and_create_video(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_detailed_infographic(summary):\n",
    "#     categories = summary['categories']\n",
    "#     values = summary['values']\n",
    "\n",
    "#     # Create figure with subplots\n",
    "#     fig = plt.figure(figsize=(15, 10))\n",
    "\n",
    "#     # Main bar plot\n",
    "#     ax1 = plt.subplot2grid((2, 2), (0, 0), colspan=2)\n",
    "#     bars = ax1.bar(categories, values, color='skyblue')\n",
    "#     ax1.set_title('Market Share Distribution', fontsize=16)\n",
    "#     ax1.set_ylabel('Percentage (%)')\n",
    "\n",
    "#     # Add value labels\n",
    "#     for bar in bars:\n",
    "#         height = bar.get_height()\n",
    "#         ax1.text(bar.get_x() + bar.get_width() / 2., height,\n",
    "#                 f'{int(height)}%',\n",
    "#                 ha='center', va='bottom')\n",
    "\n",
    "#     # Pie chart\n",
    "#     ax2 = plt.subplot2grid((2, 2), (1, 0))\n",
    "#     ax2.pie(values, labels=categories, autopct='%1.1f%%')\n",
    "#     ax2.set_title('Market Share Proportion')\n",
    "\n",
    "#     # Additional insights text\n",
    "#     ax3 = plt.subplot2grid((2, 2), (1, 1))\n",
    "#     ax3.axis('off')\n",
    "#     total = sum(values)\n",
    "#     insights_text = f\"\"\"Key Insights:\n",
    "\n",
    "#     • Total market coverage: {total}%\n",
    "#     • Leading brand: {categories[values.index(max(values))]}\n",
    "#     • Market share gap: {max(values) - min(values)}%\n",
    "#     \"\"\"\n",
    "#     ax3.text(0, 0.5, insights_text, fontsize=12, va='center')\n",
    "\n",
    "#     plt.tight_layout()\n",
    "\n",
    "#     # Save high-quality image\n",
    "#     output_path = 'detailed_infographic.png'\n",
    "#     plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "#     plt.close()\n",
    "\n",
    "#     print(f\"Detailed infographic saved as: {output_path}\")\n",
    "#     return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_images_from_visualizations(summary, output_dir=\"outputs\"):\n",
    "#     if not os.path.exists(output_dir):\n",
    "#         os.makedirs(output_dir)\n",
    "    \n",
    "#     image_paths = []\n",
    "#     for i, (category, value) in enumerate(zip(summary['categories'], summary['values'])):\n",
    "#         fig, ax = plt.subplots()\n",
    "#         ax.bar([category], [value], color='skyblue')\n",
    "#         ax.set_title(f'{category} Distribution')\n",
    "#         ax.set_ylabel('Percentage (%)')\n",
    "        \n",
    "#         image_filename = f\"{uuid.uuid4().hex}.png\"\n",
    "#         image_path = os.path.join(output_dir, image_filename)\n",
    "#         plt.savefig(image_path, dpi=300, bbox_inches='tight')\n",
    "#         plt.close()\n",
    "        \n",
    "#         image_paths.append(image_path)\n",
    "    \n",
    "#     return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_video_from_images(image_paths, output_video_path, fps=10):\n",
    "#     # Create a video from a sequence of images\n",
    "#     clip = ImageSequenceClip(image_paths, fps=fps)\n",
    "#     if clip is None:\n",
    "#         logging.error(\"Failed to create video clip from images.\")\n",
    "#         return None\n",
    "#     clip.write_videofile(output_video_path, codec=\"libx264\")\n",
    "#     return output_video_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_auto_generated_audio_to_video(video_path, audio_file_path, output_video_path):\n",
    "#     if video_path is None:\n",
    "#         logging.error(\"Video path is None, cannot add audio.\")\n",
    "#         return None\n",
    "#     video_clip = VideoFileClip(video_path)\n",
    "#     audio_clip = AudioFileClip(audio_file_path)\n",
    "\n",
    "#     # Set the audio of the video clip to the generated narration\n",
    "#     video_clip = video_clip.set_audio(audio_clip)\n",
    "\n",
    "#     # Write the final video with the audio\n",
    "#     video_clip.write_videofile(output_video_path, codec=\"libx264\", audio_codec=\"aac\")\n",
    "#     return output_video_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_infographic_video(user_prompt, prompt):\n",
    "#     summary = nlp_pipeline(user_prompt)\n",
    "#     infographic_path = create_detailed_infographic(summary)\n",
    "#     image_paths = generate_images_from_visualizations(summary)\n",
    "#     video_path = generate_video_from_images(image_paths, f'video_{uuid.uuid4().hex}.mp4')\n",
    "#     if video_path is None:\n",
    "#         logging.error(\"Failed to generate video from images.\")\n",
    "#         return\n",
    "#     final_video_path = add_auto_generated_audio_to_video(video_path, summary['audio_path'], f'final_video_{uuid.uuid4().hex}.mp4')\n",
    "#     if final_video_path is None:\n",
    "#         logging.error(\"Failed to add audio to video.\")\n",
    "#         return\n",
    "#     print(f\"Infographic video created successfully: {final_video_path}\")\n",
    "\n",
    "# def process_data_and_create_video(file_path, prompt):\n",
    "#     # Read the data\n",
    "#     df = read_data(file_path)\n",
    "\n",
    "#     # Convert the DataFrame to a string prompt\n",
    "#     user_prompt = df.to_string(index=False)\n",
    "\n",
    "#     # Create the infographic video\n",
    "#     create_infographic_video(user_prompt, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     file_path = 'D:\\\\1OOx-enginners-hackathon-submission-2\\\\data\\\\2015.csv'\n",
    "#     prompt = \"the dataset contains the sales distribution\"\n",
    "#     process_data_and_create_video(file_path, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
