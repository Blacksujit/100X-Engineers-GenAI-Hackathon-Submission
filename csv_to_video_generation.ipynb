{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script imports the necessary libraries for a comprehensive data processing, visualization, and video generation pipeline.\n",
    "Libraries:\n",
    "- pandas: Data manipulation and analysis.\n",
    "- numpy: Numerical operations.\n",
    "- seaborn: Statistical data visualization.\n",
    "- sklearn.model_selection: Splitting data into training and testing sets.\n",
    "- sklearn.preprocessing: Standardizing features.\n",
    "- sklearn.linear_model: Implementing linear regression models.\n",
    "- sklearn.metrics: Evaluating model performance.\n",
    "- pandas.read_csv, pandas.read_excel: Reading data from CSV and Excel files.\n",
    "- scipy.stats: Statistical functions.\n",
    "- moviepy.editor: Video editing and creation.\n",
    "- gtts: Text-to-speech conversion.\n",
    "- matplotlib.pyplot: Plotting graphs and charts.\n",
    "\"\"\"\n",
    "# Loading all The necessary Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from pandas import read_csv, read_excel\n",
    "from scipy import stats\n",
    "from moviepy.editor import VideoClip, concatenate_videoclips\n",
    "from gtts import gTTS\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from scipy.signal import savgol_filter\n",
    "from time import perf_counter\n",
    "import math\n",
    "# from config_loader import load_config_ani, load_config_setup\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "import gtts\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, AutoModelForTokenClassification\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip, ImageSequenceClip\n",
    "import re\n",
    "import shutil\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import imageio\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the HF_HOME environment variable to change the cache path\n",
    "os.environ['HF_HOME'] = \"D:\\\\cahc_models_folder\"  # Change this to your desired cache path\n",
    "\n",
    "# Load the model and tokenizer from .pkl files\n",
    "models_dir = os.path.abspath(os.path.join(os.getcwd(), 'models'))\n",
    "\n",
    "with open(os.path.join(models_dir, 'model.pkl'), 'rb') as model_file:\n",
    "    summary_model = pickle.load(model_file)\n",
    "\n",
    "with open(os.path.join(models_dir, 'tokenizer.pkl'), 'rb') as tokenizer_file:\n",
    "    summary_tokenizer = pickle.load(tokenizer_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP Pipeline Function\n",
    "def nlp_pipeline(text):\n",
    "    # Prepare input\n",
    "    input_text = f\"summarize: {text}\"\n",
    "    inputs = summary_tokenizer.encode(input_text, return_tensors='pt', max_length=512, truncation=True)\n",
    "\n",
    "    # Generate summary\n",
    "    outputs = summary_model.generate(inputs, max_length=100)\n",
    "    summary_text = summary_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Extract percentages and categories using regex patterns\n",
    "    percentages = [int(x.strip('%')) for x in re.findall(r'\\d+%', text)]\n",
    "    words = text.split()\n",
    "    categories = []\n",
    "\n",
    "    # Find words after \"use\" or \"uses\"\n",
    "    for i, word in enumerate(words):\n",
    "        if word.lower() in ['use', 'uses'] and i + 1 < len(words):\n",
    "            categories.append(words[i + 1])\n",
    "\n",
    "    if not percentages or not categories:\n",
    "        percentages = [100]\n",
    "        categories = ['Summary']\n",
    "\n",
    "    # Generate audio\n",
    "    tts = gtts.gTTS(summary_text, lang='en')\n",
    "    audio_filename = f'summary_audio_{uuid.uuid4().hex}.mp3'\n",
    "    audio_path = os.path.join('D:\\\\1OOx-enginners-hackathon-submission-2\\\\uploads\\\\audio_files', audio_filename)\n",
    "    tts.save(audio_path)\n",
    "\n",
    "    return {\n",
    "        'categories': categories,\n",
    "        'values': percentages,\n",
    "        'text': summary_text,\n",
    "        'audio_path': audio_path\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to generate infographics from custom prompt\n",
    "def generate_infographics_from_prompt(prompt):\n",
    "    # Use the NLP pipeline to process the prompt\n",
    "    summary = nlp_pipeline(prompt)\n",
    "\n",
    "    # Create a detailed infographic\n",
    "    create_detailed_infographic(summary)\n",
    "\n",
    "    # Generate animated GIF\n",
    "    gif_path = create_animated_gif(summary)\n",
    "\n",
    "    # Convert GIF to storytelling video\n",
    "    final_video_path = convert_gif_to_storytelling_video(gif_path, summary)\n",
    "\n",
    "    return final_video_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_detailed_infographic(summary):\n",
    "    \"\"\"\n",
    "    Creates a static detailed infographic for data storytelling\n",
    "    \"\"\"\n",
    "    categories = summary['categories']\n",
    "    values = summary['values']\n",
    "\n",
    "    # Create figure with subplots\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "\n",
    "    # Main bar plot\n",
    "    ax1 = plt.subplot2grid((2, 2), (0, 0), colspan=2)\n",
    "    bars = ax1.bar(categories, values, color='skyblue')\n",
    "    ax1.set_title('Market Share Distribution', fontsize=16)\n",
    "    ax1.set_ylabel('Percentage (%)')\n",
    "\n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width() / 2., height,\n",
    "                f'{int(height)}%',\n",
    "                ha='center', va='bottom')\n",
    "\n",
    "    # Pie chart\n",
    "    ax2 = plt.subplot2grid((2, 2), (1, 0))\n",
    "    ax2.pie(values, labels=categories, autopct='%1.1f%%')\n",
    "    ax2.set_title('Market Share Proportion')\n",
    "\n",
    "    # Additional insights text\n",
    "    ax3 = plt.subplot2grid((2, 2), (1, 1))\n",
    "    ax3.axis('off')\n",
    "    total = sum(values)\n",
    "    insights_text = f\"\"\"Key Insights:\n",
    "\n",
    "    • Total market coverage: {total}%\n",
    "    • Leading brand: {categories[values.index(max(values))]}\n",
    "    • Market share gap: {max(values) - min(values)}%\n",
    "    \"\"\"\n",
    "    ax3.text(0, 0.5, insights_text, fontsize=12, va='center')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save high-quality image\n",
    "    output_path = 'detailed_infographic.png'\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Detailed infographic saved as: {output_path}\")\n",
    "    return output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_animated_gif(summary):\n",
    "    categories = summary['categories']\n",
    "    values = summary['values']\n",
    "\n",
    "    # Create a unique frames directory\n",
    "    frames_dir = f'animation_frames_{uuid.uuid4().hex}'\n",
    "    if os.path.exists(frames_dir):\n",
    "        shutil.rmtree(frames_dir)  # Remove directory if it exists\n",
    "    os.makedirs(frames_dir)\n",
    "\n",
    "    def create_frame(frame_number, value_multiplier, categories=categories, values=values):\n",
    "        fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "        # Calculate current height of bars\n",
    "        current_values = [v * value_multiplier for v in values]\n",
    "\n",
    "        # Create bars with current height\n",
    "        bars = ax.bar(categories, current_values, color='skyblue')\n",
    "\n",
    "        # Styling\n",
    "        ax.set_title('Market Share Analysis', fontsize=20, pad=20)\n",
    "        ax.set_xlabel('Brands', fontsize=14)\n",
    "        ax.set_ylabel('Percentage (%)', fontsize=14)\n",
    "        ax.set_ylim(0, max(values) * 1.2)\n",
    "\n",
    "        # Add value labels\n",
    "        for bar, value in zip(bars, current_values):\n",
    "            if value > 0:\n",
    "                height = bar.get_height()\n",
    "                ax.text(bar.get_x() + bar.get_width() / 2., height,\n",
    "                       f'{int(value)}%',\n",
    "                       ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "        ax.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save frame\n",
    "        frame_path = os.path.join(frames_dir, f'frame_{frame_number:03d}.png')\n",
    "        plt.savefig(frame_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        return frame_path\n",
    "\n",
    "    # Generate frames\n",
    "    frames = []\n",
    "    num_frames = 20  # Number of frames for animation\n",
    "\n",
    "    print(\"Generating frames...\")\n",
    "    for i in range(num_frames + 1):\n",
    "        multiplier = i / num_frames\n",
    "        frame_path = create_frame(i, multiplier)\n",
    "        frames.append(frame_path)\n",
    "\n",
    "    # Create GIF\n",
    "    print(\"Creating GIF...\")\n",
    "    images = [Image.open(f) for f in frames]\n",
    "\n",
    "    gif_path = 'animated_infographic.gif'\n",
    "    images[0].save(\n",
    "        gif_path,\n",
    "        save_all=True,\n",
    "        append_images=images[1:],\n",
    "        duration=100,  # 100ms between frames\n",
    "        loop=0\n",
    "    )\n",
    "\n",
    "    # Clean up frames directory\n",
    "    try:\n",
    "        shutil.rmtree(frames_dir)\n",
    "        print(\"Cleanup completed successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Cleanup error: {e}\")\n",
    "\n",
    "    print(f\"Animation saved as GIF: {gif_path}\")\n",
    "    return gif_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_gif_to_storytelling_video(gif_path, summary):\n",
    "    \"\"\"\n",
    "    Converts a GIF into a storytelling video using imageio\n",
    "    \"\"\"\n",
    "    categories = summary['categories']\n",
    "    values = summary['values']\n",
    "\n",
    "    def create_text_frame(text, size=(1920, 1080), bg_color='white'):\n",
    "        img = Image.new('RGB', size, color=bg_color)\n",
    "        draw = ImageDraw.Draw(img)\n",
    "\n",
    "        try:\n",
    "            font = ImageFont.truetype(\"arial.ttf\", 60)\n",
    "        except:\n",
    "            font = ImageFont.load_default()\n",
    "\n",
    "        # Get text bbox\n",
    "        bbox = draw.textbbox((0, 0), text, font=font)\n",
    "        text_width = bbox[2] - bbox[0]\n",
    "        text_height = bbox[3] - bbox[1]\n",
    "\n",
    "        # Center text\n",
    "        x = (size[0] - text_width) // 2\n",
    "        y = (size[1] - text_height) // 2\n",
    "\n",
    "        draw.text((x, y), text, fill='black' if bg_color == 'white' else 'white', font=font)\n",
    "        # Convert to RGB numpy array\n",
    "        return np.array(img.convert('RGB'))\n",
    "\n",
    "    # Prepare frames\n",
    "    frames = []\n",
    "    fps = 30\n",
    "\n",
    "    # 1. Title sequence (2 seconds)\n",
    "    title_frame = create_text_frame(\"Market Share Analysis\", bg_color='black')\n",
    "    for _ in range(2 * fps):\n",
    "        frames.append(title_frame)\n",
    "\n",
    "    # 2. GIF sequence (4 seconds)\n",
    "    gif = Image.open(gif_path)\n",
    "    gif_frames = []\n",
    "    try:\n",
    "        while True:\n",
    "            frame = gif.copy()\n",
    "            # Resize frame and ensure RGB\n",
    "            frame = frame.convert('RGB').resize((1920, 1080), Image.LANCZOS)\n",
    "            # Convert to numpy array\n",
    "            frame_array = np.array(frame)\n",
    "            gif_frames.append(frame_array)\n",
    "            gif.seek(len(gif_frames))\n",
    "    except EOFError:\n",
    "        pass\n",
    "\n",
    "    # Extend gif frames to 4 seconds\n",
    "    frames_needed = 4 * fps\n",
    "    while len(gif_frames) < frames_needed:\n",
    "        gif_frames.extend(gif_frames)\n",
    "    frames.extend(gif_frames[:frames_needed])\n",
    "\n",
    "    # 3. Explanation sequence (4 seconds)\n",
    "    explanations = [\n",
    "        \"Analyzing market share data...\",\n",
    "        f\"Main competitor: {categories[values.index(max(values))]} leads with {max(values)}%\",\n",
    "        f\"Market gap analysis shows {max(values) - min(values)}% difference\",\n",
    "        f\"Total market coverage: {sum(values)}%\",\n",
    "        \"Generating insights and recommendations...\"\n",
    "    ]\n",
    "\n",
    "    frames_per_explanation = int((4 * fps) / len(explanations))\n",
    "    for exp in explanations:\n",
    "        exp_frame = create_text_frame(exp)\n",
    "        for _ in range(frames_per_explanation):\n",
    "            frames.append(exp_frame)\n",
    "\n",
    "    # Verify all frames have the same shape and channels\n",
    "    frame_shape = frames[0].shape\n",
    "    frames = [frame.reshape(frame_shape) if frame.shape != frame_shape else frame\n",
    "              for frame in frames]\n",
    "\n",
    "    # Save as MP4\n",
    "    output_path = 'data_storytelling_video.mp4'\n",
    "\n",
    "    print(\"Writing video...\")\n",
    "    writer = imageio.get_writer(output_path, fps=fps)\n",
    "    for frame in frames:\n",
    "        writer.append_data(frame)\n",
    "    writer.close()\n",
    "\n",
    "    print(f\"Data storytelling video saved as: {output_path}\")\n",
    "\n",
    "    # Add Narration Audio to Video\n",
    "    final_video = \"final_data_storytelling_video.mp4\"\n",
    "    add_auto_generated_audio_to_video(output_path, summary['audio_path'], output_video_path=final_video)\n",
    "\n",
    "    return final_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Add Narration Audio to Video using MoviePy\n",
    "def add_auto_generated_audio_to_video(video_path, audio_file_path, output_video_path):\n",
    "    video_clip = VideoFileClip(video_path)\n",
    "    audio_clip = AudioFileClip(audio_file_path)\n",
    "\n",
    "    # Set the audio of the video clip to the generated narration\n",
    "    video_clip = video_clip.set_audio(audio_clip)\n",
    "\n",
    "    # Write the final video with the audio\n",
    "    video_clip.write_videofile(output_video_path, codec=\"libx264\", audio_codec=\"aac\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Function to Create Infographic Video with Auto-Generated Narration and Audio\n",
    "def create_infographic_video(user_prompt):\n",
    "    final_video_path = generate_infographics_from_prompt(user_prompt)\n",
    "    print(f\"Infographic video created successfully: {final_video_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process CSV and create data storytelling video\n",
    "def process_csv_and_create_video(csv_file_path):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "\n",
    "    # Convert the DataFrame to a string prompt\n",
    "    prompt = df.to_string(index=False)\n",
    "\n",
    "    # Create the infographic video\n",
    "    create_infographic_video(prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed infographic saved as: detailed_infographic.png\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 433] A device which does not exist was specified: 'animation_frames_180ec111d8894190bc4fbceacde69c10'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      3\u001b[0m     csv_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m100x_enginners_hackathon_genai\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m2015.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mprocess_csv_and_create_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_file_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[42], line 10\u001b[0m, in \u001b[0;36mprocess_csv_and_create_video\u001b[1;34m(csv_file_path)\u001b[0m\n\u001b[0;32m      7\u001b[0m prompt \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mto_string(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Create the infographic video\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[43mcreate_infographic_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[41], line 3\u001b[0m, in \u001b[0;36mcreate_infographic_video\u001b[1;34m(user_prompt)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_infographic_video\u001b[39m(user_prompt):\n\u001b[1;32m----> 3\u001b[0m     final_video_path \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_infographics_from_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInfographic video created successfully: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_video_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[29], line 10\u001b[0m, in \u001b[0;36mgenerate_infographics_from_prompt\u001b[1;34m(prompt)\u001b[0m\n\u001b[0;32m      7\u001b[0m create_detailed_infographic(summary)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Generate animated GIF\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m gif_path \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_animated_gif\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Convert GIF to storytelling video\u001b[39;00m\n\u001b[0;32m     13\u001b[0m final_video_path \u001b[38;5;241m=\u001b[39m convert_gif_to_storytelling_video(gif_path, summary)\n",
      "Cell \u001b[1;32mIn[38], line 9\u001b[0m, in \u001b[0;36mcreate_animated_gif\u001b[1;34m(summary)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(frames_dir):\n\u001b[0;32m      8\u001b[0m     shutil\u001b[38;5;241m.\u001b[39mrmtree(frames_dir)  \u001b[38;5;66;03m# Remove directory if it exists\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_frame\u001b[39m(frame_number, value_multiplier, categories\u001b[38;5;241m=\u001b[39mcategories, values\u001b[38;5;241m=\u001b[39mvalues):\n\u001b[0;32m     12\u001b[0m     fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m7\u001b[39m))\n",
      "File \u001b[1;32m<frozen os>:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 433] A device which does not exist was specified: 'animation_frames_180ec111d8894190bc4fbceacde69c10'"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    csv_file_path = 'D:\\\\1OOx-enginners-hackathon-submission-2\\\\data\\\\2015.csv'\n",
    "    process_csv_and_create_video(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed infographic saved as: detailed_infographic.png\n",
      "Generating frames...\n",
      "Creating GIF...\n",
      "Cleanup completed successfully\n",
      "Animation saved as GIF: animated_infographic.gif\n",
      "Writing video...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1920, 1080) to (1920, 1088) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data storytelling video saved as: data_storytelling_video.mp4\n",
      "Moviepy - Building video final_data_storytelling_video.mp4.\n",
      "MoviePy - Writing audio in final_data_storytelling_videoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video final_data_storytelling_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready final_data_storytelling_video.mp4\n",
      "Infographic video created successfully: final_data_storytelling_video.mp4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import gtts\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, AutoModelForTokenClassification\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip, ImageSequenceClip\n",
    "import re\n",
    "import shutil\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import imageio\n",
    "import uuid\n",
    "\n",
    "# Set the HF_HOME environment variable to change the cache path\n",
    "os.environ['HF_HOME'] = \"D:\\\\__MACOSX\"  # Change this to your desired cache path\n",
    "\n",
    "# Load the model and tokenizer from .pkl files\n",
    "models_dir = os.path.join(os.getcwd(), 'models')\n",
    "\n",
    "with open(os.path.join(models_dir, 'model.pkl'), 'rb') as model_file:\n",
    "    summary_model = pickle.load(model_file)\n",
    "\n",
    "with open(os.path.join(models_dir, 'tokenizer.pkl'), 'rb') as tokenizer_file:\n",
    "    summary_tokenizer = pickle.load(tokenizer_file)\n",
    "\n",
    "# NLP Pipeline Function\n",
    "def nlp_pipeline(text):\n",
    "    # Prepare input\n",
    "    input_text = f\"summarize: {text}\"\n",
    "    inputs = summary_tokenizer.encode(input_text, return_tensors='pt', max_length=512, truncation=True)\n",
    "\n",
    "    # Generate summary\n",
    "    outputs = summary_model.generate(inputs, max_length=100)\n",
    "    summary_text = summary_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Extract percentages and categories using regex patterns\n",
    "    percentages = [int(x.strip('%')) for x in re.findall(r'\\d+%', text)]\n",
    "    words = text.split()\n",
    "    categories = []\n",
    "\n",
    "    # Find words after \"use\" or \"uses\"\n",
    "    for i, word in enumerate(words):\n",
    "        if word.lower() in ['use', 'uses'] and i + 1 < len(words):\n",
    "            categories.append(words[i + 1])\n",
    "\n",
    "    if not percentages or not categories:\n",
    "        percentages = [100]\n",
    "        categories = ['Summary']\n",
    "\n",
    "    # Generate audio\n",
    "    tts = gtts.gTTS(summary_text, lang='en')\n",
    "    audio_filename = f'summary_audio_{uuid.uuid4().hex}.mp3'\n",
    "    audio_path = os.path.join('F:\\\\100x_enginners_hackathon_genai\\\\uploads\\\\audio_files', audio_filename)\n",
    "    tts.save(audio_path)\n",
    "\n",
    "    return {\n",
    "        'categories': categories,\n",
    "        'values': percentages,\n",
    "        'text': summary_text,\n",
    "        'audio_path': audio_path\n",
    "    }\n",
    "\n",
    "# Define a function to generate infographics from custom prompt\n",
    "def generate_infographics_from_prompt(prompt):\n",
    "    # Use the NLP pipeline to process the prompt\n",
    "    summary = nlp_pipeline(prompt)\n",
    "\n",
    "    # Create a detailed infographic\n",
    "    create_detailed_infographic(summary)\n",
    "\n",
    "    # Generate animated GIF\n",
    "    gif_path = create_animated_gif(summary)\n",
    "\n",
    "    # Convert GIF to storytelling video\n",
    "    final_video_path = convert_gif_to_storytelling_video(gif_path, summary)\n",
    "\n",
    "    return final_video_path\n",
    "\n",
    "def create_detailed_infographic(summary):\n",
    "    \"\"\"\n",
    "    Creates a static detailed infographic for data storytelling\n",
    "    \"\"\"\n",
    "    categories = summary['categories']\n",
    "    values = summary['values']\n",
    "\n",
    "    # Create figure with subplots\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "\n",
    "    # Main bar plot\n",
    "    ax1 = plt.subplot2grid((2, 2), (0, 0), colspan=2)\n",
    "    bars = ax1.bar(categories, values, color='skyblue')\n",
    "    ax1.set_title('Market Share Distribution', fontsize=16)\n",
    "    ax1.set_ylabel('Percentage (%)')\n",
    "\n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width() / 2., height,\n",
    "                f'{int(height)}%',\n",
    "                ha='center', va='bottom')\n",
    "\n",
    "    # Pie chart\n",
    "    ax2 = plt.subplot2grid((2, 2), (1, 0))\n",
    "    ax2.pie(values, labels=categories, autopct='%1.1f%%')\n",
    "    ax2.set_title('Market Share Proportion')\n",
    "\n",
    "    # Additional insights text\n",
    "    ax3 = plt.subplot2grid((2, 2), (1, 1))\n",
    "    ax3.axis('off')\n",
    "    total = sum(values)\n",
    "    insights_text = f\"\"\"Key Insights:\n",
    "\n",
    "    • Total market coverage: {total}%\n",
    "    • Leading brand: {categories[values.index(max(values))]}\n",
    "    • Market share gap: {max(values) - min(values)}%\n",
    "    \"\"\"\n",
    "    ax3.text(0, 0.5, insights_text, fontsize=12, va='center')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save high-quality image\n",
    "    output_path = 'detailed_infographic.png'\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Detailed infographic saved as: {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "def create_animated_gif(summary):\n",
    "    categories = summary['categories']\n",
    "    values = summary['values']\n",
    "\n",
    "    # Create a unique frames directory\n",
    "    frames_dir = os.path.join(os.getcwd(), f'animation_frames_{uuid.uuid4().hex}')\n",
    "    if os.path.exists(frames_dir):\n",
    "        shutil.rmtree(frames_dir)  # Remove directory if it exists\n",
    "    os.makedirs(frames_dir)\n",
    "\n",
    "    def create_frame(frame_number, value_multiplier, categories=categories, values=values):\n",
    "        fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "        # Calculate current height of bars\n",
    "        current_values = [v * value_multiplier for v in values]\n",
    "\n",
    "        # Create bars with current height\n",
    "        bars = ax.bar(categories, current_values, color='skyblue')\n",
    "\n",
    "        # Styling\n",
    "        ax.set_title('Market Share Analysis', fontsize=20, pad=20)\n",
    "        ax.set_xlabel('Brands', fontsize=14)\n",
    "        ax.set_ylabel('Percentage (%)', fontsize=14)\n",
    "        ax.set_ylim(0, max(values) * 1.2)\n",
    "\n",
    "        # Add value labels\n",
    "        for bar, value in zip(bars, current_values):\n",
    "            if value > 0:\n",
    "                height = bar.get_height()\n",
    "                ax.text(bar.get_x() + bar.get_width() / 2., height,\n",
    "                       f'{int(value)}%',\n",
    "                       ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "        ax.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save frame\n",
    "        frame_path = os.path.join(frames_dir, f'frame_{frame_number:03d}.png')\n",
    "        plt.savefig(frame_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        return frame_path\n",
    "\n",
    "    # Generate frames\n",
    "    frames = []\n",
    "    num_frames = 20  # Number of frames for animation\n",
    "\n",
    "    print(\"Generating frames...\")\n",
    "    for i in range(num_frames + 1):\n",
    "        multiplier = i / num_frames\n",
    "        frame_path = create_frame(i, multiplier)\n",
    "        frames.append(frame_path)\n",
    "\n",
    "    # Create GIF\n",
    "    print(\"Creating GIF...\")\n",
    "    images = [Image.open(f) for f in frames]\n",
    "\n",
    "    gif_path = 'animated_infographic.gif'\n",
    "    images[0].save(\n",
    "        gif_path,\n",
    "        save_all=True,\n",
    "        append_images=images[1:],\n",
    "        duration=100,  # 100ms between frames\n",
    "        loop=0\n",
    "    )\n",
    "\n",
    "    # Clean up frames directory\n",
    "    try:\n",
    "        shutil.rmtree(frames_dir)\n",
    "        print(\"Cleanup completed successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Cleanup error: {e}\")\n",
    "\n",
    "    print(f\"Animation saved as GIF: {gif_path}\")\n",
    "    return gif_path\n",
    "\n",
    "def convert_gif_to_storytelling_video(gif_path, summary):\n",
    "    \"\"\"\n",
    "    Converts a GIF into a storytelling video using imageio\n",
    "    \"\"\"\n",
    "    categories = summary['categories']\n",
    "    values = summary['values']\n",
    "\n",
    "    def create_text_frame(text, size=(1920, 1080), bg_color='white'):\n",
    "        img = Image.new('RGB', size, color=bg_color)\n",
    "        draw = ImageDraw.Draw(img)\n",
    "\n",
    "        try:\n",
    "            font = ImageFont.truetype(\"arial.ttf\", 60)\n",
    "        except:\n",
    "            font = ImageFont.load_default()\n",
    "\n",
    "        # Get text bbox\n",
    "        bbox = draw.textbbox((0, 0), text, font=font)\n",
    "        text_width = bbox[2] - bbox[0]\n",
    "        text_height = bbox[3] - bbox[1]\n",
    "\n",
    "        # Center text\n",
    "        x = (size[0] - text_width) // 2\n",
    "        y = (size[1] - text_height) // 2\n",
    "\n",
    "        draw.text((x, y), text, fill='black' if bg_color == 'white' else 'white', font=font)\n",
    "        # Convert to RGB numpy array\n",
    "        return np.array(img.convert('RGB'))\n",
    "\n",
    "    # Prepare frames\n",
    "    frames = []\n",
    "    fps = 30\n",
    "\n",
    "    # 1. Title sequence (2 seconds)\n",
    "    title_frame = create_text_frame(\"Market Share Analysis\", bg_color='black')\n",
    "    for _ in range(2 * fps):\n",
    "        frames.append(title_frame)\n",
    "\n",
    "    # 2. GIF sequence (4 seconds)\n",
    "    gif = Image.open(gif_path)\n",
    "    gif_frames = []\n",
    "    try:\n",
    "        while True:\n",
    "            frame = gif.copy()\n",
    "            # Resize frame and ensure RGB\n",
    "            frame = frame.convert('RGB').resize((1920, 1080), Image.LANCZOS)\n",
    "            # Convert to numpy array\n",
    "            frame_array = np.array(frame)\n",
    "            gif_frames.append(frame_array)\n",
    "            gif.seek(len(gif_frames))\n",
    "    except EOFError:\n",
    "        pass\n",
    "\n",
    "    # Extend gif frames to 4 seconds\n",
    "    frames_needed = 4 * fps\n",
    "    while len(gif_frames) < frames_needed:\n",
    "        gif_frames.extend(gif_frames)\n",
    "    frames.extend(gif_frames[:frames_needed])\n",
    "\n",
    "    # 3. Explanation sequence (4 seconds)\n",
    "    explanations = [\n",
    "        \"Analyzing market share data...\",\n",
    "        f\"Main competitor: {categories[values.index(max(values))]} leads with {max(values)}%\",\n",
    "        f\"Market gap analysis shows {max(values) - min(values)}% difference\",\n",
    "        f\"Total market coverage: {sum(values)}%\",\n",
    "        \"Generating insights and recommendations...\"\n",
    "    ]\n",
    "\n",
    "    frames_per_explanation = int((4 * fps) / len(explanations))\n",
    "    for exp in explanations:\n",
    "        exp_frame = create_text_frame(exp)\n",
    "        for _ in range(frames_per_explanation):\n",
    "            frames.append(exp_frame)\n",
    "\n",
    "    # Verify all frames have the same shape and channels\n",
    "    frame_shape = frames[0].shape\n",
    "    frames = [frame.reshape(frame_shape) if frame.shape != frame_shape else frame\n",
    "              for frame in frames]\n",
    "\n",
    "    # Save as MP4\n",
    "    output_path = 'data_storytelling_video.mp4'\n",
    "\n",
    "    print(\"Writing video...\")\n",
    "    writer = imageio.get_writer(output_path, fps=fps)\n",
    "    for frame in frames:\n",
    "        writer.append_data(frame)\n",
    "    writer.close()\n",
    "\n",
    "    print(f\"Data storytelling video saved as: {output_path}\")\n",
    "\n",
    "    # Add Narration Audio to Video\n",
    "    final_video = \"final_data_storytelling_video.mp4\"\n",
    "    add_auto_generated_audio_to_video(output_path, summary['audio_path'], output_video_path=final_video)\n",
    "\n",
    "    return final_video\n",
    "\n",
    "# Step 4: Add Narration Audio to Video using MoviePy\n",
    "def add_auto_generated_audio_to_video(video_path, audio_file_path, output_video_path):\n",
    "    video_clip = VideoFileClip(video_path)\n",
    "    audio_clip = AudioFileClip(audio_file_path)\n",
    "\n",
    "    # Set the audio of the video clip to the generated narration\n",
    "    video_clip = video_clip.set_audio(audio_clip)\n",
    "\n",
    "    # Write the final video with the audio\n",
    "    video_clip.write_videofile(output_video_path, codec=\"libx264\", audio_codec=\"aac\")\n",
    "\n",
    "# Main Function to Create Infographic Video with Auto-Generated Narration and Audio\n",
    "def create_infographic_video(user_prompt):\n",
    "    final_video_path = generate_infographics_from_prompt(user_prompt)\n",
    "    print(f\"Infographic video created successfully: {final_video_path}\")\n",
    "\n",
    "# Function to process CSV and create data storytelling video\n",
    "def process_csv_and_create_video(csv_file_path):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "\n",
    "    # Convert the DataFrame to a string prompt\n",
    "    prompt = df.to_string(index=False)\n",
    "\n",
    "    # Create the infographic video\n",
    "    create_infographic_video(prompt)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    csv_file_path = 'F:\\\\100x_enginners_hackathon_genai\\\\data\\\\2015.csv'\n",
    "    process_csv_and_create_video(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed infographic saved as: detailed_infographic.png\n",
      "Generating frames...\n",
      "Creating GIF...\n",
      "Cleanup completed successfully\n",
      "Animation saved as GIF: animated_infographic.gif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1920, 1080) to (1920, 1088) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing video...\n",
      "Data storytelling video saved as: data_storytelling_video.mp4\n",
      "Moviepy - Building video final_data_storytelling_video.mp4.\n",
      "MoviePy - Writing audio in final_data_storytelling_videoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video final_data_storytelling_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready final_data_storytelling_video.mp4\n",
      "Infographic video created successfully: final_data_storytelling_video.mp4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import gtts\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, AutoModelForTokenClassification\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip, ImageSequenceClip, concatenate_videoclips\n",
    "import re\n",
    "import shutil\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import imageio\n",
    "import uuid\n",
    "\n",
    "# Set the HF_HOME environment variable to change the cache path\n",
    "os.environ['HF_HOME'] = \"D:\\\\__MACOSX\"  # Change this to your desired cache path\n",
    "\n",
    "# Load the model and tokenizer from .pkl files\n",
    "models_dir = os.path.join(os.getcwd(), 'models')\n",
    "\n",
    "with open(os.path.join(models_dir, 'model.pkl'), 'rb') as model_file:\n",
    "    summary_model = pickle.load(model_file)\n",
    "\n",
    "with open(os.path.join(models_dir, 'tokenizer.pkl'), 'rb') as tokenizer_file:\n",
    "    summary_tokenizer = pickle.load(tokenizer_file)\n",
    "\n",
    "# NLP Pipeline Function\n",
    "def nlp_pipeline(text):\n",
    "    # Prepare input\n",
    "    input_text = f\"summarize: {text}\"\n",
    "    inputs = summary_tokenizer.encode(input_text, return_tensors='pt', max_length=512, truncation=True)\n",
    "\n",
    "    # Generate summary\n",
    "    outputs = summary_model.generate(inputs, max_length=100)\n",
    "    summary_text = summary_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Extract percentages and categories using regex patterns\n",
    "    percentages = [int(x.strip('%')) for x in re.findall(r'\\d+%', text)]\n",
    "    words = text.split()\n",
    "    categories = []\n",
    "\n",
    "    # Find words after \"use\" or \"uses\"\n",
    "    for i, word in enumerate(words):\n",
    "        if word.lower() in ['use', 'uses'] and i + 1 < len(words):\n",
    "            categories.append(words[i + 1])\n",
    "\n",
    "    if not percentages or not categories:\n",
    "        percentages = [100]\n",
    "        categories = ['Summary']\n",
    "\n",
    "    # Generate audio\n",
    "    tts = gtts.gTTS(summary_text, lang='en')\n",
    "    audio_filename = f'summary_audio_{uuid.uuid4().hex}.mp3'\n",
    "    audio_path = os.path.join('F:\\\\100x_enginners_hackathon_genai\\\\uploads\\\\audio_files', audio_filename)\n",
    "    tts.save(audio_path)\n",
    "\n",
    "    return {\n",
    "        'categories': categories,\n",
    "        'values': percentages,\n",
    "        'text': summary_text,\n",
    "        'audio_path': audio_path\n",
    "    }\n",
    "\n",
    "# Define a function to generate infographics from custom prompt\n",
    "def generate_infographics_from_prompt(prompt):\n",
    "    # Use the NLP pipeline to process the prompt\n",
    "    summary = nlp_pipeline(prompt)\n",
    "\n",
    "    # Create a detailed infographic\n",
    "    create_detailed_infographic(summary)\n",
    "\n",
    "    # Generate animated GIF\n",
    "    gif_path = create_animated_gif(summary)\n",
    "\n",
    "    # Convert GIF to storytelling video\n",
    "    final_video_path = convert_gif_to_storytelling_video(gif_path, summary)\n",
    "\n",
    "    return final_video_path\n",
    "\n",
    "def create_detailed_infographic(summary):\n",
    "    \"\"\"\n",
    "    Creates a static detailed infographic for data storytelling\n",
    "    \"\"\"\n",
    "    categories = summary['categories']\n",
    "    values = summary['values']\n",
    "\n",
    "    # Create figure with subplots\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "\n",
    "    # Main bar plot\n",
    "    ax1 = plt.subplot2grid((2, 2), (0, 0), colspan=2)\n",
    "    bars = ax1.bar(categories, values, color='skyblue')\n",
    "    ax1.set_title('Market Share Distribution', fontsize=16)\n",
    "    ax1.set_ylabel('Percentage (%)')\n",
    "\n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width() / 2., height,\n",
    "                f'{int(height)}%',\n",
    "                ha='center', va='bottom')\n",
    "\n",
    "    # Pie chart\n",
    "    ax2 = plt.subplot2grid((2, 2), (1, 0))\n",
    "    ax2.pie(values, labels=categories, autopct='%1.1f%%')\n",
    "    ax2.set_title('Market Share Proportion')\n",
    "\n",
    "    # Additional insights text\n",
    "    ax3 = plt.subplot2grid((2, 2), (1, 1))\n",
    "    ax3.axis('off')\n",
    "    total = sum(values)\n",
    "    insights_text = f\"\"\"Key Insights:\n",
    "\n",
    "    • Total market coverage: {total}%\n",
    "    • Leading brand: {categories[values.index(max(values))]}\n",
    "    • Market share gap: {max(values) - min(values)}%\n",
    "    \"\"\"\n",
    "    ax3.text(0, 0.5, insights_text, fontsize=12, va='center')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save high-quality image\n",
    "    output_path = 'detailed_infographic.png'\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Detailed infographic saved as: {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "def create_animated_gif(summary):\n",
    "    categories = summary['categories']\n",
    "    values = summary['values']\n",
    "\n",
    "    # Create a unique frames directory\n",
    "    frames_dir = os.path.join(os.getcwd(), f'animation_frames_{uuid.uuid4().hex}')\n",
    "    if os.path.exists(frames_dir):\n",
    "        shutil.rmtree(frames_dir)  # Remove directory if it exists\n",
    "    os.makedirs(frames_dir)\n",
    "\n",
    "    def create_frame(frame_number, value_multiplier, categories=categories, values=values):\n",
    "        fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "        # Calculate current height of bars\n",
    "        current_values = [v * value_multiplier for v in values]\n",
    "\n",
    "        # Create bars with current height\n",
    "        bars = ax.bar(categories, current_values, color='skyblue')\n",
    "\n",
    "        # Styling\n",
    "        ax.set_title('Market Share Analysis', fontsize=20, pad=20)\n",
    "        ax.set_xlabel('Brands', fontsize=14)\n",
    "        ax.set_ylabel('Percentage (%)', fontsize=14)\n",
    "        ax.set_ylim(0, max(values) * 1.2)\n",
    "\n",
    "        # Add value labels\n",
    "        for bar, value in zip(bars, current_values):\n",
    "            if value > 0:\n",
    "                height = bar.get_height()\n",
    "                ax.text(bar.get_x() + bar.get_width() / 2., height,\n",
    "                       f'{int(value)}%',\n",
    "                       ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "        ax.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save frame\n",
    "        frame_path = os.path.join(frames_dir, f'frame_{frame_number:03d}.png')\n",
    "        plt.savefig(frame_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        return frame_path\n",
    "\n",
    "    # Generate frames\n",
    "    frames = []\n",
    "    num_frames = 20  # Number of frames for animation\n",
    "\n",
    "    print(\"Generating frames...\")\n",
    "    for i in range(num_frames + 1):\n",
    "        multiplier = i / num_frames\n",
    "        frame_path = create_frame(i, multiplier)\n",
    "        frames.append(frame_path)\n",
    "\n",
    "    # Create GIF\n",
    "    print(\"Creating GIF...\")\n",
    "    images = [Image.open(f) for f in frames]\n",
    "\n",
    "    gif_path = 'animated_infographic.gif'\n",
    "    images[0].save(\n",
    "        gif_path,\n",
    "        save_all=True,\n",
    "        append_images=images[1:],\n",
    "        duration=100,  # 100ms between frames\n",
    "        loop=0\n",
    "    )\n",
    "\n",
    "    # Clean up frames directory\n",
    "    try:\n",
    "        shutil.rmtree(frames_dir)\n",
    "        print(\"Cleanup completed successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Cleanup error: {e}\")\n",
    "\n",
    "    print(f\"Animation saved as GIF: {gif_path}\")\n",
    "    return gif_path\n",
    "\n",
    "def convert_gif_to_storytelling_video(gif_path, summary):\n",
    "    \"\"\"\n",
    "    Converts a GIF into a storytelling video using imageio\n",
    "    \"\"\"\n",
    "    categories = summary['categories']\n",
    "    values = summary['values']\n",
    "\n",
    "    def create_text_frame(text, size=(1920, 1080), bg_color='white'):\n",
    "        img = Image.new('RGB', size, color=bg_color)\n",
    "        draw = ImageDraw.Draw(img)\n",
    "\n",
    "        try:\n",
    "            font = ImageFont.truetype(\"arial.ttf\", 60)\n",
    "        except:\n",
    "            font = ImageFont.load_default()\n",
    "\n",
    "        # Get text bbox\n",
    "        bbox = draw.textbbox((0, 0), text, font=font)\n",
    "        text_width = bbox[2] - bbox[0]\n",
    "        text_height = bbox[3] - bbox[1]\n",
    "\n",
    "        # Center text\n",
    "        x = (size[0] - text_width) // 2\n",
    "        y = (size[1] - text_height) // 2\n",
    "\n",
    "        draw.text((x, y), text, fill='black' if bg_color == 'white' else 'white', font=font)\n",
    "        # Convert to RGB numpy array\n",
    "        return np.array(img.convert('RGB'))\n",
    "\n",
    "    # Prepare frames\n",
    "    frames = []\n",
    "    fps = 30\n",
    "\n",
    "    # 1. Title sequence (2 seconds)\n",
    "    title_frame = create_text_frame(\"Market Share Analysis\", bg_color='black')\n",
    "    for _ in range(2 * fps):\n",
    "        frames.append(title_frame)\n",
    "\n",
    "    # 2. GIF sequence (4 seconds)\n",
    "    gif = Image.open(gif_path)\n",
    "    gif_frames = []\n",
    "    try:\n",
    "        while True:\n",
    "            frame = gif.copy()\n",
    "            # Resize frame and ensure RGB\n",
    "            frame = frame.convert('RGB').resize((1920, 1080), Image.LANCZOS)\n",
    "            # Convert to numpy array\n",
    "            frame_array = np.array(frame)\n",
    "            gif_frames.append(frame_array)\n",
    "            gif.seek(len(gif_frames))\n",
    "    except EOFError:\n",
    "        pass\n",
    "\n",
    "    # Extend gif frames to 4 seconds\n",
    "    frames_needed = 4 * fps\n",
    "    while len(gif_frames) < frames_needed:\n",
    "        gif_frames.extend(gif_frames)\n",
    "    frames.extend(gif_frames[:frames_needed])\n",
    "\n",
    "    # 3. Explanation sequence (4 seconds)\n",
    "    explanations = [\n",
    "        \"Analyzing market share data...\",\n",
    "        f\"Main competitor: {categories[values.index(max(values))]} leads with {max(values)}%\",\n",
    "        f\"Market gap analysis shows {max(values) - min(values)}% difference\",\n",
    "        f\"Total market coverage: {sum(values)}%\",\n",
    "        \"Generating insights and recommendations...\"\n",
    "    ]\n",
    "\n",
    "    frames_per_explanation = int((4 * fps) / len(explanations))\n",
    "    for exp in explanations:\n",
    "        exp_frame = create_text_frame(exp)\n",
    "        for _ in range(frames_per_explanation):\n",
    "            frames.append(exp_frame)\n",
    "\n",
    "    # Verify all frames have the same shape and channels\n",
    "    frame_shape = frames[0].shape\n",
    "    frames = [frame.reshape(frame_shape) if frame.shape != frame_shape else frame\n",
    "              for frame in frames]\n",
    "\n",
    "    # Save as MP4\n",
    "    output_path = 'data_storytelling_video.mp4'\n",
    "\n",
    "    print(\"Writing video...\")\n",
    "    writer = imageio.get_writer(output_path, fps=fps)\n",
    "    for frame in frames:\n",
    "        writer.append_data(frame)\n",
    "    writer.close()\n",
    "\n",
    "    print(f\"Data storytelling video saved as: {output_path}\")\n",
    "\n",
    "    # Add Narration Audio to Video\n",
    "    final_video = \"final_data_storytelling_video.mp4\"\n",
    "    add_auto_generated_audio_to_video(output_path, summary['audio_path'], output_video_path=final_video)\n",
    "\n",
    "    return final_video\n",
    "\n",
    "# Step 4: Add Narration Audio to Video using MoviePy\n",
    "def add_auto_generated_audio_to_video(video_path, audio_file_path, output_video_path):\n",
    "    video_clip = VideoFileClip(video_path)\n",
    "    audio_clip = AudioFileClip(audio_file_path)\n",
    "\n",
    "    # Set the audio of the video clip to the generated narration\n",
    "    video_clip = video_clip.set_audio(audio_clip)\n",
    "\n",
    "    # Write the final video with the audio\n",
    "    video_clip.write_videofile(output_video_path, codec=\"libx264\", audio_codec=\"aac\")\n",
    "\n",
    "# Main Function to Create Infographic Video with Auto-Generated Narration and Audio\n",
    "def create_infographic_video(user_prompt):\n",
    "    final_video_path = generate_infographics_from_prompt(user_prompt)\n",
    "    print(f\"Infographic video created successfully: {final_video_path}\")\n",
    "\n",
    "# Function to process CSV and create data storytelling video\n",
    "def process_csv_and_create_video(csv_file_path):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "\n",
    "    # Convert the DataFrame to a string prompt\n",
    "    prompt = df.to_string(index=False)\n",
    "\n",
    "    # Create the infographic video\n",
    "    create_infographic_video(prompt)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    csv_file_path = 'F:\\\\100x_enginners_hackathon_genai\\\\data\\\\2015.csv'\n",
    "    process_csv_and_create_video(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed infographic saved as: detailed_infographic.png\n",
      "Moviepy - Building video final_data_storytelling_video.mp4.\n",
      "MoviePy - Writing audio in final_data_storytelling_videoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video final_data_storytelling_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready final_data_storytelling_video.mp4\n",
      "Data storytelling video saved as: final_data_storytelling_video.mp4\n",
      "Infographic video created successfully: final_data_storytelling_video.mp4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import gtts\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip, ImageSequenceClip, concatenate_videoclips, TextClip, CompositeVideoClip\n",
    "import re\n",
    "import shutil\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import imageio\n",
    "import uuid\n",
    "\n",
    "# Set the HF_HOME environment variable to change the cache path\n",
    "os.environ['HF_HOME'] = \"D:\\\\__MACOSX\"  # Change this to your desired cache path\n",
    "\n",
    "# Load the model and tokenizer from .pkl files\n",
    "models_dir = os.path.join(os.getcwd(), 'models')\n",
    "\n",
    "with open(os.path.join(models_dir, 'model.pkl'), 'rb') as model_file:\n",
    "    summary_model = pickle.load(model_file)\n",
    "\n",
    "with open(os.path.join(models_dir, 'tokenizer.pkl'), 'rb') as tokenizer_file:\n",
    "    summary_tokenizer = pickle.load(tokenizer_file)\n",
    "\n",
    "# NLP Pipeline Function\n",
    "def nlp_pipeline(text):\n",
    "    # Prepare input\n",
    "    input_text = f\"summarize: {text}\"\n",
    "    inputs = summary_tokenizer.encode(input_text, return_tensors='pt', max_length=512, truncation=True)\n",
    "\n",
    "    # Generate summary\n",
    "    outputs = summary_model.generate(inputs, max_length=100)\n",
    "    summary_text = summary_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Extract percentages and categories using regex patterns\n",
    "    percentages = [int(x.strip('%')) for x in re.findall(r'\\d+%', text)]\n",
    "    words = text.split()\n",
    "    categories = []\n",
    "\n",
    "    # Find words after \"use\" or \"uses\"\n",
    "    for i, word in enumerate(words):\n",
    "        if word.lower() in ['use', 'uses'] and i + 1 < len(words):\n",
    "            categories.append(words[i + 1])\n",
    "\n",
    "    if not percentages or not categories:\n",
    "        percentages = [100]\n",
    "        categories = ['Summary']\n",
    "\n",
    "    # Generate audio\n",
    "    tts = gtts.gTTS(summary_text, lang='en')\n",
    "    audio_filename = f'summary_audio_{uuid.uuid4().hex}.mp3'\n",
    "    audio_path = os.path.join('F:\\\\100x_enginners_hackathon_genai\\\\uploads\\\\audio_files', audio_filename)\n",
    "    tts.save(audio_path)\n",
    "\n",
    "    return {\n",
    "        'categories': categories,\n",
    "        'values': percentages,\n",
    "        'text': summary_text,\n",
    "        'audio_path': audio_path\n",
    "    }\n",
    "\n",
    "# Define a function to generate infographics from custom prompt\n",
    "def generate_infographics_from_prompt(prompt):\n",
    "    # Use the NLP pipeline to process the prompt\n",
    "    summary = nlp_pipeline(prompt)\n",
    "\n",
    "    # Create a detailed infographic\n",
    "    infographic_path = create_detailed_infographic(summary)\n",
    "\n",
    "    # Create storytelling video\n",
    "    final_video_path = create_storytelling_video(infographic_path, summary)\n",
    "\n",
    "    return final_video_path\n",
    "\n",
    "def create_detailed_infographic(summary):\n",
    "    \"\"\"\n",
    "    Creates a static detailed infographic for data storytelling\n",
    "    \"\"\"\n",
    "    categories = summary['categories']\n",
    "    values = summary['values']\n",
    "\n",
    "    # Create figure with subplots\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "\n",
    "    # Main bar plot\n",
    "    ax1 = plt.subplot2grid((2, 2), (0, 0), colspan=2)\n",
    "    bars = ax1.bar(categories, values, color='skyblue')\n",
    "    ax1.set_title('Market Share Distribution', fontsize=16)\n",
    "    ax1.set_ylabel('Percentage (%)')\n",
    "\n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width() / 2., height,\n",
    "                f'{int(height)}%',\n",
    "                ha='center', va='bottom')\n",
    "\n",
    "    # Pie chart\n",
    "    ax2 = plt.subplot2grid((2, 2), (1, 0))\n",
    "    ax2.pie(values, labels=categories, autopct='%1.1f%%')\n",
    "    ax2.set_title('Market Share Proportion')\n",
    "\n",
    "    # Additional insights text\n",
    "    ax3 = plt.subplot2grid((2, 2), (1, 1))\n",
    "    ax3.axis('off')\n",
    "    total = sum(values)\n",
    "    insights_text = f\"\"\"Key Insights:\n",
    "\n",
    "    • Total market coverage: {total}%\n",
    "    • Leading brand: {categories[values.index(max(values))]}\n",
    "    • Market share gap: {max(values) - min(values)}%\n",
    "    \"\"\"\n",
    "    ax3.text(0, 0.5, insights_text, fontsize=12, va='center')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save high-quality image\n",
    "    output_path = 'detailed_infographic.png'\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Detailed infographic saved as: {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "def create_text_frame(text, size=(1920, 1080), bg_color='white'):\n",
    "    \"\"\"\n",
    "    Creates a text frame using PIL\n",
    "    \"\"\"\n",
    "    img = Image.new('RGB', size, color=bg_color)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", 60)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    # Get text bbox\n",
    "    bbox = draw.textbbox((0, 0), text, font=font)\n",
    "    text_width = bbox[2] - bbox[0]\n",
    "    text_height = bbox[3] - bbox[1]\n",
    "\n",
    "    # Center text\n",
    "    x = (size[0] - text_width) // 2\n",
    "    y = (size[1] - text_height) // 2\n",
    "\n",
    "    draw.text((x, y), text, fill='black' if bg_color == 'white' else 'white', font=font)\n",
    "    # Convert to RGB numpy array\n",
    "    return np.array(img.convert('RGB'))\n",
    "\n",
    "def create_storytelling_video(infographic_path, summary):\n",
    "    \"\"\"\n",
    "    Creates a storytelling video using the infographic and summary\n",
    "    \"\"\"\n",
    "    categories = summary['categories']\n",
    "    values = summary['values']\n",
    "    summary_text = summary['text']\n",
    "    audio_path = summary['audio_path']\n",
    "\n",
    "    # Create video clips\n",
    "    clips = []\n",
    "\n",
    "    # Title clip\n",
    "    title_frame = create_text_frame(\"Market Share Analysis\", bg_color='black')\n",
    "    title_clip = ImageSequenceClip([title_frame], fps=1).set_duration(2)\n",
    "    clips.append(title_clip)\n",
    "\n",
    "    # Infographic clip\n",
    "    infographic_clip = ImageSequenceClip([infographic_path], fps=1).set_duration(5)\n",
    "    clips.append(infographic_clip)\n",
    "\n",
    "    # Explanation clips\n",
    "    explanations = [\n",
    "        \"Analyzing market share data...\",\n",
    "        f\"Main competitor: {categories[values.index(max(values))]} leads with {max(values)}%\",\n",
    "        f\"Market gap analysis shows {max(values) - min(values)}% difference\",\n",
    "        f\"Total market coverage: {sum(values)}%\",\n",
    "        \"Generating insights and recommendations...\"\n",
    "    ]\n",
    "\n",
    "    for exp in explanations:\n",
    "        exp_frame = create_text_frame(exp)\n",
    "        exp_clip = ImageSequenceClip([exp_frame], fps=1).set_duration(4)\n",
    "        clips.append(exp_clip)\n",
    "\n",
    "    # Concatenate all clips\n",
    "    video = concatenate_videoclips(clips)\n",
    "\n",
    "    # Add narration audio\n",
    "    audio_clip = AudioFileClip(audio_path)\n",
    "    video = video.set_audio(audio_clip)\n",
    "\n",
    "    # Save final video\n",
    "    final_video_path = 'final_data_storytelling_video.mp4'\n",
    "    video.write_videofile(final_video_path, codec=\"libx264\", audio_codec=\"aac\")\n",
    "\n",
    "    print(f\"Data storytelling video saved as: {final_video_path}\")\n",
    "    return final_video_path\n",
    "\n",
    "# Main Function to Create Infographic Video with Auto-Generated Narration and Audio\n",
    "def create_infographic_video(user_prompt):\n",
    "    final_video_path = generate_infographics_from_prompt(user_prompt)\n",
    "    print(f\"Infographic video created successfully: {final_video_path}\")\n",
    "\n",
    "# Function to process CSV and create data storytelling video\n",
    "def process_csv_and_create_video(csv_file_path):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "\n",
    "    # Convert the DataFrame to a string prompt\n",
    "    prompt = df.to_string(index=False)\n",
    "\n",
    "    # Create the infographic video\n",
    "    create_infographic_video(prompt)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    csv_file_path = 'F:\\\\100x_enginners_hackathon_genai\\\\data\\\\2015.csv'\n",
    "    process_csv_and_create_video(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Country          Region  Happiness Rank  Happiness Score  \\\n",
      "0  Switzerland  Western Europe               1            7.587   \n",
      "1      Iceland  Western Europe               2            7.561   \n",
      "2      Denmark  Western Europe               3            7.527   \n",
      "3       Norway  Western Europe               4            7.522   \n",
      "4       Canada   North America               5            7.427   \n",
      "\n",
      "   Standard Error  Economy (GDP per Capita)   Family  \\\n",
      "0         0.03411                   1.39651  1.34951   \n",
      "1         0.04884                   1.30232  1.40223   \n",
      "2         0.03328                   1.32548  1.36058   \n",
      "3         0.03880                   1.45900  1.33095   \n",
      "4         0.03553                   1.32629  1.32261   \n",
      "\n",
      "   Health (Life Expectancy)  Freedom  Trust (Government Corruption)  \\\n",
      "0                   0.94143  0.66557                        0.41978   \n",
      "1                   0.94784  0.62877                        0.14145   \n",
      "2                   0.87464  0.64938                        0.48357   \n",
      "3                   0.88521  0.66973                        0.36503   \n",
      "4                   0.90563  0.63297                        0.32957   \n",
      "\n",
      "   Generosity  Dystopia Residual  \n",
      "0     0.29678            2.51738  \n",
      "1     0.43630            2.70201  \n",
      "2     0.34139            2.49204  \n",
      "3     0.34699            2.46531  \n",
      "4     0.45811            2.45176  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_and_preprocess_csv(csv_file_path):\n",
    "    \"\"\"\n",
    "    Reads a CSV file and preprocesses the data.\n",
    "    \"\"\"\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "\n",
    "    # Perform any necessary preprocessing steps\n",
    "    # For example, handling missing values, converting data types, etc.\n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    csv_file_path = 'F:\\\\100x_enginners_hackathon_genai\\\\data\\\\2015.csv'\n",
    "    df = read_and_preprocess_csv(csv_file_path)\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'categories': ['Summary'], 'values': [100], 'text': '20% of users own an iPhone, 50% own a Samsung, and the rest own a variety of brands. the rest own a variety of brands, including a tv, a pc, a pc, a pc, a pc, a pc, a pc, a pc, a pc, a pc, a pc'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import re\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "# Load the model and tokenizer from .pkl files\n",
    "models_dir = os.path.join(os.getcwd(), 'models')\n",
    "\n",
    "with open(os.path.join(models_dir, 'model.pkl'), 'rb') as model_file:\n",
    "    summary_model = pickle.load(model_file)\n",
    "\n",
    "with open(os.path.join(models_dir, 'tokenizer.pkl'), 'rb') as tokenizer_file:\n",
    "    summary_tokenizer = pickle.load(tokenizer_file)\n",
    "\n",
    "def nlp_pipeline(text):\n",
    "    \"\"\"\n",
    "    Generates a summary and extracts insights from the text.\n",
    "    \"\"\"\n",
    "    # Prepare input\n",
    "    input_text = f\"summarize: {text}\"\n",
    "    inputs = summary_tokenizer.encode(input_text, return_tensors='pt', max_length=512, truncation=True)\n",
    "\n",
    "    # Generate summary\n",
    "    outputs = summary_model.generate(inputs, max_length=100)\n",
    "    summary_text = summary_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Extract percentages and categories using regex patterns\n",
    "    percentages = [int(x.strip('%')) for x in re.findall(r'\\d+%', text)]\n",
    "    words = text.split()\n",
    "    categories = []\n",
    "\n",
    "    # Find words after \"use\" or \"uses\"\n",
    "    for i, word in enumerate(words):\n",
    "        if word.lower() in ['use', 'uses'] and i + 1 < len(words):\n",
    "            categories.append(words[i + 1])\n",
    "\n",
    "    if not percentages or not categories:\n",
    "        percentages = [100]\n",
    "        categories = ['Summary']\n",
    "\n",
    "    return {\n",
    "        'categories': categories,\n",
    "        'values': percentages,\n",
    "        'text': summary_text\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    text = \"20% of users own an iPhone, 50% own a Samsung, and the rest own a variety of brands\"\n",
    "    summary = nlp_pipeline(text)\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video new_video_final_data_storytelling_video.mp4.\n",
      "MoviePy - Writing audio in new_video_final_data_storytelling_videoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video new_video_final_data_storytelling_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready new_video_final_data_storytelling_video.mp4\n",
      "Data storytelling video saved as: new_video_final_data_storytelling_video.mp4\n"
     ]
    }
   ],
   "source": [
    "import gtts\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip, ImageSequenceClip, concatenate_videoclips\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "\n",
    "def create_text_frame(text, size=(1920, 1080), bg_color='white'):\n",
    "    \"\"\"\n",
    "    Creates a text frame using PIL.\n",
    "    \"\"\"\n",
    "    img = Image.new('RGB', size, color=bg_color)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", 60)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    # Get text bbox\n",
    "    bbox = draw.textbbox((0, 0), text, font=font)\n",
    "    text_width = bbox[2] - bbox[0]\n",
    "    text_height = bbox[3] - bbox[1]\n",
    "\n",
    "    # Center text\n",
    "    x = (size[0] - text_width) // 2\n",
    "    y = (size[1] - text_height) // 2\n",
    "\n",
    "    draw.text((x, y), text, fill='black' if bg_color == 'white' else 'white', font=font)\n",
    "    # Convert to RGB numpy array\n",
    "    return np.array(img.convert('RGB'))\n",
    "\n",
    "def create_storytelling_video(infographic_path, summary):\n",
    "    \"\"\"\n",
    "    Creates a storytelling video using the infographic and summary.\n",
    "    \"\"\"\n",
    "    categories = summary['categories']\n",
    "    values = summary['values']\n",
    "    summary_text = summary['text']\n",
    "    audio_path = summary['audio_path']\n",
    "\n",
    "    # Create video clips\n",
    "    clips = []\n",
    "\n",
    "    # Title clip\n",
    "    title_frame = create_text_frame(\"Market Share Analysis\", bg_color='black')\n",
    "    title_clip = ImageSequenceClip([title_frame], fps=1).set_duration(2)\n",
    "    clips.append(title_clip)\n",
    "\n",
    "    # Infographic clip\n",
    "    infographic_clip = ImageSequenceClip([infographic_path], fps=1).set_duration(5)\n",
    "    clips.append(infographic_clip)\n",
    "\n",
    "    # Explanation clips\n",
    "    explanations = [\n",
    "        \"Analyzing market share data...\",\n",
    "        f\"Main competitor: {categories[values.index(max(values))]} leads with {max(values)}%\",\n",
    "        f\"Market gap analysis shows {max(values) - min(values)}% difference\",\n",
    "        f\"Total market coverage: {sum(values)}%\",\n",
    "        \"Generating insights and recommendations...\"\n",
    "    ]\n",
    "\n",
    "    for exp in explanations:\n",
    "        exp_frame = create_text_frame(exp)\n",
    "        exp_clip = ImageSequenceClip([exp_frame], fps=1).set_duration(4)\n",
    "        clips.append(exp_clip)\n",
    "\n",
    "    # Concatenate all clips\n",
    "    video = concatenate_videoclips(clips)\n",
    "\n",
    "    # Add narration audio\n",
    "    audio_clip = AudioFileClip(audio_path)\n",
    "    video = video.set_audio(audio_clip)\n",
    "\n",
    "    # Save final video\n",
    "    final_video_path = 'new_video_final_data_storytelling_video.mp4'\n",
    "    video.write_videofile(final_video_path, codec=\"libx264\", audio_codec=\"aac\")\n",
    "\n",
    "    print(f\"Data storytelling video saved as: {final_video_path}\")\n",
    "    return final_video_path\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    summary = {\n",
    "        'categories': ['iPhone', 'Samsung', 'Others'],\n",
    "        'values': [20, 50, 30],\n",
    "        'text': '20% of users own an iPhone, 50% own a Samsung, and the rest own a variety of brands',\n",
    "        'audio_path': 'F:\\\\100x_enginners_hackathon_genai\\\\uploads\\\\audio_files\\\\summary_audio.mp3'\n",
    "    }\n",
    "    infographic_path = 'detailed_infographic.png'\n",
    "    create_storytelling_video(infographic_path, summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed infographic saved as: detailed_infographic.png\n",
      "Moviepy - Building video new_video_final_data_storytelling_video.mp4.\n",
      "MoviePy - Writing audio in new_video_final_data_storytelling_videoTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video new_video_final_data_storytelling_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready new_video_final_data_storytelling_video.mp4\n",
      "Data storytelling video saved as: new_video_final_data_storytelling_video.mp4\n",
      "Infographic video created successfully: new_video_final_data_storytelling_video.mp4\n"
     ]
    }
   ],
   "source": [
    "def process_csv_and_create_video(csv_file_path):\n",
    "    \"\"\"\n",
    "    Orchestrates the entire process from reading the CSV file to generating the final video.\n",
    "    \"\"\"\n",
    "    # Step 1: Read and preprocess the CSV file\n",
    "    df = read_and_preprocess_csv(csv_file_path)\n",
    "\n",
    "    # Step 2: Convert the DataFrame to a string prompt\n",
    "    prompt = df.to_string(index=False)\n",
    "\n",
    "    # Step 3: Generate summaries and insights\n",
    "    summary = nlp_pipeline(prompt)\n",
    "\n",
    "    # Step 4: Generate audio for the summary\n",
    "    tts = gtts.gTTS(summary['text'], lang='en')\n",
    "    audio_filename = f'summary_audio_{uuid.uuid4().hex}.mp3'\n",
    "    audio_path = os.path.join('F:\\\\100x_enginners_hackathon_genai\\\\uploads\\\\audio_files', audio_filename)\n",
    "    tts.save(audio_path)\n",
    "    summary['audio_path'] = audio_path\n",
    "\n",
    "    # Step 5: Create detailed infographics\n",
    "    infographic_path = create_detailed_infographic(summary)\n",
    "\n",
    "    # Step 6: Create storytelling video\n",
    "    final_video_path = create_storytelling_video(infographic_path, summary)\n",
    "\n",
    "    print(f\"Infographic video created successfully: {final_video_path}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    csv_file_path = 'F:\\\\100x_enginners_hackathon_genai\\\\data\\\\2015.csv'\n",
    "    process_csv_and_create_video(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chart.js HTML visualization saved as: F:\\100x_enginners_hackathon_genai\\templates\\chart_visualization.html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def generate_chart_js_html(df, output_html_path):\n",
    "    \"\"\"\n",
    "    Generates an HTML file with Chart.js visualizations from a DataFrame.\n",
    "    \"\"\"\n",
    "    categories = df.columns.tolist()\n",
    "    values = df.iloc[0].tolist()\n",
    "\n",
    "    html_content = f\"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <head>\n",
    "        <title>Chart.js Visualization</title>\n",
    "        <script src=\"https://cdn.jsdelivr.net/npm/chart.js\"></script>\n",
    "    </head>\n",
    "    <body>\n",
    "        <canvas id=\"myChart\" width=\"400\" height=\"400\"></canvas>\n",
    "        <script>\n",
    "            var ctx = document.getElementById('myChart').getContext('2d');\n",
    "            var myChart = new Chart(ctx, {{\n",
    "                type: 'bar',\n",
    "                data: {{\n",
    "                    labels: {categories},\n",
    "                    datasets: [{{\n",
    "                        label: 'Data',\n",
    "                        data: {values},\n",
    "                        backgroundColor: 'rgba(54, 162, 235, 0.2)',\n",
    "                        borderColor: 'rgba(54, 162, 235, 1)',\n",
    "                        borderWidth: 1\n",
    "                    }}]\n",
    "                }},\n",
    "                options: {{\n",
    "                    scales: {{\n",
    "                        y: {{\n",
    "                            beginAtZero: true\n",
    "                        }}\n",
    "                    }}\n",
    "                }}\n",
    "            }});\n",
    "        </script>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "\n",
    "    with open(output_html_path, 'w') as f:\n",
    "        f.write(html_content)\n",
    "\n",
    "    print(f\"Chart.js HTML visualization saved as: {output_html_path}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    csv_file_path = 'F:\\\\100x_enginners_hackathon_genai\\\\data\\\\2015.csv'\n",
    "    df = read_and_preprocess_csv(csv_file_path)\n",
    "    output_html_path = 'F:\\\\100x_enginners_hackathon_genai\\\\templates\\\\chart_visualization.html'\n",
    "    generate_chart_js_html(df, output_html_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Command '['node', 'F:\\\\\\\\100x_enginners_hackathon_genai\\\\\\\\static\\\\\\\\js\\\\\\\\convert_html_to_image.js']' returned non-zero exit status 1.\n",
      "Ensure that Node.js and Puppeteer are installed and accessible.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import shutil\n",
    " \n",
    "import subprocess#+\n",
    "def convert_html_to_image(html_path, output_image_path):\n",
    "    \"\"\"\n",
    "    Converts an HTML file to an image using Puppeteer.\n",
    "    \"\"\"\n",
    "    script = r\"\"\"\n",
    "    const puppeteer = require('puppeteer');\n",
    "    (async () => {{\n",
    "        const browser = await puppeteer.launch();\n",
    "        const page = await browser.newPage();\n",
    "        await page.goto('file:///{html_path.replace(\"\\\\\", \"/\")}');\n",
    "        await page.screenshot({{ path: '{output_image_path.replace(\"\\\\\", \"/\")}', fullPage: true }});\n",
    "        await browser.close();\n",
    "    }})();\n",
    "    \"\"\"\n",
    "\n",
    "    script_path = r'F:\\\\100x_enginners_hackathon_genai\\\\static\\\\js\\\\convert_html_to_image.js'\n",
    "    with open(script_path, 'w') as f:\n",
    "        f.write(script)\n",
    "\n",
    "    try:\n",
    "        subprocess.run(['node', script_path], check=True)\n",
    "        print(f\"HTML visualization converted to image: {output_image_path}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(\"Ensure that Node.js and Puppeteer are installed and accessible.\")\n",
    " \n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    html_path = r'F:\\\\100x_enginners_hackathon_genai\\\\templates\\\\chart_visualization.html'\n",
    "    output_image_path = r'F:\\100x_enginners_hackathon_genai\\static\\images\\chart_visualization.png'\n",
    "    convert_html_to_image(html_path, output_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work on this module tommorow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
